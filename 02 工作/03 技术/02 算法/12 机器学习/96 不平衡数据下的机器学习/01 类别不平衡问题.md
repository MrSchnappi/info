# 类别不平衡

# 情况介绍

类别不平衡 class-imbalance

场景：

- 搜索引擎的点击预测（点击的网页往往占据很小的比例）
- 电子商务领域的商品推荐（推荐的商品被购买的比例很低）
- 信用卡欺诈检测
- 网络攻击识别
- 等等。

定义：

- 不平衡数据的学习即需要在样本类别极不均衡的数据集中学习到有用的信息。


举例：

- 以二分类问题为例，通常情况下把多数类样本的比例为 $100:1$，$1000:1$，甚至是 $10000:1$ 这种情况下为不平衡数据。

产生的问题：

- 分类学习算法通常假设不同类别的训练样例数目基本相同。如果不同类别的训练样例数目差别很大，则会影响学习结果，测试结果变差。

举例：

- 分类问题中有 998 个反例，正例有 2 个，那学习方法只需返回一个永远将新样本预测为反例的分类器，就能达到 99.8%的精度；然而这样的分类器没有价值。


# 处理方式

（进行更好的补充和组织）

主要处理方法：

- 采样 从数据层面解决不平衡数据的学习问题
- 在算法层面上解决不平衡数据学习


举例：

- 二分类问题
- 训练集中 80% 分类为 A，20% 分类为 B。


解决：

- 简单方法
  - 采集更多小样本的数据。
  - 数据多的欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当。
  - 数据少的过采样(over-sampling)，即重复使用一部分数据，使其与较多类别的数据相当。
  - 阈值调整（threshold moving，例如数据均衡时，阈值为 0.5，那么可以按比例，例如调整到 0.8。
- 复杂方法
  - 数据采样过程中，生成并插样“少数类别”数据，代表算法 SMOTE 和 ADASYN。
    - SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。新的少数类样本产生的策略：对每个少数类样本 $a$，在 $a$ 的最近邻中随机选一个样本 $b$，然后在 $a$、$b$ 之间的连线上随机选一点作为新合成的少数类样本。<span style="color:red;">这样真的有效果吗？会不会有问题？</span>
    - ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。<span style="color:red;">什么叫把分类决策边界自适应地转移到困难的样本？这个 ADASYN 没有很理解。</span>
  - 数据先聚类，“多数类别”随机欠采样，“少数类别”数据生成。
  - 随机欠采样容易丢失重要信息，可结合集成学习欠采样，代表算法：EasyEnsemble。
    - EasyEnsemble。利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器欠采样，避免全局丢失重要信息。<span style="color:red;">这个效果怎么样。</span>
- 使用新评价指标
  - 如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。
- 选择新算法
  - 不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。
- 数据代价加权
  - 例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。<span style="color:red;">怎么加权？给损失函数中按分类进行加权吗？加权多少合适？</span>
- 转化问题思考角度
  - 例如在分类问题时，把小类的样本作为异常点。此时问题转化为异常点检测或变化趋势检测问题。
    - 异常点检测即是对那些罕见事件进行识别。
    - 变化趋势检测区别于异常点检测，在于其通过检测不寻常的变化趋势来识别。
- 将问题细化分析
  - 对问题进行分析与挖掘，将问题拆解成多个更小的问题，看这些小问题是否更容易解决。

