# R-CNN

## 介绍

目的：

- 提高效果，超过端到端方法 OverFeat 

地址：

- <http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf>


介绍：

- 利用选择性搜索（Selective Search）算法评测相邻图像子块的特征相似度
- 通过对合并后的相似图像区域打分，选择出感兴趣区域的候选框作为样本输入到卷积神经网络结构内部
- 由网络学习候选框和标定框组成的正负样本特征，形成对应的特征向量
- 再由支持向量机设计分类器对特征向量分类
- 最后对候选框以及标定框完成边框回归操作达到目标检测的定位目的。

效果：

- 相较于传统目标检测算法取得了 50% 的性能提升


缺点：

- 训练网络的正负样本候选区域由传统算法生成，使得算法速度受到限制
- 卷积神经网络需要分别对每一个生成的候选区域进行一次特征提取，实际存在大量的重复运算，制约了算法性能。

## 关键

- Selective Search


Region Proposal 方法：

- 滑窗法
- Selective Search



### 滑窗法

非极大值抑制？补充下。

步骤：

- 一个已经训练好的分类器
- 把图像按照一定间隔和不同的大小分成一个个窗口，在这些窗口上执行分类器，如果得到较高的分类分数，就认为是检测到了物体。
- 把每个窗口都用分类器执行一遍之后，再对得到的分数做一些后处理如非极大值抑制(Non-Maximum Suppression, NMS)等，最后就得到了物体类别和对应区域。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180901/84Eh3Cdb3C.png?imageslim">
</p>


特点：

- 简单
- 效率极低
- 要考虑物体长宽比


### Selective Search

提出原因：

- 滑窗法的缺点相当于对一张图像上的子区域进行类似穷举式的搜索，一般情况下这种低效率搜索到的区域里大部分都是没有任何物体的。所以一个很自然的想法就是只对图像中最有可能包含物体的区域进行搜索，进而提升物体检测的效率。在这种思路的方法中，最为熟知的是 Selective Search。

思路：

- 可能存在物体的区域都应该是有某种相似性的或连续的区域。

做法：（即超像素合并）

- 用分割算法在图像上产生很多的小区域，这些区域就是最基础的子区域，或者可以看作是超像素。
- 然后根据这些区域之间的相似性进行区域合并，成为大一点的区域。衡量相似性的标准可以是颜色、纹理和大小等。<span style="color:red;">纹理和大小怎么作为相似性的衡量标准的？</span>
- 不断迭加这种小区域合并为大区域的过程，最后整张图会合并成为一个区域。
- 这个过程中，给每个区域做一个外切的矩形，就得到了许许多多的可能是物体的区域方框。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180901/1Bb4HG8lcl.png?imageslim">
</p>

优势：

- 高效，因为不再是漫无目的的穷举式搜索。
- 一开始的区域是小区域，合并过程中不断产生大区域，所以天然能够包含各种大小不同的疑似物体框。
- 计算相似度采用了多样的指标，提升了找到物体的可靠性。<span style="color:red;">？</span>

优化：

- Selective Search 选出的框未必精确，所以还加入了一些改进，如和物体标注框的位置的回归来修正 Selective Search 提出的原始物体框。<span style="color:red;">？</span>


### Region  Proposal 方法缺点

速度慢：

- Selective Search 虽然比起滑窗法已经快了很多，但可用性还是很差，因为一个稍微“靠谱”的识别任务需要用 Selective Search 提出上千个框 (R-CNN中是 2000 个)。这上千个图像区域都需要单独过一遍卷积神经网络进行前向计算，速度自然快不了。
