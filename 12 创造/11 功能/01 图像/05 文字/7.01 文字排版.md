---
title: 7.01 文字排版
toc: true
date: 2019-09-16
---
# 文字排版

由于 OCR 只能识别图片中的文字，用户在粘贴之后还需要进行重新将电子文档排版、修正，这将会花费用户大量的时间。同时因拍摄的纸质文档中会存在大量的文字外内容，例如表格、图片、段落样式、文字样式、排版，如果使用单一的 OCR 通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的能力，则无法将图片中的数据准确的识别，并且图片等不需要识别的内容也无法保留下来。

如下图所示因无法判断是否为图片，将地图中的文字也进行了识别，并且表格也无法保留，导致后期需要大量的时间进行文档的修改。

<center>

![mark](http://images.iterate.site/blog/image/20190915/62OezwcGlqDG.png?imageslim)

</center>

可以发现与传统的 OCR 识别方案不同，**我们需要识别出图片中的表格、图片、公式、段落样式、文字样式、排版等内容，并可以在保证内容不丢失的情况下直接插入到文档中，将纸质文档一键转换成可直接编辑的电子文档**，解决了传统方案中识别内容丢失和文档格式不兼容等问题，减少了用户后期重复编辑的时间，大大提升了用户的工作效率。


## 整个方案主要包括以下三个环节

1. 重新过程需先对文档进行版面分析，版面分析是对版面内的图像、文本、表格信息和位置关系进行自动分析、识别和理解的过程，决定了恢复出来文档的完整性和质量。
2. 版面分析得到段落、图片、表格等结构化信息后，再进行 OCR 识别和表格恢复。
3. 生成用户可以直接编辑的格式。

当前使用的技术：

- 版面分析：目前业界一般对二值化图像提取连通域，设计人为经验规则提取相应特征，然后利用决策树、SVM分类器得到每个区域的类别。整个流程依赖人为设计的特征，对倾斜旋转图像不够鲁棒，泛化性较差。
- OCR识别：目前业界主要通过深度学习如 Faster-RCNN、EAST算法、LSTM\RNN等技术检测识别文本行。
- 表格恢复：目前业界一般利用 Canny 算子提取边缘，计算单元格坐标位置从而恢复出表格，对模糊等低质图像效果不理想，后处理繁杂。

针对版面分析、表格重建使用深度学习来处理：

- 对文档图像进行语义分割，进而提取结构化的语义信息，最后对不同类型的区域进行相应的增强恢复。
- 特别针对表格重建，引入 CNN 提取表格边线，免去许多复杂后处理流程。


## 技术框架

方案主要由输入模块、版面分析模块、排版模块三个模块组成，如下图整体方案所示。

<center>

![mark](http://images.iterate.site/blog/image/20190915/zmAUPr99uqcz.png?imageslim)

</center>

> 整体方案

1. 系统首先对包含文档的图像进行检测，对扭曲的文档进行校正。
2. 然后通过版面分析模块，得到段落、图表等兴趣区域，针对每个区域进行相应增强恢复处理。
3. 最后根据阅读顺序，生成用户可以直接编辑的电子文档，如下图文档重建关键步骤所示。


<center>

![mark](http://images.iterate.site/blog/image/20190915/zC5heThmFJL2.png?imageslim)

</center>


> 文档重建关键步骤

## 输入模块

主要是进行预处理操作，作用：

- 自动框选
- 扭曲矫正

实现：

- 自动框选利用 HED 深度学习模型对图片中文档区域进行框选
- 扭曲矫正算法利用 DocNet 深度学习模型对文档图片进行扭曲矫正

这两个步骤目的是生成高质量的文档图片，提供版面分析效果。

## 版面分析模块

版面分析模块利用了图像分割模型 UNet 对文档版面进行学习，分割出图片中的段落、表格、图片、公式等元素，为了处理多栏、环绕等复杂版面，我们特意设计的版本分割线的学习，这样有利用提高版本分析的效果。后处理模块，主要是对图像分割模型产生 mask 图片进行处理，处理 mask 图像中的相交、包含等区域，划分出各个类型的子块，根据各个子块的位置以及分割线生成版面信息。


版面分析网络：版面分析是文档分析中的关键技术，传统的方法是通过设计人为规则判断文档各个区域元素类型。随着深度学习的兴起，越来越多人利用语义分割来解决版面分析问题。传统的分割网络一般基于图像分类网络如 ResNet、VGGNet，虽然这些网络在图像分类任务中取得比较好的效果，但是为了让网络得到较大的感受野，会对特征图进行下采样，导致丢失很多边缘细节信息，得到的物体边界轮廓往往不够清晰。我们提出了端到端多尺度融合模型如图，主要由两部分组成：编码器和解码器，相同尺度的编码器特征和解码器特征会相互结合，这样同时保持了语义特征和边缘特征。为了加速网络的学习，让低层的特征学习到框线表示，这里我们引入多尺度模型融合，编码器每个部分都有相应的预测输出，融合解码器的输出作为最终的结果。



<center>

![mark](http://images.iterate.site/blog/image/20190915/09yX9BTOazgy.png?imageslim)

</center>

> 版面分析网络

为了加快网络各个特征层的学习我们引入多尺度损失函数融合，分别计算原图分辨率下的损失函数, 原图 1/4和原图 1/16的损失函数，最后将这三个结果融合作为我们的目标函数。特别指出的是，在文档版面中公式、表格的占比远远少于段落文字，存在严重类别不均衡问题。传统语义分割损失函数往往采用交叉熵，针对类别不均衡效果不太理想，对于公式这种数据较少的类别识别效果很差。因此我们这里引入 IOU 损失函数，它能很好的解决类别不均衡问题。

目前版面识别支持的类型有公式、图片、表格、段落、题注、分割线、页眉和页脚，我们的网络在 1w+张测试集上平均 IOU 达到 91%。



<center>

![mark](http://images.iterate.site/blog/image/20190915/llsa1elSOaGD.png?imageslim)

</center>

> 版面识别效果



## 文字识别模块


字体识别网络：日常文档图片往往存在各种特色字体，比如粗体、下划线或者楷书等等。为了更好地还原文档的真实内容，这里我们引入字体识别模块支持特殊字体的识别。粗体、下划线、斜体这三类特性是可以叠加的，同时可以和任意一种字体结合的，比如我们实际中常用到加粗的宋体，加粗又带下划线的行楷等等。因此这里我们将粗体、下划线、斜体定义为字体属性，宋体行楷等定义为字体类别，针对性设计 Unet 双分支多任务网络，字体属性识别分支和字体类别识别分支共用图像编码层。

<center>

![mark](http://images.iterate.site/blog/image/20190915/YfF7Cpuxg19W.png?imageslim)

</center>

> 字体识别网络



目前字体识别支持的类型有粗体，斜体，下划线，宋体，楷体，隶书，我们的网络在 1w+张测试集上字体属性 mIOU 达到 93%，字体类别 mIOU 达到 91%。

<center>

![mark](http://images.iterate.site/blog/image/20190915/4HBiSRLvdDY3.png?imageslim)

</center>

> 字体识别效果



## 排版模块

排版模块的工作是根据版面信息生成最终的 word 文档，对于不同类型的子块进行差异化处理。对于文字类型的子块，组段算法是利用 OCR 技术对文字块图片的文字信息进行组段，生成有语义信息的段落，并且利用了图像分割技术对文字块进行字体识别，识别出文字块中粗体、斜体、下划线、宋体、隶书等字体信息。对于表格类型的子块，运用图像分割技术对表格框线像素进行识别，再结合 OCR 文本框坐标关系，推断出单元格的位置，最后对单元格内容进行分析，进一步得到单元格字号和对齐方式。而对于图片、公式类型，直接切图输出图片。最后，为了提高用户的阅读体验，我们设计了阅读顺序算法，根据子块的位置、语义信息，复原文档的阅读排序。

若文档中有表格，前面的步骤已定位了区域。接下来将切割出来的表格部分图片转换为表格结构信息，转换的具体流程如下图所示。

<center>

![mark](http://images.iterate.site/blog/image/20190915/EgNWmn3SbOt5.png?imageslim)

</center>

> 表格重建流程

首先，对表格图片使用神经网络进行像素级的分割，神经网络采用 Unet 卷积神经网络结构，每个像素有四个对应输出概率，分别表示此像素属于横向框线（可见或隐含）和竖向框线（可见或隐含）的概率。


<center>

![mark](http://images.iterate.site/blog/image/20190915/52EPAyKVHy8C.png?imageslim)

</center>

> 表格线提取效果

得到像素级别分割结果后，再进行几何分析。首先，提取横竖向两个分割图的连通区域，每个连通区域是一条曲线，对连通区域的像素拟合一条折线，也即若干线段的方程。接着对折线再进行合并，依据各折线中各线段的倾角相似度和坐标值的远近，将属于同一条框线的折线合并在一起。为把每条框线中的线段校正至水平或竖直，拟合单应矩阵，同时也把图片校正。将校正好的图片进行 OCR 计算，获取文本框坐标和字符坐标。接着对所有横竖框线计算交点，依据交点提取出每个单元格。最后将各个单元格信息再进行整合，得出每行的高度，每列的宽度，以及单元格的合并关系。单元格的合并关系是这样表示的：（左上角的单元格编号， 右下角的单元格编号）。最后再依据单元格和表格图的大小比例推算每个单元格中的字号大小，根据单元格中文字放置的位置推断对齐方式。将这些信息转成 WORD 文档中表格编码格式，使其可以在 WORD 等软件中显示、编辑。



# 相关

- [走进 AI 时代的文档识别技术 之文档重建 | 鹅厂实战](https://zhuanlan.zhihu.com/p/69465271)
