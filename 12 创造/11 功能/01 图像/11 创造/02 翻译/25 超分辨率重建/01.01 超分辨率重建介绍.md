---
title: 01.01 超分辨率重建介绍
toc: true
date: 2019-10-29
---
# 超分辨率重建介绍

**超分辨率重建 (Image Super-Resolution)**

去年夏天，一款名为“waifu 2x”（http://t.cn/R2AL4br）的岛国应用在动画和计算机图形学中着实火了一把。waifu 2x借助深度「卷积神经网络」(Convolutional Neural Network, CNN) 可以将图像的分辨率提升2倍，同时还能对图像降噪。简单来说，就是让计算机「无中生有」的填充一些原图中并没有的像素，从而让漫画看起来更清晰真切。大家不妨看看下图，真想童年时候看的就是如此高清的龙珠（http://t.cn/RYiMUaT）啊！

![img](http://5b0988e595225.cdn.sohucs.com/images/20171204/08f6e075290a4b3fb28ad1ab3511063e.jpeg)

![img](http://5b0988e595225.cdn.sohucs.com/images/20171204/4836bb690c89400789f41a6d0135f9ff.jpeg)

不过需要指出的是，图像超分辨率的研究始于2009年左右，只是得力于「深度学习」的发展，waifu 2x可以做出更好的效果。在具体训练CNN时，输入图像为原分辨率， 而对应的超分辨率图像则作为目标，以此构成训练的“图像对” (image pair)，经过模型训练便可得到超分辨率重建模型。waifu 2x的深度网络原型基于香港中文大学汤晓欧教授团队的工作[1]。有趣的是，[1]中指出可以用传统方法给予深度模型以定性的解释。如下图，低分辨率图像通过CNN的卷积 (convolution) 和池化 (pooling) 操作后可以得到抽象后的特征图 (feature map)。基于低分辨率特征图，同样可以利用卷积和池化实现从低分辨率到高分辨率特征图的非线性映射 (non-linear mapping)。最后的步骤则是利用高分辨率特征图重建高分辨率图像。实际上，所述三个步骤与传统超分辨率重建方法的三个过程是一致的。

![img](http://5b0988e595225.cdn.sohucs.com/images/20171204/f82580a7ff1a44c999efa997810ba9f7.jpeg)
