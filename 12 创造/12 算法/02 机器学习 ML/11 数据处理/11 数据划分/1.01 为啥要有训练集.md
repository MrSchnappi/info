---
title: 1.01 为啥要有训练集
toc: true
date: 2019-05-23
---
# 可以补充进来的


## 超参数和验证集


大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是通过学习算法本身学习出来的 (尽管我们可以设计一个嵌套的学习过程，一个学习算法为另一个学习算法学出最优超参数) 。<span style="color:red;">嗯嗯，是的，总结下什么时候我们需要这么做，而且，想问下怎么能保证另一个学习方法自己的超参数呢。。。</span>


<center>

![](http://images.iterate.site/blog/image/20190522/GmgGsOhGNG8x.png?imageslim){ width=55% }

</center>


在上图所示的多项式回归示例中，有一个超参数，即多项式的次数，作为容量超参数。控制权重衰减程度的 $\lambda$ 是另一个超参数。

超参数存在的原因：

- **有时一个选项被设为学习算法不用学习的超参数，是因为它太难优化了。**
- **更多的情况是，该选项必须是超参数，因为它不适合在训练集上学习。** 这适用于控制模型容量的所有超参数。如果在训练集上学习超参数，这些超参数总是趋向于最大可能的模型容量，导致过拟合(见图 5.3)。<span style="color:red;">哇塞，对于这个地方没有过这个认识，嗯，很好。</span>例如，相比低次多项式和正的权重衰减设定，更高次的多项式和权重衰减参数设定 $\lambda=0$ 总能在训练集上更好地拟合。<span style="color:red;">嗯嗯，是呀。</span>


## 那么怎么解决这些不能优化的超参数的更新问题呢？

为了解决这个问题，我们需要一个训练算法观测不到的验证集(validation set)样本。

早先我们讨论过和训练数据相同分布的样本组成的测试集，它可以用来估计学习过程完成之后的学习器的泛化误差。其重点在于测试样本不能以任何形式参与到模型的选择中，包括设定超参数。基于这个原因，测试集中的样本不能用于验证集。

因此，我们总是从训练数据中构建验证集。特别地，我们将训练数据分成两个不相交的子集。其中一个用于学习参数。另一个作为验证集，用于估计训练中或训练后的泛化误差，更新超参数。



# 相关

- 《深度学习》花书
