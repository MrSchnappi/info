---
title: 1.14 去重处理
toc: true
date: 2019-09-20
---
# 可以补充进来的

- 更系统一些。


# 去重处理

以 DataFrame 数据格式为例：

```py
#创建数据，data里包含重复数据
>>> data = pd.DataFrame({'v1':['a']*5+['b']* 4,'v2':[1,2,2,2,3,4,4,5,3]})
>>> data
  v1  v2
0  a   1
1  a   2
2  a   2
3  a   2
4  a   3
5  b   4
6  b   4
7  b   5
8  b   3

#DataFrame的 duplicated 方法返回一个布尔型 Series，表示各行是否是重复行
>>> data.duplicated()
0    False
1    False
2     True
3     True
4    False
5    False
6     True
7    False
8    False
dtype: bool

#drop_duplicates方法用于返回一个移除了重复行的 DataFrame
>>> data.drop_duplicates()
  v1  v2
0  a   1
1  a   2
4  a   3
5  b   4
7  b   5
8  b   3

#这两个方法默认会判断全部列，你也可以指定部分列进行重复项判断。假设你还有一列值，且只希望根据 v1 列过滤重复项：
>>> data['v3']=range(9)
>>> data
  v1  v2  v3
0  a   1   0
1  a   2   1
2  a   2   2
3  a   2   3
4  a   3   4
5  b   4   5
6  b   4   6
7  b   5   7
8  b   3   8
>>> data.drop_duplicates(['v1'])
  v1  v2  v3
0  a   1   0
5  b   4   5

#duplicated和 drop_duplicates默认保留的是第一个出现的值组合。传入 take_last=True则保留最后一个：
>>> data.drop_duplicates(['v1','v2'],take_last = True)
  v1  v2  v3
0  a   1   0
3  a   2   3
4  a   3   4
6  b   4   6
7  b   5   7
8  b   3   8
```


如果数据是列表格式的，有以下几种方法可以删除：


```py
list0=['b','c', 'd','b','c','a','a']

方法 1：使用 set()

list1=sorted(set(list0),key=list0.index) # sorted output
print( list1)

方法 2：使用 {}.fromkeys().keys()

list2={}.fromkeys(list0).keys()
print(list2)

方法 3：set()+sort()

list3=list(set(list0))
list3.sort(key=list0.index)
print(list3)

方法 4：迭代

list4=[]
for i in list0:
    if not i in list4:
        list4.append(i)
print(list4)

方法 5：排序后比较相邻 2 个元素的数据，重复的删除

def sortlist(list0):
    list0.sort()
    last=list0[-1]
    for i in range(len(list0)-2,-1,-1):
        if list0[i]==last:
            list0.remove(list0[i])
        else:
            last=list0[i]
    return list0

print(sortlist(list0))
```


# 相关

- [机器学习基础与实践（一）----数据清洗](https://www.cnblogs.com/charlotte77/p/5606926.html)
