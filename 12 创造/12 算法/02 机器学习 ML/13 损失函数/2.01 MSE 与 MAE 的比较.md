---
title: 2.01 MSE 与 MAE 的比较
toc: true
date: 2019-09-03
---
# MSE 与 MAE 的比较

## MSE对异常点的鲁棒性不够好

简单来说，MSE计算简便，但 MAE 对异常点有更好的鲁棒性。

下面让我们观察 MAE 和 RMSE（即 MSE 的平方根，同 MAE 在同一量级中）在两个例子中的计算结果。


第一个例子中，预测值和真实值很接近，而且误差的方差也较小。第二个例子中，因为存在一个异常点，而导致误差非常大。


<center>

![mark](http://images.iterate.site/blog/image/20190902/huzS44fyeGAF.png?imageslim)


</center>



MSE对误差取了平方（令 e=真实值-预测值），因此若 e>1，则 MSE 会进一步增大误差。如果数据中存在异常点，那么 e 值就会很大，而 $e^{2}$ 则会远大于 $|\mathrm{e}|$。

因此，相对于使用 MAE 计算损失，使用 MSE 的模型会赋予异常点更大的权重。在第二个例子中，用 RMSE 计算损失的模型会以牺牲了其他样本的误差为代价，朝着减小异常点误差的方向更新。然而这就会降低模型的整体性能。

如果训练数据被异常点所污染，那么 MAE 损失就更好用（比如，在训练数据中存在大量错误的反例和正例标记，但是在测试集中没有这个问题）。

直观上可以这样理解：如果我们最小化 MSE 来对所有的样本点只给出一个预测值，那么这个值一定是所有目标值的平均值。但如果是最小化 MAE，那么这个值，则会是所有样本点目标值的中位数。众所周知，对异常值而言，中位数比均值更加鲁棒，因此 MAE 对于异常值也比 MSE 更稳定。


## MAE的问题 更新的梯度始终相同

然而 MAE 存在一个严重的问题（特别是对于神经网络）：更新的梯度始终相同，也就是说，即使对于很小的损失值，梯度也很大。这样不利于模型的学习。为了解决这个缺陷，我们可以使用变化的学习率，在损失接近最小值时降低学习率。

而 MSE 在这种情况下的表现就很好，即便使用固定的学习率也可以有效收敛。MSE损失的梯度随损失增大而增大，而损失趋于 0 时则会减小。这使得在训练结束时，使用 MSE 模型的结果会更精确。


![mark](http://images.iterate.site/blog/image/20190902/a6wKgHTpb1Xl.png?imageslim)



## 如果使用，那么需要注意的

如果异常点代表在商业中很重要的异常情况，并且需要被检测出来，则应选用 MSE 损失函数。相反，如果只把异常值当作受损数据，则应选用 MAE 损失函数。

总而言之，处理异常点时，L1损失函数更稳定，但它的导数不连续，因此求解效率较低。L2损失函数对异常点更敏感，但通过令其导数为 0，可以得到更稳定的封闭解。

## 两种损失函数都无法满足要求的情况

在某些情况下，上述两种损失函数都不能满足需求。例如，若数据中 90%的样本对应的目标值为 150，剩下 10%在 0 到 30 之间。那么使用 MAE 作为损失函数的模型可能会忽视 10%的异常点，而对所有样本的预测值都为 150。

这是因为模型会按中位数来预测。而使用 MSE 的模型则会给出很多介于 0 到 30 的预测值，因为模型会向异常点偏移。上述两种结果在许多商业场景中都是不可取的。

这些情况下应该怎么办呢？

最简单的办法是对目标变量进行变换。而另一种办法则是换一个损失函数，即 Huber 损失函数。




# 相关

- [使用 L1、L2损失的回归模型在有无异常值时的表现](http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/)
