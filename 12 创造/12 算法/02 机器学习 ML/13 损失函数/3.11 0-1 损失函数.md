---
title: 3.11 0-1 损失函数
toc: true
date: 2019-09-03
---
# 0-1 损失函数

主要应用场景：

- 二分类问题。


0-1 Loss 是最简单也是最容易直观理解的一种损失函数。对于二分类问题，如果预测类别 $\hat{y}$ 与真实类别 $y$ 不同，则 $L=1$；如果预测类别 $\hat{y}$ 与 真实类别 $y$ 相同，则 $L=0$（$L$ 表示损失函数）。



0-1 Loss 的表达式为：

$$
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}
$$

一般的在实际使用中，相等的条件过于严格，可适当放宽条件：

$$
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}
$$



## 曲线

0-1 Loss 的曲线如下图所示：


![mark](http://images.iterate.site/blog/image/20190902/JQb8uyG1g92S.png?imageslim)


## 缺点

0-1 Loss 的特点就是非常直观容易理解。但是它存在两个缺点：

- 0-1 Loss 对每个错分类点都施以相同的惩罚（损失为 1），这样对犯错比较大的点（ys 远小于 0）无法进行较大的惩罚，所有犯错点都同等看待，这不符合常理，不太合适。
- 0-1 Loss 不连续、非凸、不可导，难以使用梯度优化算法。

因此，实际应用中，0-1 Loss 很少使用。



# 相关

- [确定不收藏？机器学习必备的分类损失函数速查手册](https://redstonewill.com/1584/)
