---
title: 1.08 对单个学习器泛化性能的假设进行检验
toc: true
date: 2019-08-27
---

# 对单个学习器泛化性能的假设进行检验

## 假设检验

假设检验中的 “假设” 是对学习器泛化错误率分布的某种判断或猜想，例如 “ $\epsilon=\epsilon_0$ ”。现实任务中我们并不知道学习器的泛化错误率，只能获知其测试错误率 $\cap{\epsilon}$  ，泛化错误率与测试错误率未必相同，但直观上，二者接近的可能性应比较大，相差很远的可能性比较小。因此，我们可以根据测试错误率估推出泛化错误率的分布.

泛化错误率为 $\epsilon$ 的学习器在一个样本上犯错的概率是 $\epsilon$ ；测试错误率 $\cap{\epsilon}$  意味着在 m 个测试样本中恰有 $\cap{\epsilon}* m$ 个被误分类。假定测试样本是从样本总体分布中独立采样而得，那么泛化错误率为 $\epsilon$ 的学习器将其中 m' 个样本误分类、其 余样本全都分类正确的概率是 $\epsilon^{m'}(1-\epsilon)^{m-m'}$ ；由此可估算出其恰将 $\cap{\epsilon}* m$ 个样本误分类的概率如下式所示，这也表达了在包含 m 个样本的测试集上，泛化错误率为 $\epsilon$ 的学习器被测得测试错误率为 $\cap{\epsilon}$  的概率：

$$
P(\hat{\epsilon} ; \epsilon)=\left(\begin{array}{c}{m} \\ {\hat{\epsilon} \times m}\end{array}\right) \epsilon^{\hat{\epsilon} \times m}(1-\epsilon)^{m-\hat{\epsilon} \times m}
$$
给定测试错误率，则解 $\partial P(\cap{\epsilon};\epsilon)/\partial \epsilon=0$ 可知，$P(\cap{\epsilon};\epsilon)$ 在 $\epsilon=\cap{\epsilon}$ 时最大，$|\epsilon-\cap{\epsilon}|$ 增大时 $P(\cap{\epsilon};\epsilon)$ 减小。这符合二项(binomial)分布，如下图所示，若 $\epsilon =0.3$ ，则 10 个样本中测得 3 个被误分类的概率最大。


二项分布示意图（m=10,$\epsilon$ =0.3）：（$\alpha$ 的常用取值有 0.05、0.1 ，图中 $\alpha$ 较大是为了绘图方便）

<center>

![](http://images.iterate.site/blog/image/180727/aaliELa3ae.png?imageslim){ width=55% }


</center>


我们可使用 “二项检验” (binomial test) 来对 $\epsilon \leq 0.3$  （即“泛化错误率是否不大于 0.3” ) 这样的假设进行检验。更一般的，考虑假设 $\epsilon \leq \epsilon_0$ ，则在 $1-\alpha$ 的概率内所能观测到的最大错误率如下式计算。这里 $1-\alpha$ 反映了结论的 “置信度” (confidence)，直观地来看，相应于上图中非阴影部分的范围：



$$
\overline{\epsilon}=\max \epsilon \quad \text { s.t. } \quad \sum_{i=\epsilon_{0} \times m+1}^{m}\left(\begin{array}{c}{m} \\ {i}\end{array}\right) \epsilon^{i}(1-\epsilon)^{m-i}<\alpha
$$


注：s.t. 是 “subject to” 的简写，使左边式子在右边条件满足时成立。



此时若测试错误率 $\cap{\epsilon}$  小于临界值 $\overline{\epsilon}$  ，则根据二项检验可得出结论：在 $\alpha$ 的显著度 下，假设 $\epsilon \leq \epsilon_0$ 不能被拒绝，即能以 $1-\alpha$ 的置信度认为，学习器的泛化错误率不大于 $\epsilon_0$；否则该假设可被拒绝，即在 $\alpha$ 的显著度下可认为学习器的泛化错误率大于 $\epsilon_0$。



在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是交叉验证法等进行多次训练/测试，这样会得到多个测试错误率，此时可使用 “t检验”（t-test）。假定我们得到了 k 个测试错误率，$\cap{\epsilon_1},\cap{\epsilon_2},\cdots ,\cap{\epsilon_k}$，则平均测试错误率 $\mu$ 和方差 $\sigma^2$ 为：

$$
\mu=\frac{1}{k} \sum_{i=1}^{k} \hat{\epsilon}_{i}
$$
$$
\sigma^{2}=\frac{1}{k-1} \sum_{i=1}^{k}\left(\hat{\epsilon}_{i}-\mu\right)^{2}
$$


考虑到这 k 个测试错误率可看作泛化错误率 $\epsilon_0$ 的独立采样，则变量：

$$
\tau_{t}=\frac{\sqrt{k}\left(\mu-\epsilon_{0}\right)}{\sigma}
$$

服从自由度为 t-1 的 t 分布，如下图所示：


<center>

![](http://images.iterate.site/blog/image/180727/f5Ac9fIA53.png?imageslim){ width=55% }

</center>

对假设 $\mu=\epsilon_0$ 和显著度 $\alpha$ ，我们可计算出当测试错误率均值为 $\epsilon_0$ 时，在  $1-\alpha$ 概率内能观测到的最大错误率，即临界值。这里考虑双边（two-tailed）假设，如上图所示，两边阴影部分各有 $\alpha/2$ 的面积；假定阴影部分范围分别为 $[-\infty,t_{-\alpha/2}]$ 和 $[t_{\alpha/2},\infty]$ 。若平均错误率 $mu$ 与 $\epsilon_0$ 之差 $|\mu-\epsilon_0|$ 位于临界值范围 $[t_{-\alpha/2},t_{\alpha/2}]$ 内，则不能拒绝假设 “ $\mu=\epsilon_0$ ”，即可认为泛化错误率为 $\epsilon_0$ ，置信度为 $1-\alpha$ ，否则可拒绝该假设，即在该显著度下可认为泛化错误率与 $\epsilon_0$ 有显著不同。$\alpha$ 常用取值有 0.05 和 0.1 。下表给出了一些常用临界值：


<center>

![](http://images.iterate.site/blog/image/180727/iHfl8Hcela.png?imageslim){ width=55% }

</center>

上面介绍的两种方法都是对关于单个学习器泛化性能的假设进行检验，而在现实任务中，更多时候我们需对不同学习器的性能进行比较，下面将介绍适用于此类情况的假设检验方法.




# 相关

- 《机器学习》周志华
