---
title: 2.05 从线性回归到广义线性模型
toc: true
date: 2018-07-30 20:03:56
---

# 可以补充进来的

- 从回归里面把加入扰动的部分拿进来 <span style="color:red;">有加入扰动的部分吗？</span>
- 实际中真的会用到广义线性模型吗？广义线性模型的联系函数是怎么确定的？


# 从线性回归到广义线性模型

嗯，其实，到上面这里，线性回归的主要东西就已经都讲了。

那么，我们现在继续想一下：

线性模型虽简单，其实却有可以有丰富的变化的，例如对于样例 $(\boldsymbol{x}, y), y \in \mathbb{R}$，之前我们想让预测值逼近真实标记 $y$ 的时候， 就得到了线性回归模型：

$$
y=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\tag{3.13}
$$

OK，那么可否令模型预测值逼近 $y$ 的衍生物呢？比如 $lny$ ？OK，我们先假设样本的目标 $y$ 实际上是在指数尺度上变化的，那么，我们就可以将输出标记的对数作为线性模型逼近的目标 ，即：<span style="color:red;">为什么可以这么假定？即使从领域知识也不能得出这样的假定吧？</span>

$$
\ln y=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\tag{3.14}
$$

而这，就是 "对数线性回归" (log-linear regression) ，它实际上是在试图让 $e^{\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b}$ 逼近 $y$。实际上，上面这个式子虽然在形式上仍是线性回归，但实质上已经是在求取输入空间到输出空间的非线性函数映射了，如图所示：<span style="color:red;">是的，的确是输入空间到输出空间的非线性映射。</span>

<center>

![](http://images.iterate.site/blog/image/180625/42bCB3hLib.png){ width=55% }

</center>


而这里面的对数函数则起到了将线性回归模型的预测值与真实标记联系起来的作用。<span style="color:red;">厉害呀，但是，怎么能从一开始就知道要加上这个对数函数？</span>

更一般地，考虑单调可微函数 $g(\cdot )$， $g(\cdot )$ 连续且充分光滑
令：<span style="color:red;">为什么一定是一个单调可微函数呢？</span>

$$
y=g^{-1}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right)\tag{3.15}
$$

这样得到的模型称为 "广义线性模型" (generalized linear model)，其中 函数 $g(\cdot )$ 称为"联系函数" (link funtin)。显然，对数线性回归是广义线性模型在 $g(\cdot )=ln(\cdot )$ 时的特例。<span style="color:red;">嗯，是的，这样的广义线性模型威力还是很大的感觉，但是这种联系函数我们在一开始的时候怎么知道呢？</span>

注：广义线性模型的参数估计常通过加权最小二乘法或极大似然法进行。<span style="color:red;">厉害了，要总结下，而且，什么是加权最小二乘法？到底要怎么计算广义线性模型的参数估计？</span>








# 相关

- 《机器学习》周志华
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)
