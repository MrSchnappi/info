---
title: 6.02 EM 算法
toc: true
date: 2019-05-26
---
# EM 算法


最大期望算法

Expectation-maximization algorithm

在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中，参数的最大似然估计。

在统计计算中，最大期望（EM）算法是在概率（Probabilistic）模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量（Latent Variable）。最大期望经常用在机器学习和计算机视觉的数据聚类（Data Clustering）领域。最大期望算法经过两个步骤交替进行计算，第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；第二步是最大化（M），最大化在 E 上求得的最大似然值来计算参数的值。M上找到的参数估计值被用于下一个 E 计算中，这个过程不断交替进行



<span style="color:red;">最大期望（EM）算法 之前一直有看过，老师也讲过，但是还是感觉没有很清楚，自己在总结下。</span>





（6.1）EM算法
EM（期望最大化）算法通过不断改变簇属性值的隶属度来获得逐步优化的簇。1997 年，Mitchell 等人提出。
EM算法：
算法：EM算法
（1）选择模型参数的初始集（随机选择）
（2）Repeat
（3）期望步：对于每个对象，计算每个对象属于每个分布的概率，即计算
（4）最大化步：给定期望步得到的概率，找出最大化该期望似然的新的参数估计。
（5）Until参数不再变化
其中， 是第 j 个分布产生一个对象的概率， 是对象 来自第 j 个分布的概率，K个分布，m个对象， 是第 j 个分布的参数， 是所有参数的集合。
EM算法特点：
可以使用合适的统计模型来捕获潜在簇，并且非常简洁，广泛应用于处理数据挖掘和统计学中的学习问题。然而，EM算法可能收敛不到最优解，而是收敛到局部极大点。
EM算法针对不同模型，高斯混合模型可以看成 EM 算法的一个现实中的应用。并且它的 R 实现：在 mclust 包中有该算法的实现——Mclust（）
（高斯混合模型就是用高斯概率密度函数（正态分布曲线）精确地量化事物，它是一个将事物分解为若干的基于高斯概率密度函数（正态分布曲线）形成的模型。
所谓混合高斯模型（GMM）就是指对样本的概率密度分布进行估计，而估计采用的模型（训练模型）是几个高斯模型的加权和（具体是几个要在模型训练前建立好）。每个高斯模型就代表了一个类（一个 Cluster）。对样本中的数据分别在几个高斯模型上投影，就会分别得到在各个类上的概率。然后我们可以选取概率最大的类所为判决结果。

    从中心极限定理的角度上看，把混合模型假设为高斯的是比较合理的，当然，也可以根据实际数据定义成任何分布的 Mixture Model，不过定义为高斯的在计算上有一些方便之处，另外，理论上可以通过增加 Model 的个数，用 GMM 近似任何概率分布。）



# 相关


- [聚类算法总结 划分法，层次聚类，基于网格，基于密度，谱聚类，基于模型，模糊聚类](https://blog.csdn.net/qq_29258361/article/details/79536444)
