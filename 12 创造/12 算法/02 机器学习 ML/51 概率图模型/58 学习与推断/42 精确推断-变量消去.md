---
title: 42 精确推断-变量消去
toc: true
date: 2019-08-27
---

## 1变量消去

精确推断的实质是一类动态规划算法，它利用图模型所描述的条件独立性 来削减计算目标概率值所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础.

<center>

![](http://images.iterate.site/blog/image/180701/KcCGK66gIc.png?imageslim){ width=55% }


</center>

我们先以图 14.7（a）中的有向图模型为例来介绍其工作流程.

假定推断目标是计算边际概率 $P(x_5)$ 。显然，为了完成此目标，只需通过加 法消去变量 $\{x_1,x_2,x_3,x_4\}$ 即

$$
\begin{aligned} P\left(x_{5}\right) &=\sum_{x_{4}} \sum_{x_{3}} \sum_{x_{2}} \sum_{x_{1}} P\left(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}\right) \\ &=\sum_{x_{4}} \sum_{x_{3}} \sum_{x_{2}} \sum_{x_{1}} P\left(x_{1}\right) P\left(x_{2} | x_{1}\right) P\left(x_{3} | x_{2}\right) P\left(x_{4} | x_{3}\right) P\left(x_{5} | x_{3}\right) \end{aligned}
$$
不难发现，若采用 $\{x_1,x_2,x_4,x_3\}$ 的顺序计算加法，则有

$$
\begin{aligned} P\left(x_{5}\right) &=\sum_{x_{3}} P\left(x_{5} | x_{3}\right) \sum_{x_{4}} P\left(x_{4} | x_{3}\right) \sum_{x_{2}} P\left(x_{3} | x_{2}\right) \sum_{x_{1}} P\left(x_{1}\right) P\left(x_{2} | x_{1}\right) \\ &=\sum_{x_{3}} P\left(x_{5} | x_{3}\right) \sum_{x_{4}} P\left(x_{4} | x_{3}\right) \sum_{x_{2}} P\left(x_{3} | x_{2}\right) m_{12}\left(x_{2}\right) \end{aligned}
$$

其中 $m_{ij}(x_j)$ 是求加过程的中间结果，下标 $i$ 表示此项是对 $x_i$ 求加的结果，下标 j 表示此项中剩下的其他变量。显然，$m_{ij}(x_j)$ 是关于 $x_j$ 的函数。不断执行此过程可得

$$
\begin{aligned} P\left(x_{5}\right) &=\sum_{x_{3}} P\left(x_{5} | x_{3}\right) \sum_{x_{4}} P\left(x_{4} | x_{3}\right) m_{23}\left(x_{3}\right) \\ &=\sum_{x_{3}} P\left(x_{5} | x_{3}\right) m_{23}\left(x_{3}\right) \sum_{x_{4}} P\left(x_{4} | x_{3}\right) \\ &=\sum_{x_{3}} P\left(x_{5} | x_{3}\right) m_{23}\left(x_{3}\right) m_{43}\left(x_{3}\right) \\ &=m_{35}\left(x_{5}\right) \end{aligned}
$$


显然，最后的 $m_{35}(x_5)$ 是关于 $x_5$ 的函数，仅与变量 $x_5$ 的取值有关.

事实上，上述方法对无向图模型同样适用。不妨忽略图 14.7(a)中的箭头，将其看作一个无向图模型，有

$$
P\left(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}\right)=\frac{1}{Z} \psi_{12}\left(x_{1}, x_{2}\right) \psi_{23}\left(x_{2}, x_{3}\right) \psi_{34}\left(x_{3}, x_{4}\right) \psi_{35}\left(x_{3}, x_{5}\right)
$$

其中 $Z$ 为规范化因子。边际分布 $P(x_5)$ 可这样计算：

$$
\begin{aligned} P\left(x_{5}\right) &=\frac{1}{Z} \sum_{x_{3}} \psi_{35}\left(x_{3}, x_{5}\right) \sum_{x_{4}} \psi_{34}\left(x_{3}, x_{4}\right) \sum_{x_{2}} \psi_{23}\left(x_{2}, x_{3}\right) \sum_{x_{1}} \psi_{12}\left(x_{1}, x_{2}\right) \\ &=\frac{1}{Z} \sum_{x_{3}} \psi_{35}\left(x_{3}, x_{5}\right) \sum_{x_{4}} \psi_{34}\left(x_{3}, x_{4}\right) \sum_{x_{2}} \psi_{23}\left(x_{2}, x_{3}\right) m_{12}\left(x_{2}\right) \\ &=\cdots \\ &=\frac{1}{Z} m_{35}\left(x_{5}\right) \end{aligned}
$$

显然，通过利用乘法对加法的分配律，变量消去法把多个变量的积的求和 问题，转化为对部分变量交替进行求积与求和的问题。这种转化使得每次的求 和与求积运算限制在局部，仅与部分变量有关，从而简化了计算.

变量消去法有一个明显的缺点：若需计算多个边际分布，重复使用变量 消去法将会造成大量的冗余计算。例如在图 14.7(a)的贝叶斯网上，假定在计 算 $P(x_5)$ 之外还希望计算 $P(x_4)$ ，若采用 $\{x_1,x_2,x_5,x_3\}$ 的顺序，则 $m_{12}(x_2)$ 和 $m_{23}(x_3)$ 的计算是重复的.
