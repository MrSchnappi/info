---
title: 44 近似推断-采样
toc: true
date: 2019-08-27
---

## MCMC 采样

在很多任务中，我们关心某些概率分布并非因为对这些概率分布本身感兴趣，而是要基于它们计算某些期望，并且还可能进一步基于这些期望做出决策。 例如对图 14.7(a)的贝叶斯网，进行推断的目的可能是为了计算变量 $x_5$ 的期望。 若直接计算或逼近这个期望比推断概率分布更容易，则直接操作无疑将使推断问题的求解更为高效。

采样法正是基于这个思路。具体来说，假定我们的目标是计算函数 $f(x)$ 在概率密度函数 $p(x)$ 下的期望

$$
\mathbb{E}_{p}[f]=\int f(x) p(x) d x\tag{14.21}
$$

则可根据 $p(X)$ 抽取一组样本 $\{x_1,x_2,\cdots ,x_N\}$ 。然后计算 $f(x)$ 在这些样本上的均值

$$
\hat{f}=\frac{1}{N} \sum_{i=1}^{N} f\left(x_{i}\right)\tag{14.22}
$$

以此来近似目标期望 $\mathbb{E}[f]$ 。若样本 $\{x_1,x_2,\cdots,x_N\}$ 独立，基于大数定律，这种通过大量采样的办法就能获得较高的近似精度。问题的关键是如何采样。对概率图模型来说，就是如何高效地基于图模型所描述的概率分布来获取样本。

概率图模型中最常用的采样技术是马尔可夫链蒙特卡罗(Markov Chain Monte Carlo，简称 MCMC)方法。给定连续变量 $x \in X$ 的槪率密度函数 $p(x)$, $x$ 在区间 $A$ 中的概率计算为

$$
P(A)=\int_{A} p(x) d x\tag{14.23}
$$

若有函数 $f:X\mapsto \mathbb{R}$ ，则可计算 $f(x)$ 的期望

$$
p(f)=\mathbb{E}_{p}[f(X)]=\int_{x} f(x) p(x) d x\tag{14.24}
$$

若 $x$ 不是单变量而是一个高维多元变量 $\mathbf{x}$，且服从一个非常复杂的分布，则对式(14.24)求积分通常很困难。为此，MCMC先构造出服从 $p$ 分布的独立同分布随机变量 $\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{N}$ ，再得到式(14.24)的无偏估计

$$
\tilde{p}(f)=\frac{1}{N} \sum_{i=1}^{N} f\left(\mathbf{x}_{i}\right)\tag{14.25}
$$

然而，若概率密度函数 $p(\mathbf{x})$ 很复杂，则构造服从 $p$ 分布的独立同分布样本也很困难。MCMC方法的关键就在于通过构造“平稳分布为 $p$ 的马尔可夫链” 来产生样本：若马尔可夫链运行时间足够长(即收敛到平稳状态)，则此时产出 的样本 $\mathbf{x}$ 近似服从于分布 $p$ 。如何判断马尔可夫链到达平稳状态呢？假定平稳马尔可夫链 $T$ 的状态转移概率(即从状态 $\mathbf{x}$ 转移到状态 $\mathbf{x}'$ 的概率)为 $T\left(\mathbf{x}^{\prime} | \mathbf{x}\right)$ , $t$ 时刻状态的分布为 $p\left(\mathbf{x}^{t}\right)$，则若在某个时刻马尔可夫链满足平稳条件

$$
p\left(\mathbf{x}^{t}\right) T\left(\mathbf{x}^{t-1} | \mathbf{x}^{t}\right)=p\left(\mathbf{x}^{t-1}\right) T\left(\mathbf{x}^{t} | \mathbf{x}^{t-1}\right)\tag{14.26}
$$

>
> $$p(x^t)T(x^{t-1}|x^t)=p(x^{t-1})T(x^t|x^{t-1})$$
>
> [解析]：假设变量 $x$ 所在的空间有 $n$ 个状态($s_1,s_2,..,s_n$), 定义在该空间上的一个转移矩阵 $T(n\times n)$ 如果满足一定的条件则该马尔可夫过程存在一个稳态分布 $\pi$, 使得
> $$
> \begin{aligned}
> \pi T=\pi
> \end{aligned}
> \tag{1}
> $$
> 其中, $\pi$ 是一个是一个 $n$ 维向量，代表​$s_1,s_2,..,s_n$ 对应的概率. 反过来, 如果我们希望采样得到符合某个分布​$\pi$ 的一系列变量​$x_1,x_2,..,x_t$, 应当采用哪一个转移矩阵​$T(n\times n)​$ 呢？
>
> 事实上，转移矩阵只需要满足马尔可夫细致平稳条件
> $$
> \begin{aligned}
> \pi (i)T(i,j)=\pi (j)T(j,i)
> \end{aligned}
> \tag{2}
> $$
> 即公式 $14.26​$，这里采用的符号与西瓜书略有区别以便于理解.  证明如下
> $$
> \begin{aligned}
> \pi T(j) = \sum _i \pi (i)T(i,j) = \sum _i \pi (j)T(j,i) = \pi(j)
> \end{aligned}
> \tag{3}
> $$
> 假设采样得到的序列为 $x_1,x_2,..,x_{t-1},x_t$，则可以使用 $MH$ 算法来使得 $x_{t-1}$(假设为状态 $s_i$)转移到 $x_t$(假设为状态 $s_j$)的概率满足式 $(2)$.


则 $p(\mathbf{x})$ 是该马尔可夫链的平稳分布，且马尔可夫链在满足该条件时已收敛到平 稳状态。

也就是说，MCMC方法先设法构造一条马尔可夫链，使其收敛至平稳分布恰为待估计参数的后验分布，然后通过这条马尔可夫链来产生符合后验分布的 样本，并基于这些样本来进行估计。这里马尔可夫链转移概率的构造至关重要， 不同的构造方法将产生不同的 MCMC 算法。


Metropolis-Hastings (简称 MH)算法是 MCMC 的重要代表。它基于“拒绝采样” (reject sampling) 来逼近平稳分布 $p$ 。如图 14.9所示，算法每次根据上一轮采样结果 $\mathbf{x}^{t-1}$ 来采样获得候选状态样本 $\mathbf{x}^{*}$ ，但这个候选样本会以一定的概率被“拒绝”掉。假定从状态 $\mathbf{x}^{t-1}$ 到状态的转移概率为 $Q\left(\mathbf{x}^{*} |\right.\mathbf{x}^{t-1} ) A\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)$ ，其中 $Q\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)$ 是用户给定的先验概率，$A\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)$ 是  $\mathbf{x}^{*}$  被接受的概率。若 $\mathbf{x}^{*}$ 最终收敛到平稳状态，则根据式(14.26)有

$$
p\left(\mathbf{x}^{t-1}\right) Q\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right) A\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)=p\left(\mathbf{x}^{*}\right) Q\left(\mathbf{x}^{t-1} | \mathbf{x}^{*}\right) A\left(\mathbf{x}^{t-1} | \mathbf{x}^{*}\right)\tag{14.27}
$$

<center>

![](http://images.iterate.site/blog/image/180701/B7DJfdd7e8.png?imageslim){ width=55% }

</center>

于是，为了达到平稳状态，只需将接受率设置为

$$
A\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)=\min \left(1, \frac{p\left(\mathbf{x}^{*}\right) Q\left(\mathbf{x}^{t-1} | \mathbf{x}^{*}\right)}{p\left(\mathbf{x}^{t-1}\right) Q\left(\mathbf{x}^{*} | \mathbf{x}^{t-1}\right)}\right)\tag{14.28}
$$

>
> $$A(x^* | x^{t-1}) = \min\left ( 1,\frac{p(x^*)Q(x^{t-1} | x^*) }{p(x^{t-1})Q(x^* | x^{t-1})} \right )$$
>
> [推导]：这个公式其实是拒绝采样的一个 trick，因为基于式 $14.27​$ 只需要
> $$
> \begin{aligned}
>   A(x^* | x^{t-1}) &= p(x^*)Q(x^{t-1} | x^*)  \\
>   A(x^{t-1} | x^*) &= p(x^{t-1})Q(x^* | x^{t-1})
>  \end{aligned}
>  \tag{4}
> $$
> 即可满足式 $14.26$，但是实际上等号右边的数值可能比较小，比如各为 0.1和 0.2，那么好不容易才到的样本只有百分之十几得到利用，所以不妨将接受率设为 0.5和 1，则细致平稳分布条件依然满足，样本利用率大大提高, 所以可以将 $(4)$ 改进为
> $$
> \begin{aligned}
> A(x^* | x^{t-1}) &=  \frac{p(x^*)Q(x^{t-1} | x^*)}{norm}  \\
> A(x^{t-1} | x^*) &= \frac{p(x^{t-1})Q(x^* | x^{t-1}) }{norm}
> \end{aligned}
> \tag{5}
> $$
> 其中
> $$
> \begin{aligned}
> norm = \max\left (p(x^{t-1})Q(x^* | x^{t-1}),p(x^*)Q(x^{t-1} | x^*) \right )
> \end{aligned}
> \tag{6}
> $$
> 即教材的 $14.28​$.


吉布斯采样(Gibbs sampling)有时被视为 MH 算法的特例，它也使用马尔可夫链获取样本，而该马尔可夫链的平稳分布也是采样的目标分布 $p(\mathbf{x})$ 。具体 来说，假定 $\mathbf{x}=\left\{x_{1}, x_{2}, \dots, x_{N}\right\}$ ，目标分布为 $p(\mathbf{x})$，在初始化 $\mathbf{x}$ 的取值后，通过 循环执行以下步骤来完成采样：

1. 随机或以某个次序选取某变量 $x_i$
2. 根据 $\mathbf{x}$ 中除 $x_i$ 外的变量的现有取值，计算条件概率 $p(x_i|\mathbf{x}_{\overline{i} })$ ，其中 $\mathbf{x}_{\overline{i} }=\{x_1,x_2,\cdots,x_{i-1},x_{i+1},\cdots,x_N\}$ ;
3. 根据 $p(x_i|\mathbf{x}_{\overline{i} })$ 对变量 $x_i$ 采样，用采样值代替原值。
