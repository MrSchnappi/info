---
title: 7.11 理解 Dropout 正则化
toc: true
date: 2019-09-03
---

# 理解 dropout 正则化

<span style="color:red;">重新总结下。</span>

​Dropout 可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？

​直观上理解：

- 不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和之前讲的 L2 正则化类似；<span style="color:red;">没理解，单元的四个输入增加一点权重？</span>
- 实施 dropout 的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；<span style="color:red;">完成一些预防过拟合的外层正则化，是什么？</span>
- L2 对不同权重的衰减是不同的，它取决于激活函数倍增的大小。<span style="color:red;">什么倍增的大小？</span>
