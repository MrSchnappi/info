---
title: 海量数据算法
toc: true
date: 2018-08-03 14:15:53
---
> 关于海量数据处理问题，通过最近的面试可以看出这是一个经常会问的问题。本篇文章基于实际的面试问题，总结关于海量数据处理的常用算法以及针对这些实际面试问题提出解决方案。


### 一、海量数据处理

所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，**就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。**

##### 那解决办法呢?

针对时间，我们可以采用巧妙的算法搭配合适的数据结构，如 Bloom filter/Hash/bit-map/堆/trie树。

针对空间，无非就一个办法：大而化小，分而治之（hash映射）。

### 二、算法/数据结构基础

#### 1.Bloom Filter

Bloom Filter（BF）是一种空间效率很高的随机数据结构，**它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。**它是一个判断元素是否存在集合的快速的概率算法。Bloom Filter有可能**会出现错误判断，但不会漏掉判断。**也就是 Bloom Filter**判断元素不再集合，那肯定不在。如果判断元素存在集合中，有一定的概率判断错误。**因此，Bloom Filter不适合那些“零错误”的应用场合。
 而在能容忍低错误率的应用场合下，Bloom Filter比其他常见的算法（如 hash，折半查找）极大节省了空间。

##### 适用范围

可以用来实现数据字典，进行数据的判重，或者集合求交集

具体参考：[海量数据处理之 Bloom Filter详解](https://link.jianshu.com?t=http://blog.csdn.net/v_july_v/article/details/6685894)

#### 2.Hash

Hash，一般翻译做“散列”，也有直接音译为“哈希”的，就是**把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。**这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。

具体参考：[十一、从头到尾解析 Hash 表算法](https://link.jianshu.com?t=http://blog.csdn.net/v_july_v/article/details/6256463)

#### 3. Bit-map

所谓的 Bit-map就是用一个 bit 位来标记某个元素对应的值。由于采用了 Bit 为单位来存储数据，因此在存储空间方面，可以大大节省。

![](http://images.iterate.site/blog/image/180803/3B50kdIhhD.png?imageslim){ width=55% }

然后遍历这 5 个元素，首先第一个元素是 4，那么就把 4 对应的位置为 1（可以这样操作 p+(i/8)|(0x01<<(i%8)) 当然了这里的操作涉及到 Big-ending和 Little-ending的情况，这里默认为 Big-ending），因为是从零开始的，所以要把第五位置为一（如下图）：

![](http://images.iterate.site/blog/image/180803/a12KLlH79e.png?imageslim){ width=55% }

![](http://images.iterate.site/blog/image/180803/8flFK2hfBD.png?imageslim){ width=55% }

具体参考：[数据结构：位图法](https://link.jianshu.com?t=http://blog.csdn.net/wypblog/article/details/8237956)

#### 4.堆

堆是一种特殊的二叉树，具备以下两种性质
 1）每个节点的值都大于（或者都小于，称为最小堆）其子节点的值
 2）树是完全平衡的，并且最后一层的树叶都在最左边这样就定义了一个最大堆。
 如下图用一个数组来表示堆：

![](http://images.iterate.site/blog/image/180803/amBfCLEHbB.png?imageslim){ width=55% }

#### 5.trie树

下面我们有 and,as,at,cn,com这些关键词，那么如何构建 trie 树呢？

![](http://images.iterate.site/blog/image/180803/8H30acmiAD.png?imageslim){ width=55% }


从上面的图中，我们或多或少的可以发现一些好玩的特性。

第一：根节点不包含字符，除根节点外的每一个子节点都包含一个字符。

第二：从根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串。

第三：每个单词的公共前缀作为一个字符节点保存。

**适用范围：**

前缀统计，词频统计。

具体参考：[6天通吃树结构—— 第五天 Trie树](https://link.jianshu.com?t=http://www.cnblogs.com/huangxincheng/archive/2012/11/25/2788268.html)

#### 6.外排序

**适用范围：**

大数据的排序，去重

** 基本原理及要点：**

外部排序的两个独立阶段：

1）首先按内存大小，将外存上含 n 个记录的文件分成若干长度 L 的子文件或段。依次读入内存并利用有效的内部排序对他们进行排序，并将排序后得到的有序字文件重新写入外存，通常称这些子文件为归并段。

2）对这些归并段进行逐趟归并，使归并段逐渐由小到大，直至得到整个有序文件为之。

外排序的优化方法：置换选择 败者树原理，最优归并树

具体参考：[选择置换+败者树搞定外部排序](https://link.jianshu.com?t=http://www.cnblogs.com/benjamin-t/p/3325401.html)

### 三、面试问题解决

##### ①、海量日志数据，提取出某日访问百度次数最多的那个 IP。

**算法思想：分而治之+Hash**

1.IP地址最多有 2^32=4G种取值情况，所以不能完全加载到内存中处理；
 2.可以考虑采用“分而治之”的思想，按照 IP 地址的 Hash(IP)%1024值，把海量 IP 日志分别存储到 1024 个小文件中。这样，每个小文件最多包含 4MB 个 IP 地址；
 3.对于每一个小文件，可以构建一个 IP 为 key，出现次数为 value 的 Hash map，同时记录当前出现次数最多的那个 IP 地址；
 4.可以得到 1024 个小文件中的出现次数最多的 IP，再依据常规的排序算法得到总体上出现次数最多的 IP；

##### ②、 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为 1-255字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是 1 千万，但如果除去重复后，不超过 3 百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的 10 个查询串，要求使用的内存不能超过 1G。

**可以在内存中处理，典型的 Top K算法**

**算法思想：hashmap+堆**

1.先对这批海量数据预处理，在 O（N）的时间内用 Hash 表完成**统计**；
 2.借助堆这个数据结构，找出 Top K，时间复杂度为 O(N*logK)。

或者：采用 trie 树，关键字域存该查询串出现的次数，没有出现为 0。最后用 10 个元素的最小推来对出现频率进行排序。

##### ③、有一个 1G 大小的一个文件，里面每一行是一个词，词的大小不超过 16 字节，内存限制大小是 1M。返回频数最高的 100 个词。

**算法思想：分而治之 + hash统计 + 堆排序**

1.顺序读文件中，对于每个词 x，取 hash(x)%5000，然后按照该值存到 5000 个小文件（记为 x0,x1,...x4999）中。这样每个文件大概是 200k 左右。如果其中的有的文件超过了 1M 大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过 1M。

2.对每个小文件，采用 trie 树/hash_map等统计每个文件中出现的词以及相应的频率。

3.取出出现频率最大的 100 个词（可以用含 100 个结点的最小堆）后，再把 100 个词及相应的频率存入文件，这样又得到了 5000 个文件。最后就是把这 5000 个文件进行归并（类似于归并排序）的过程了。

##### ④、有 10 个文件，每个文件 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求你按照 query 的频度排序。

**方案 1：**

**算法思想：分而治之 + hash统计 + 堆排序**

顺序读取 10 个文件，按照 hash(query)%10的结果将 query 写入到另外 10 个文件中。这样新生成的文件每个的大小大约也 1G，大于 1G 继续按照上述思路分。

找一台内存在 2G 左右的机器，依次对用 hash_map(query, query_count)来统计每个 query 出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的 query 和对应的 query_cout输出到文件中。这样得到了 10 个排好序的文件（记为）。

对这 10 个文件进行归并排序（内排序与外排序相结合）。

**方案 2：**

**算法思想：hashmap+堆**

一般 query 的总量是有限的，只是重复的次数比较多而已，可能对于所有的 query，一次性就可以加入到内存了。这样，我们就可以采用 trie 树/hash_map等直接来统计每个 query 出现的次数，然后按出现次数做快速/堆/归并排序就可以了。

##### ⑤、 给定 a、b两个文件，各存放 50 亿个 url，每个 url 各占 64 字节，内存限制是 4G，让你找出 a、b文件共同的 url

**方案 1：**可以估计每个文件安的大小为 5G×64=320G，远远大于内存限制的 4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。

**算法思想：分而治之 + hash统计 **

遍历文件 a，对每个 url 求取 hash(url)%1000，然后根据所取得的值将 url 分别存储到 1000 个小文件（记为 a0,a1,...,a999）中。这样每个小文件的大约为 300M。

遍历文件 b，采取和 a 相同的方式将 url 分别存储到 1000 小文件（记为 b0,b1,...,b999）。这样处理后，所有可能相同的 url 都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的 url。然后我们只要求出 1000 对小文件中相同的 url 即可。

求每对小文件中相同的 url 时，可以把其中一个小文件的 url 存储到 hash_set中。然后遍历另一个小文件的每个 url，看其是否在刚才构建的 hash_set中，如果是，那么就是共同的 url，存到文件里面就可以了。

**方案 2：**如果允许有一定的错误率，可以使用 Bloom filter，4G内存大概可以表示 340 亿 bit。将其中一个文件中的 url 使用 Bloom filter映射为这 340 亿 bit，然后挨个读取另外一个文件的 url，检查是否与 Bloom filter，如果是，那么该 url 应该是共同的 url（注意会有一定的错误率）。

##### ⑥、在 2.5亿个整数中找出不重复的整数，注，内存不足以容纳这 2.5亿个整数。

采用 2-Bitmap（每个数分配 2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存 2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这 2.5亿个整数，查看 Bitmap 中相对应位，如果是 00 变 01，01变 10，10保持不变。所描完事后，查看 bitmap，把对应位是 01 的整数输出即可。

##### ⑦、给 40 亿个不重复的 unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那 40 亿个数当中？

**方案 1：**申请 512M 的内存，一个 bit 位代表一个 unsigned int值。读入 40 亿个数，设置相应的 bit 位，读入要查询的数，查看相应 bit 位是否为 1，为 1 表示存在，为 0 表示不存在。

**方案 2：**因为 2^32为 40 亿多，所以给定一个数可能在，也可能不在其中；
 这里我们把 40 亿个数中的每一个用 32 位的二进制来表示
 假设这 40 亿个数开始放在一个文件中。

然后将这 40 亿个数分成两类:
 1.最高位为 0
 2.最高位为 1
 并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；
 与要查找的数的最高位比较并接着进入相应的文件再查找

再然后把这个文件为又分成两类:
 1.次最高位为 0
 2.次最高位为 1

并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；
 与要查找的数的次最高位比较并接着进入相应的文件再查找。
 .......
 以此类推，就可以找到了。

##### 参考文章：

[海量数据处理 算法总结](https://link.jianshu.com?t=http://blog.csdn.net/hguisu/article/details/7856239)
 [十道海量数据处理面试题与十个方法大总结](https://link.jianshu.com?t=http://blog.csdn.net/v_july_v/article/details/6279498)
 [教你如何迅速秒杀掉：99%的海量数据处理面试题](https://link.jianshu.com?t=http://blog.csdn.net/v_july_v/article/details/7382693)


# 相关
- [面试必备之海量数据处理](https://www.jianshu.com/p/ac5cad6d64a8)
