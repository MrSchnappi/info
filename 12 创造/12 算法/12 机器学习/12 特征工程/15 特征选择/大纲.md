---
title: 大纲
toc: true
date: 2019-10-17
---
# 大纲



在做特征抽取的时候，我们是尽可能地抽取更多的Feature，但过多的Feature会造成冗余，噪声，容易过拟合等问题，因此我们需要进行特征筛选。特征选择可以加快模型的训练速度，甚至还可以提升效果。

特征选择的方法多种多样，最简单的是相关度系数(Correlation coefficient)，它主要是衡量两个变量之间的线性关系，数值在[-1.0, 1.0]区间中。数值越是接近0，两个变量越是线性不相关。但是数值为0，并不能说明两个变量不相关，只是线性不相关而已。

我们通过一个例子来学习一下怎么分析相关系数矩阵：

![img](http://mmbiz.qpic.cn/mmbiz_jpg/bicdMLzImlibR1JbulZec5CkJfqq8bykSXRChpZLlEWAvSFgkh3rRf9S6sDxjdukL9Iaiapbvt8W6ax9dpiaVubJ6Q/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

相关系数矩阵是一个对称矩阵，所以只需要关注矩阵的左下角或者右上角。我们可以拆成两点来看：

1. Feature和Label的相关度可以看作是该Feature的重要度，越接近1或-1就越好。
2. Feature和Feature之间的相关度要低，如果两个Feature的相关度很高，就有可能存在冗余。

除此之外，还可以训练模型来筛选特征，比如带L1或L2惩罚项的Linear Model、Random Forest、GDBT等，它们都可以输出特征的重要度。在这次比赛中，我们对上述方法都进行了尝试，将不同方法的平均重要度作为最终参考指标，筛选掉得分低的特征。
