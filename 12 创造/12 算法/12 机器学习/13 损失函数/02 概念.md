# 概念



# 目标函数 损失函数 代价函数

明确：

- 损失函数 = 代价函数
- 目标函数：对于目标函数来说在有约束条件下的最小化就是损失函数。

更加明确：


- 损失函数是定义在单个样本上的，算的是一个样本的误差。
- 代价函数是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。
- 目标函数定义为：代价函数 + 正则化项。


## 经验风险 结构风险


<p align="center">
    <img width="90%" height="70%" src="http://images.iterate.site/blog/image/20190902/p93yUIf7uKv7.png?imageslim">
</p>

上图中：

- 函数依次为 $f_{1}(x), f_{2}(x), f_{3}(x)$。我们想用这三个函数分别来拟合 Price，Price的真实值记为 $Y$ 。
- 我们给定 $x$，函数输出 $f(X)$，真实值是 $\boldsymbol{Y}$ 


此时，我们用一个函数来度量拟合的好坏：

比如：$L(Y, f(X))=(Y-f(X))^{2}$，这个函数就称为**损失函数**，或者叫代价函数。损失函数越小，就代表模型拟合的越好。

那是不是我们的目标就只是让损失函数越小越好呢？

并不是。

这个时候还有一个概念叫**风险函数**(risk function)。风险函数是损失函数的期望，我们知道，输入输出 $(X, Y)$ 是遵循一个联合分布的，但是，我们这个联合分布是未知的。所以，我们使用基于训练集上的平均损失作为我们的风险：即$\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)$，叫做**经验风险**。最小化这个经验风险的过程为经验风险最小化。

只用经验风险，存在一个问题，如上图中最右面的 $f_{3}(x)$ ，经验风险函数最小，但是从图上来看 $f_{3}(x)$ 肯定不是最好的，因为已经过拟合。

因此，我们不仅要让经验风险最小化，还要让**结构风险最小化**。定义了一个函数 $J(f)$，专门用来度量**模型的复杂度**，在机器学习中也叫正则化(regularization)。常用的有 $L_{1}$ , $L_{2}$ 范数。

此时，我们的最终优化函数是：

$$
\min \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)
$$

即最优化经验风险和结构风险，而这个函数就被称为**目标函数**。

综上：

- 最左面的 $f_{1}(x)$ 结构风险最小（模型结构最简单），但是经验风险最大（对历史数据拟合的最差）；
- 最右面的 $f_{3}(x)$ 经验风险最小（对历史数据拟合的最好），但是结构风险最大（模型结构最复杂）；
- $f_{2}(x)$ 达到了二者的良好平衡，最适合用来预测未知数据集。


# 残差 误差


简单理解为:

- 误差:即观测值与真实值的偏离;
- 残差:观测值与拟合值的偏离.


误差分为两类：

- 系统误差。系统误差与测量方案有关，通过改进测量方案可以避免系统误差。
- 随机误差。随机误差与观测者，测量工具，被观测物体的性质有关，只能尽量减小，却不能避免。


要看一个模型是否合适,看误差;
要看所取样本是否合适,看残差;
