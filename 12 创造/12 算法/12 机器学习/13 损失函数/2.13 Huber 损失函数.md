---
title: 2.13 Huber 损失函数
toc: true
date: 2019-09-03
---
# Huber 损失

平滑的平均绝对误差

Huber 损失对数据中的异常点没有平方误差损失那么敏感。它在 0 也可微分。

本质上，Huber损失是绝对误差，只是在误差很小时，就变为平方误差。误差降到多小时变为二次误差由超参数 $\delta$（delta）来控制。当 Huber 损失在 $[0-\delta, 0+\delta]$ 之间时，等价为 MSE，而在 $[-\infty, \delta]$ 和 $[\delta,+\infty]$ 时为 MAE。


$$
L_{\delta}(y, f(x))=\left\{\begin{array}{ll}{\frac{1}{2}(y-f(x))^{2}} & {\text { for }|y-f(x)| \leq \delta} \\ {\delta|y-f(x)|-\frac{1}{2} \delta^{2}} & {\text { otherwise }}\end{array}\right.
$$



这里超参数 delta 的选择非常重要，因为这决定了你对与异常点的定义。当残差大于 delta，应当采用 L1（对较大的异常值不那么敏感）来最小化，而残差小于超参数，则用 L2 来最小化。


## 图示

均方误差损失函数、绝对损失函数、Huber 损失函数图示如下：

<center>

![](http://images.iterate.site/blog/image/20190407/zNMm3RmSRr1y.png?imageslim){ width=55% }


</center>

## 为何要使用 Huber 损失

使用 MAE 训练神经网络最大的一个问题就是不变的大梯度，这可能导致在使用梯度下降快要结束时，错过了最小点。而对于 MSE，梯度会随着损失的减小而减小，使结果更加精确。

在这种情况下，Huber损失就非常有用。它会由于梯度的减小而落在最小值附近。比起 MSE，它对异常点更加鲁棒。因此，Huber损失结合了 MSE 和 MAE 的优点。但是，Huber损失的问题是我们可能需要不断调整超参数 delta。<span style="color:red;">delta 需要不断调整吗？</span>



# 相关


- [机器学习大牛最常用的 5 个回归损失函数，你知道几个？](https://www.jiqizhixin.com/articles/2018-06-21-3)
