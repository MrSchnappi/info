---
title: 1.02 RNN 典型特点
toc: true
date: 2019-09-03
---

## 6.3 RNNs典型特点？

1. RNNs 主要用于处理序列数据。对于传统神经网络模型，从输入层到隐含层再到输出层，层与层之间一般为全连接，每层之间神经元是无连接的。但是传统神经网络无法处理数据间的前后关联问题。例如，为了预测句子的下一个单词，一般需要该词之前的语义信息。这是因为一个句子中前后单词是存在语义联系的。
2. RNNs中当前单元的输出与之前步骤输出也有关，因此称之为循环神经网络。具体的表现形式为当前单元会对之前步骤信息进行储存并应用于当前输出的计算中。隐藏层之间的节点连接起来，隐藏层当前输出由当前时刻输入向量和之前时刻隐藏层状态共同决定。
3. 标准的 RNNs 结构图，图中每个箭头代表做一次变换，也就是说箭头连接带有权值。
4. 在标准的 RNN 结构中，隐层的神经元之间也是带有权值的，且权值共享。
5. 理论上，RNNs能够对任何长度序列数据进行处理。但是在实践中，为了降低复杂度往往假设当前的状态只与之前某几个时刻状态相关，**下图便是一个典型的 RNNs**：

<center>

![](http://images.iterate.site/blog/image/20190722/ytbYCITFL9JO.png?imageslim){ width=55% }

</center>


<center>

![](http://images.iterate.site/blog/image/20190722/GO91nbMVuPpY.jpg?imageslim){ width=55% }

</center>

- 输入单元(Input units)：输入集 $\bigr\{x_0,x_1,...,x_t,x_{t+1},...\bigr\}$，
- 输出单元(Output units)：输出集 $\bigr\{y_0,y_1,...,y_t,y_{y+1},...\bigr\}$，
- 隐藏单元(Hidden units)：输出集 $\bigr\{s_0,s_1,...,s_t,s_{t+1},...\bigr\}$。

**图中信息传递特点：**

1. 一条单向流动的信息流是从输入单元到隐藏单元。
2. 一条单向流动的信息流从隐藏单元到输出单元。
3. 在某些情况下，RNNs会打破后者的限制，引导信息从输出单元返回隐藏单元，这些被称为“Back Projections”。
4. 在某些情况下，隐藏层的输入还包括上一时刻隐藏层的状态，即隐藏层内的节点可以自连也可以互连。
5. 当前单元（cell）输出是由当前时刻输入和上一时刻隐藏层状态共同决定。








# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
