---
title: 2.22 零数据学习 zero-shot learning
toc: true
date: 2019-09-01
---
# 可以补充进来的

- 之前看到的贪心学院的 zero-shot 的一段讲解挺好的，合并到这里。


# 零数据学习 zero-shot learning


源数据为标记数据，目标数据非标记。


Zero-shot Learning 比 Domain-adversarial training更严苛，它要求迁移的两种任务差别也是很大的。

如下图，源数据是猫狗图片，而目标数据是草泥马图片，这两种分类任务属于不同的任务了。<span style="color:red;">这差别也太大了吧？</span>

<center>

![mark](http://images.iterate.site/blog/image/20190901/fAfRGWDMaCXd.png?imageslim)


</center>

## 使用属性组合来分类


我们首先将分类任务中对应的所有分类目标的属性存在数据库里，并且必须保证每个分类目标的属性组合独一无二（属性组合重复的两者将无法在下述方法中区分）。

如下图，那么，我们在学习 NN 模型时，不再要求 NN 的输出直接是样例的分类，而要求是对应的分类目标包含哪些属性。<span style="color:red;">嗯，可以。</span>

那么，我们再在目标数据/测试数据上做分类时，也只要先用模型获提取出样例的属性，再查表即可。

而如果数据特征变得复杂（比如是图片作为输入），那么我们就可以做 embedding，即尝试训练一个 NN，将样例特征映射到一个低维的 embedding 空间，然后让映射后的结果和样例对应的属性尽可能地相近。


但是，如果我们没有数据库（没有属性数据）呢？

借用 Word Vector的概念：word vector的每一个 dimension 代表了当前这个 word 的某一个属性，所以其实我们也不需要知道具体每个动物对应的属性是什么，只要知道每个动物对应的 word vector就可以了。即将属性换成 word vector，再做 embedding。<span style="color:red;">嗯。</span>




## Zero-shot Learning 的训练


![mark](http://images.iterate.site/blog/image/20190901/t7kQfEC1HxGd.png?imageslim)

思想：让同一对的 x 与 y 尽量靠近，让不同对的 x 与 y 尽量远离。

$$
f^{*}, g^{*}=\arg \min _{f, g} \sum_{n}\left\|f\left(x^{n}\right)-g\left(y^{n}\right)\right\|_{2}
$$


$$
f^{*}, g^{*}=\arg \min _{f, g} \sum_{n} \max \left(0, k-f\left(x^{n}\right) \cdot g\left(y^{n}\right)+\max _{m \neq n} f\left(x^{n}\right) \cdot g\left(y^{m}\right)\right)
$$

其中 k 是 margin you defined.

那么，我们就是要 zero loss：

$$
k-f\left(x^{n}\right) \cdot g\left(y^{n}\right)+\max _{m \neq n} f\left(x^{n}\right) \cdot g\left(y^{m}\right)<0
$$

即：

$$
f\left(x^{n}\right) \cdot g\left(y^{n}\right)-\max _{m \neq n} f\left(x^{n}\right) \cdot g\left(y^{m}\right)>k
$$

其中：

- $f\left(x^{n}\right) \cdot g\left(y^{n}\right)$ 意思是 $f\left(x^{n}\right)$ 和 $g\left(y^{n}\right)$ are as close
- $\max _{m \neq n} f\left(x^{n}\right) \cdot g\left(y^{m}\right)$ 意思是 $f\left(x^{n}\right)$ 和 $g\left(y^{m}\right)$ not as close

还有一种训练方法更简单：Convex Combination of Semantic Embedding

假设训练出一个狮虎分类器，它对于一张图片给出了“50%是狮子，50%是老虎”的结果，那么我们就将狮子和老虎对应的 word vector分别乘以 0.5再加和，获得新的 vector，看这个 vector 和哪个动物对应的 vector 最相近（比如狮虎兽 liger 最相近）。

<span style="color:red;">上面这两段的例子没咋明白？是要说明什么？</span>

而做这个只要求我们有一组 word vector和一个语义辨识系统即可。


<center>

![mark](http://images.iterate.site/blog/image/20190901/AOoyaqsdKNRE.png?imageslim)

</center>

下图是一个对比普通 CNN，做 Embedding 的 Zero-shot Leaning，和 Convex Combination of Semantic Embedding三种方法对于 Stellar Sealion识别的效果比较：<span style="color:red;">那种是那种？</span>



<center>

![mark](http://images.iterate.site/blog/image/20190901/k1klr3P9w071.png?imageslim)

</center>


# 相关

- [迁移学习（Transfer Learning）](https://blog.csdn.net/qq_32690999/article/details/78849565)
