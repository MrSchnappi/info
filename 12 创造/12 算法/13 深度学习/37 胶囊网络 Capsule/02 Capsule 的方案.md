---
title: 02 Capsule 的方案
toc: true
date: 2019-09-29
---
# Capsule 的方案

在 Capsule 的方案中，CNN的卷积层保留，MaxPooling层被拿掉。

这里需要强调的是，Capsule本身是一种技术框架，并不单单是具体的某项技术，Hinton论文给出的是最简单的一种实现方法，完全可以在遵循其技术思路情况下创造全新的具体实现方法。

要理解 Capsule 的思路或者对其做一个新的技术实现其实也不困难，只要理解其中的几个关键环节就能实现此目的。如果用一句话来说明其中的关键点的话，可以用“一个中心，两个基本点”来概括。

这里的一个中心，指的是：

- Capsule的核心目的是希望将“视角不变性”能力引入图像处理系统中。所谓“视角不变性”，指的是当我们给 3D 物体拍照片的时候，镜头所对的一定是物体的某个角度看上去的样子，也就是 2D 照片反映 3D 物体一定是体现出了镜头和 3D 物体的某个视角角度，而不是 360 度的物体全貌。那么，要达到视角不变性，就是希望给定某个物体某个角度的 2D 照片，当看到另外一张同一物体不同视角的 2D 照片时，希望 CNN 也能识别出其实这仍然是那个物体。这就是所谓的“视角不变性”（参照下图，上下对应的图片代表同一物体的不同视角），这是传统的 CNN 模型很难做好的事情。

<center>

![mark](http://images.iterate.site/blog/image/20190927/MeGRLMO3QYbq.png?imageslim)

</center>


> 视角不变性

至于说两个基本点：

- 首先第一个基本点是：用一维向量或者二维数组来表征一个物体或者物体的某个部件。传统的 CNN 尽管也能用特征来表征物体或者物体的构成部件，但是往往是通过不同层级的卷积层或者 Pooling 层的某个神经元是否被激活来体现图像中是否具备某个特征。Capsule则考虑用更多维的信息来记载并表征特征级别的物体，类似于自然语言处理中使用 Word Embedding表征一个单词的语义。这样做的好处是描述物体的属性可以更加细致，比如可以将物体的纹理、速度、方向等作为描述某个物体的具体属性。
- 第二个基本点是：Capsule不同层间神经元之间的动态路由机制，具体而言是低层神经元向高层神经元传递信息时的动态路由机制。低层特征向高层神经元进行动态路由本质上是要体现如下思想：构成一个物体的组成部件之间会通过协同地相互加强的方式来体现这种“整体-组成部分”的关系，比如尽管图片的视角发生了变换，但是对一个人脸来说，嘴和鼻子等构成人脸的构件会协同地发生类似的视角变换，它们仍然组合在一起构成了从另外一个视角看过去的人脸。如果从本质上来说，动态路由机制其实是组成一个物体的构件之间的特征聚类，通过聚类的方式把属于某个物体的组成部分动态地自动找出来，并建立特征的“整体-部分”的层级构成关系（比如人脸是由鼻子，嘴，眼睛等部件构成）。

以上所述的三个方面是深入理解 Capsule 的关键。

Capsule的论文发出来后引发了大量的关注和讨论，目前关于 Capsule 计算框架，大部分人持赞赏的态度，当然也有一些研究人员提出了质疑，比如论文中采用的 MINST 数据集规模小不够复杂、Capsule的性能优势不明显、消耗较多内存计算速度慢等。但是无论这项新计算框架能否在未来取代 CNN 标准模型，抑或它很快会被人抛弃并遗忘，Hinton老先生这种老而弥坚的求真治学态度，以及勇于推翻自己构建的技术体系的勇气，这些是值得所有人敬佩和学习的。



# 相关

- [2017年 AI 技术前沿进展与趋势](https://zhuanlan.zhihu.com/p/37057045)
