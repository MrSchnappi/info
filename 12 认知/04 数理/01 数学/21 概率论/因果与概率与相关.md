
[机器人的局限是？—从相关关系和因果关系谈起](https://book.douban.com/review/9650863/)

数了下，大约已经学了3年的统计，我对统计中不确定性的衡量深深着迷，但是也正是因为这种不确定性有时会让我十分的迷茫，比如统计中最常用的**相关性（Correlation）**。不论是因果性还是相关性，都是衡量不同变量之间关系的指标。很多关于未来的预测都指出，基于大数据时代，我们的思维模式应该从决定论体系下的因果关系慢慢转变为不确定体系下的相关关系。

相关关系不难于理解，尤其是依托于卡尔皮尔逊的**相关系数 （Correlation coefficient）** 的概念，在数据量充足的情况下，我们有了一个在[-1,1]的数来衡量不同变量之间的关系。好像一切都变得简单起来，从数据出发，由数据驱动就变得理所应当。最有名的那个啤酒和尿布的例子正好说明了这一点。从销售数据来看，在暴风天气，啤酒和尿布的销量呈正相关，那么好了，只要把这两个物品放在一起，就会更加提高销量。都不用去想明白这背后到底是为什么。（当然有研究指出，是因为暴风雨天气出来买尿布往往是男性，而在暴风雨天也许男性觉得来杯啤酒是不错的选择。）

这当然是成功的例子，而且还有很多很多成功的例子。但问题是我们拥有了太多的相关关系。正如《The Book of Why》里那个信手拈来的例子，一个国家诺贝尔奖获得者的人数和这个国家的巧克力销售量有正相关的关系。那到底是为什么？难道只要想办法增加巧克力的销量，就能产生诺贝尔奖获得者吗？这简直太荒唐了。

到了真正做数据实验的时候也是这样，现在运用一些机器学习的算法实在是太容易了。只要有一些基础，就可以很容易实现那些复杂的算法，然后就用机器学习那套固定的trade-off的模式，训练误差、测试误差统统算过，来看看最好的模型是什么。我想这一切的算法都是建立在承认不同变量之间的相关性的基础之上的，但我的问题是这样真的就够了嘛？

从实用性的角度来看，答案是肯定的。机器学习的算法已经成功的运用到了各个地方，几乎需要预测的地方都有用。但是想想高尔顿最基本的那个**回归模型（Regression Model）**，解释性呢？大多预测很棒的算法都以一个黑匣子的样子出现，我们能看到的只是几个参数和不同的拟合、预测值，但是不同变量之间的关系呢？真的就可以不管不顾吗？

我想Pearl教授给了我一个能说服我的答案。那就是从书一开始就提到的“The Ladder of Causation”，也就是“因果的阶梯”。在这个阶梯最底层是Seeing，用眼睛去看。这一层主要的考虑的是Assiciation（关联），机器人和猫头鹰在这个阶层。第二层是Doing，这一层要考虑的是Intervention（介入），三岁的小孩和原始人在这个阶层。最高层是Imagining，这一层要考虑Counterfactuals（反事实），这是我们人类所处的阶层。而计算机的局限就在于，无论机器学习的算法多么厉害都只停留在了Seeing的阶段。计算机可以完美的拟合数据，但是不能跨越阶层，而Pearl教授的观点就是必须要给计算机配备能够帮助计算机跨越阶层的**因果推断模型**。

在他看来，因果推断的起源是那个整天口袋里装着豚鼠的Sewall Wright教授。Wright为了研究清楚豚鼠的遗传问题，建立了**路径图（Path diagram）**。而由路径图发展而来，也是由Pearl教授提出的贝叶斯网络正是因果推断的核心。

这里面要设计很多贝叶斯统计和图论的知识，暂且抛开不谈，我想单单就是对不同变量之间关系的理解就让我耳目一新。比如有三个不同的变量A、B和C，在因果分析中三者有三种基本的关系。（P113）

> 1、A—>B—>C，这被称作一个链子（chain）。举个例子，着火（A）—>冒烟（B）—>报警（C）。显然，只有先着火，火导致冒烟，烟导致报警。但是如果我们只知道两个，尤其是只知道A和C，那么A和C是有关的吗？假想一下我们的数据是一个地区着火次数和报警次数，那么这两个次数之间我想应该是呈现正相关的。这里需要注意一点，一旦我们给定B，即知道了B冒烟与否。假设，已知了在B=1（1表示冒烟，0表示不冒烟）的情况下，着火和报警的次数，那么这A和C就是条件（在B=1的条件下）独立的。

> 2、A<—B—>C，这称为叉子（fork）。同样我们用一个例子来说明这种关系。鞋子的大小（A）<—孩子的年龄（B）—>阅读能力（C）。还是考虑A和C，从相关的角度来看，鞋子的大小和阅读能力可以想象有正相关的关系。但是我们一旦限定某个年龄层的孩子，比如孩子年龄等于8岁，那么我想A和C之间也就条件（在Age=8的条件下）独立了。

> 3、A—>B<—C，这称为对撞（collider）。最显然的例子就是，好莱坞演员的天分（A）—>名气（B）<—外表（C）。我们看过了太多的例子，天分和外表是无关的。但是在好莱坞，无论是外表还是天分都可以让你成名。那么把事情反过来想，如果你成名了对于大多数人（当然我们得排除约翰尼德普、汤姆克鲁斯这种）来说，不是靠A就是靠C，如果靠了A那C的成分就弱一些（这是某种负相关）。所以，A和C本身独立，但是限定了B之后，A和C变得相关起来。

以上便是书中阐述的三种基本的因果关系，也是Pearl教授认为计算机应该要发现并认知的关系。那这些关系有什么用？按照作者的看法，他能帮助计算机从Seeing阶层上升到Doing阶层。怎么做？假设我们发现A和C有某种相关关系，但是不知道本质的因果是什么？是A直接导致了C吗？还是说A和C直接混淆（Confounder）了B呢？这就需要做（do）由统计学家，那个伟大的统计学家Fisher提出的RCT（Randomized controlled trail，随机控制实验）。

当然抛开方法论不谈，简单来说就是给A一个扰动，控制B为常数看看C怎么变？当然对于chain关系来说，对A一个扰动很难保证B为常数（都着火（A增大）了不冒烟（B能不变吗）吗？），对于fork关系而言，对A的扰动并不会改变B和C，（一定年龄的孩子（B=常数）穿上大一点的鞋子（A增大）就能阅读能力好（C增大？）了吗？最后，对于collider关系，A的扰动确实会影响B，但是对C却影响甚微（增加一个演员的天分（A变大）会让他更容易有名声（B变大），但是对于他的容貌并无太大影响（C基本不变））。

由此，我们通过某种以RCT指导的介入（Intervention）过程，可以得到一些可观察的结果，通过这些结果我们可以进一步去思考，不同变量之间的关系到底何如，而这些基本的理念就成了因果分析的基石。