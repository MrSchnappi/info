# 代价敏感学习


代价敏感学习算法

Cost-Sensitive Learning


在数据层面解决不平衡数据的问题主要是通过采样，而在算法层面上主要是基于代价敏感学习算法(Cost-Sensitive Learning)。

# 核心要素 代价矩阵

核心要素：

- 代价矩阵


举例：

- 在实际的应用中不同类型的误分类情况导致的代价是不一样的，例如：
  - 在医疗中，“将病人误疹为健康人”和“将健康人误疹为病人”的代价不同；
  - 在信用卡盗用检测中，“将盗用误认为正常使用”与“将正常使用识破认为盗用”的代价也不相同


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190828/M4KLUyerS88M.png?imageslim">
</p>


说明：

- 标记 $C_{ij}$ 为将类别 $j$ 误分类为类别 $i$ 的代价
- 显然 $C_{00}=C_{11}=0$。$C_{01}$，$C_{10}$ 为两种不同的误分类代价，当两者相等时为代价不敏感的学习问题。


# 三种实现

代价敏感学习方法的三种实现方式：

1. 从学习模型出发，着眼于对某一具体学习方法的改造，使之能适应不平衡数据下的学习。研究者们针对不同的学习模型如感知机，支持向量机，决策树，神经网络等分别提出了其代价敏感的版本。<span style="color:red;">补充。</span>
   - 以代价敏感的决策树为例，可从三个方面对其进行改进以适应不平衡数据的学习，这三个方面分别是决策阈值的选择方面、分裂标准的选择方面、剪枝方面，这三个方面中都可以将代价矩阵引入。
2. 从贝叶斯风险理论出发，把代价敏感学习看成是分类结果的一种后处理，按照传统方法学习到一个模型，以实现损失最小为目标对结果进行调整，优化公式如下所示。此方法的优点在于它可以不依赖所用具体的分类器，但是缺点也很明显它要求分类器输出值为概率。<span style="color:red;">补充。</span>


$$
\mathcal{H}(x)=\arg \min _{i}\left(\sum_{j \in\{-,+\}} P(j | x) C(i, j)\right)
$$


3. 从预处理的角度出发，将代价用于权重的调整，使得分类器满足代价敏感的特性。
   - 比如一种基于 Adaboost 的权重更新策略，AdaCost。




## AdaCost算法


回顾 Adaboost：

- Adaboost算法通过反复迭代，每一轮迭代学习到一个分类器，并根据当前分类器的表现更新样本的权重。
- 如图中红框所示，其更新策略为正确分类样本权重降低，错误分类样本权重加大。

$$
D_{t+1}(i)=\frac{D_{t}(i) \exp \left(-\alpha_{t} y_{i} h_{t}\left(x_{i}\right)\right)}{Z_{t}}
$$

- 最终的模型是多次迭代模型的一个加权线性组合，分类越准确的分类器将会获得越大的权重。


<p align="center">
    <img width="80%" height="70%" src="http://images.iterate.site/blog/image/20190828/kajcxHPftUUM.png?imageslim">
</p>



AdaCost ：（修改了 Adaboost 算法的权重更新策略）

- 基本思想是对于代价高的误分类样本大大地提高其权重，而对于代价高的正确分类样本适当地降低其权重，使其权重降低相对较小。
- 总体思想是代价高样本权重增加得大降低得慢。其样本权重按照如下公式进行更新。




$$
D_{t+1}(i)=\frac{D_{t}(i) \exp \left(-\alpha_{t} y_{i} h_{t}\left(x_{i}\right)\beta_{i} \right)}{Z_{t}}
$$

$$
\beta_{+}=-0.5 C_{i}+0.5
$$

$$
\beta_{-}=0.5 C_{i}+0.5
$$

说明：

- $\beta_+和\beta_-$ 分别表示样本被正确和错误分类情况下$\beta$ 的取值。