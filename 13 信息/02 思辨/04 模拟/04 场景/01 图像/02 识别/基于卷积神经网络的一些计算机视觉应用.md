## 基于卷积神经网络的计算机视觉应用

和计算机关联最紧密的深度学习技术是卷积神经网络。本节来列举一些卷积神经网络 发挥重要作用的计算机视觉的方向。

### 图像分类

顾名思义，图像分类就是对于输入的已知图像，由算法提取特征并最终分 到已知的一个类别里，或者说判断图像中是否包含一个已知类别中的物体，如图 1-9所示。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180830/ecbm08F19m.png?imageslim">
</p>

前面花了不少篇幅讲述 ILSVRC 从 2010 年到 2016 年的风云变幻，而图像分类是深度 学习在计算机视觉领域大放异彩的第一个方向。不管是最开始的 MNIST，还是后来的 ImageNet，基于深度学习的图像分类在特定任务上早就超过了人的平均水平。

### 物体检测

物体检测和图像分类差不多，也是计算机视觉里最基础的两个方向。它和图像分类的侧重点不同，物体检测要稍微复杂一些，关心的是什么东西出现在了什么地方, 是一种更强的信息。如图 1-10中，经过物体检测，我们得到的信息不仅是照片中包含马和摄影师，还得到了每一样检测到的类别的位置信息，以方框的形式展现出来。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180830/jLKhlBGjjI.png?imageslim">
</p>

和图像分类相比，物体检测传达的信息更强，例如要分类猫和狗的图片的问题，那么如果图像中既有猫又有狗该怎么分类呢？这时候如果还是坚持用分类则是一个多标签分类问题，或者就进一步用物体检测告诉我们猫在哪，狗在哪。在物体检测领域以基于 Region Proposal 的 R-CNN及后续的衍生算法，以及基于直接回归的 YOLO/SSD 一系的算法为代表。这两类算法都是基于卷积神经网络，借助的不仅仅是深度网络强大的图像特征提取和分类能力，也会用到神经网络的逼近能力。<span style="color:red;">R-CNN 和 YOLO/SSD 不是一个原理吗？基于 RegionProposal 和 基于直接回归的有什么区别？</span>

### 人脸识别

人脸识别是计算机视觉里非常悠久的一个方向，也是和人相关的研究最多 的一个计算机视觉子领域。和我们生活中最相关的应用一般有两个方面：

- 第一个是检测图像中是否存在人脸，这个应用和物体检测很像。主要应用有数码相机中对人脸的检测，网络或手机相册中对人脸的提取等；
- 第二个是人脸匹配，有了第一个方面或是其他手段把人脸部分找到后，人脸的匹配才是一个更主流的应用。主要的思想是把要比对的两个人脸之间的相似度计算出来。计算这种度量，传统的方法叫做度量学习(metric learning)。其基 本思想是通过变换，让变换后的空间中定义为相似的样本距离更近，不相似的样本距离更远。基于深度学习也有相应的方法，比较有代表性的是 Siamese 网络和 Triplet 网络，当然广义上来说都可以算是度量学习。有了这种度量，可以进一步判断是否是一个人。这就是身份辨识，广泛用于罪犯身份确认、银行卡开卡等场景中。2015年马云在德国的汉诺威信息技术博览会上“刷脸”的大新闻，背后就是这种技术。此外还可以利用相似度实现一些好玩的应用，如用自拍照找相似的明星脸等。<span style="color:red;">什么是 Siamese 网络和 Triplet 网络？之前好像没听说过。</span>

人脸领域最流行的测试基准数据是 LFW (Labeled Faces in the Wild)，顾名思义就是从实拍照片中标注的人脸。该图片库由美国麻省理工大学开发，约 13000 多张图片，其中有 1680 人的脸出现了两次或两次以上。在这个数据上，人类判断两张脸是否是同一人能达到的准确率为 99.2%。而在深度学习大行其道之后，自 2014 年起这个记录已经被各种基于深度学习的方法打破。虽然这未必真的代表深度学习胜过了人类，但基于深度学习的人脸算法让相关应用的可用性大大提高。如今人脸识别相关的商业应用已经遍地开花。


### 图像分割

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180830/ckBegg9EDC.png?imageslim">
</p>

图像分割是个比较传统的视觉应用，指的是以像素为单位将图像划分为不同部分，这些部分代表着不同的感兴趣区域。如图 1-11所示的例子，画面中是山东威海的 一只受伤幼年红隼和背景。经过图像分割后，红隼在画面中所占的像素被标了出来，和背景有了区分。

传统的图像分割算法五花八门，如基于梯度和动态规划路径的 Intelligent Scissors (Photoshop中的磁力套索)；利用高一维空间的超曲面解决当前空间轮廓的水平集(Level Set)方法；直接聚类的 K-means；后期很流行的基于能量最小化的 GraphCut/GrabCut 和随机场的 CRF (Conditional Random Field)等。<span style="color:red;">竟然有这么多方法，都要好好整理下。</span>

后来深度学习出现了。和传统方法相比，深度学习未必能做到很精细的像素级分割。

但是因为深度学习能学到大量样本中的图像语义信息的天然优势，这更贴近人对图像的理解，所以分割的结果可用性通常也更好一些。常见的基于深度学习的图像分割手段是全卷积神经网络(Fully Convolutional Networks, FCN)。Facebook 的人工智能实验室 FAIR(Facebook Artificial Intelligence Research)于 2016 年发布了一套用于分割+物体检测的框 架。其构成是一个大体分割出物体区域的网络 DeepMask，加上利用浅层图像信息精细图像分割的 SharpMask，最后是一个 MultiPathNet 模块进行物体检测。其实在这背后也体现 出学界和业界开始慢慢流行起的另一个很底层的思想：就是图像分割和物体检测背后其实 是一回事，不应该分开来研究。对照物体检测和图像分类的关系，图像分割传达的是比物体检测更进一步、更强的信息。<span style="color:red;">嗯，之前对于图像分割还没有很重视，还没有把他单独列出来，现在看起来图像分割可以划分到物体检测里面</span>



