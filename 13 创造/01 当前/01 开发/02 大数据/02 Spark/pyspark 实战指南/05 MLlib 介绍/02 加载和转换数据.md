---
title: 02 加载和转换数据
toc: true
date: 2019-07-02
---
5.2 加载和转换数据
虽然 MLlib 是着重为 RDD 和 DStream 设计的，但是为了方便转换数据，我们将读取数据并将其转换为 DataFrame。DStream是 Spark Streaming的基本数据抽象（请参考 http://bit.ly/2jIDT2A）。
如同在上一章中所做的一样，我们首先指定数据集的 schema。注意这里（为了简洁），我们只呈现一些特征。你可以随时在我们的 GitHub 帐户来获得本书最新版本的代码：https://github.com/drabastomek/learningPySpark。
代码如下：
接下来，我们来加载数据。.read.csv（……）方法可以读取未压缩的或（如同本例中）“GZipped”压缩的逗号分隔的值。参数 header 设置为 true，代表第一行包含头，而且我们使用 schema 来指定正确的数据类型：
我们的数据集中有很多特征是字符串类型的。这些都是需要我们以某种方式将其转换为数字形式的分类变量。您可以在以下地址中查看原始的 schema 定义文件：ftp：//ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf。
首先定义重编码字典：
我们本章的目标是预测“INFANT_ALIVE_AT_REPORT”是 1 还是 0。因此，我们将丢弃与婴儿相关的所有特征，而仅仅基于与其母亲、父亲和出生地点相关的特征来预测婴儿的存活机会：


在我们的数据集中有大量的特征，它们的值是 Yes/No/Unknown；我们将仅仅把 Yes 编码为 1，其他值设置为 0。
还有个小问题是，母亲吸烟的数量如何编码：因为 0 意味着母亲在怀孕前或怀孕期间没有吸烟；1～97之间代表的是母亲实际吸烟数量；98代表母亲实际吸烟数量是 98 或更多；而 99 代表母亲实际吸烟数量未知，我们将假设未知状态为 0，并以此重新编码。
接下来我们将指定我们的重新编码方法：
recode方法从 recode_dictionary（给出键）查找正确的键，并返回更正的值。correct_cig方法检查如下，当 feat 特征值不等于 99 时，返回特征值；如果值等于 99，我们则得到 0。
我们不能直接在 DataFrame 上使用 recode 函数，它需要转换为 Spark 可理解的 UDF。rec_integer函数功能如下：通过传递我们指定的 recode 函数及指定返回值数据类型，我们可以用它来重新编码 Yes/No/Unknown特征。
所以我们来看看，首先我们更正与吸烟数量相关的特征：
.withColumn（……）方法用列名作为其第一个参数，用转换作为第二个参数。在以前的例子中，我们不会创建新列，而是重用相同的列。
现在我们将集中更正 Yes/No/Unknown特征。首先，用下面的代码段来确定有哪些：
首先，我们创建了一个包含列名称和相应数据类型的元组（cols）列表。接下来，我们循环遍历这些列表，并计算所有字符串列的不同值；如果“Y”在返回的列表中，我们将列名追加到 YNU_cols列表。
DataFrame可以在选择特征时批量转换特征。要介绍这个想法，请考虑以下示例：
我们得到如下结果：
我们选择“INFANT_NICU_ADMISSION”列，并且将该特征的名称传递给 rec_integer方法。我们还将新转换的列的别名称为“INFANT_NICU_ADMISSION_RECODE”。这样我们还可确保 UDF 按预期工作。
因此，为了一次性转换所有的 YNU_cols，我们将创建一个转换的列表，如下所示：

检查一下得到的结果是否正确：
我们得到如下输出：
看起来一切工作如同预期一样正常，所以让我们来更好地了解我们的数据吧。
