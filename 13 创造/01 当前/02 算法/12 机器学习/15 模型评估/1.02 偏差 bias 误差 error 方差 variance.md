
# 偏差 bias 误差 error 方差 variance

- 误差 Error
- 偏差 Bias
- 方差 Variance

说明：

- 误差。
  - 一般把学习器的实际预测值与样本的真实标签之间的差异称为“误差”。反映的是整个模型的准确度。
  - Error = Bias + Variance + Noise
- 偏差
  - 衡量模型拟合训练数据的能力（注：训练数据不一定是整个训练集，而是指用于训练它的那一部分数据，例如：mini-batch）
  - 偏差反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度。
  - 偏差越小，拟合能力越高，越可能产生过拟合。
- 方差
  - 方差描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。公式：$S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}$
  - 方差越大，数据的分布越分散，模型的稳定程度越差。
  - 方差越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。
  - 如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差劣，则方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。 如下图右列所示。
- 噪声。
  - 描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。


<p align="center">
    <img width="99%" height="70%" src="http://images.iterate.site/blog/image/20190826/46JXI1pijVxo.png?imageslim">
</p>




联系：


一般情况下，我们评价模型性能时都会使用泛化误差。泛化误差越低，模型性能越好。泛化误差可分解为方差、偏差和噪声三部分。这三部分中，噪声是个不可控因素，它的存在是算法一直无法解决的问题，很难约减，所以我们更多考虑的是方差和偏差。

 方差和偏差在泛化误差上可做如下分解，假设我们的预测值为 g(x)，真实值为 f(x)，则均方误差为

$$
E((g(x)−f(x))^2)
$$

这里假设不考虑噪声，g来代表预测值，f代表真实值，g¯=E(g)代表算法的期望预测，则有如下表达：

$$
\begin{aligned}
E(g-f)^2&=E(g^2-2gf+f^2)
\\&=E(g^2)-\bar g^2+(\bar g-f)^2
\\&=E(g^2)-2\bar g^2+\bar g^2+(\bar g-f)^2
\\&=E(g^2-2g\bar g^2+\bar g^2)+(\bar g-f)^2
\\&=\underbrace{E(g-\bar g)^2}_{var(x)}+\underbrace{(\bar g-f)^2}_{bias^2(x)}
\end{aligned}
$$

有上述公式可知，方差描述是理论期望和预测值之间的关系，这里的理论期望通常是指所有适用于模型的各种不同分布类型的数据集；偏差描述为真实值和预测值之间的关系，这里的真实值通常指某一个特定分布的数据集合。

所以综上方差表现为模型在各类分布数据的适应能力，方差越大，说明数据分布越分散，而偏差则表现为在特定分布上的适应能力，偏差越大越偏离真实值。


