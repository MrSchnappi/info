---
title: 1.03 LDA 优缺点
toc: true
date: 2019-09-03
---
# LDA 优缺点


| 优缺点 | 简要说明                                                                                                                                                                |
|:------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|  优点  | 1. 可以使用类别的先验知识；<br />2. 以标签、类别衡量差异性的有监督降维方式，相对于 PCA 的模糊性，其目的更明确，更能反映样本间的差异；                                     |
|  缺点  | 1. LDA不适合对非高斯分布样本进行降维；<span style="color:red;">为什么不适合对非高斯分布样本进行降维？</span><br />2. LDA降维最多降到分类数 $k-1$ 维；<br />3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好；<span style="color:red;">什么是依赖方差而不是均值？</span><br />4. LDA可能过度拟合数据。 <span style="color:red;">为什么会过度拟合数据？</span>|






# LDA 的优势与限制

LDA 相比 PCA 更善于对有类别信息的数据进行降维处理，但它对数据的分布做了一些很强的假设，例如，每个类数据都是高斯分布、各个类的协方差相等。<span style="color:red;">好吧，这些前提还是要注意的。嗯，要在推导公式的时候进行标注说明。不然很容易在使用的时候忘记。这就是为什么要会推导公式，因为整个定理在推导的过程中是有一些前提条件的，这些条件在使用的时候也是必须要遵守的。</span>

尽管这些假设在实际中并不一定完全满足，但 LDA 已被证明是非常有效的一种降维方法。主要是因为线性模型对于噪声的鲁棒性比较好，但由于模型简单，表达能力有一定局限性，我们可以通过引入核函数扩展 LDA 方法以处理分布较为复杂的数据。<span style="color:red;">要怎么引入核函数？效果怎么样？什么时候使用什么核函数？</span>






## LDA特点：


LDA 是一个很好的结论，但是对于现在的分类问题而言没有这么强的实践意义。因为由 LDA 的计算公式看出，LDA是强依赖均值的。如果类别之间的均值相差不大或者需要方差等高阶矩来分类，效果一般。

若均值无法有效代表概率分布，LDA效果一般。LDA适用于类别是高斯分布的分类。


![](http://images.iterate.site/blog/image/180728/5ggCm1EbI7.png?imageslim){ width=55% }

有各种各样的情况不太适合于分类

另外一个中看不中用的原因是：

LDA与线性回归的关系：


![](http://images.iterate.site/blog/image/180728/kEj4c919Hh.png?imageslim){ width=55% }

什么叫![](http://images.iterate.site/blog/image/180728/GBIHl2gbD2.png?imageslim){ width=55% }？

但是线性回归是不太适合做分类的，logistic回归是没问题的，但是线性回归是不合适的。所以这套 LDA 知道就可以。那么为什么要介绍呢？因为历史上出现过。好多时候会提到，比如面试什么的。并且主题模型的 LDA 在实践中还是有用的。**主体模型的 LDA 与这个地方的 LDA 有什么关系吗？**

更重要的是，如果我们的数据没有给定标记的时候，能不能仍然进行分类呢？





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions) 原文
