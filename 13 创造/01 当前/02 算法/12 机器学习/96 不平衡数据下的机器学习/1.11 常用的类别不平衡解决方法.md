---
title: 1.11 常用的类别不平衡解决方法
toc: true
date: 2019-09-03
---

### 2.16.21 常见的类别不平衡问题解决方法

防止类别不平衡对学习造成的影响，在构建分类模型之前，需要对分类不平衡性问题进行处理。主要解决方法有：

1. 扩大数据集
	- 增加包含小类样本数据的数据，更多的数据能得到更多的分布信息。

1. 对大类数据欠采样
	- 减少大类数据样本个数，使与小样本个数接近。
	- 缺点：欠采样操作时若随机丢弃大类样本，可能会丢失重要信息。
	- 代表算法：EasyEnsemble。其思想是利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器都进行欠采样，但对于全局则不会丢失重要信息。<span style="color:red;">嗯，这个 EasyEnsemble 有应用到深度学习上吗？</span>

1. 对小类数据过采样
	- 过采样：对小类的数据样本进行采样来增加小类的数据样本个数。
	- 代表算法：SMOTE 和 ADASYN。
		- SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。新的少数类样本产生的策略：对每个少数类样本 $a$，在 $a$ 的最近邻中随机选一个样本 $b$，然后在 $a$、$b$ 之间的连线上随机选一点作为新合成的少数类样本。<span style="color:red;">这样真的有效果吗？会不会有问题？</span>
		- ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。<span style="color:red;">什么叫把分类决策边界自适应地转移到困难的样本？这个 ADASYN 没有很理解。</span>

1. 使用新评价指标
	- 如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。<span style="color:red;">类别不均衡时候的评价指标还是要补充下。</span>

1. 选择新算法
	- 不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。

1. 数据代价加权
	- 例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。<span style="color:red;">怎么加权？给损失函数中按分类进行加权吗？加权多少合适？</span>

1. 转化问题思考角度
	- 例如在分类问题时，把小类的样本作为异常点，将问题转化为异常点检测或变化趋势检测问题。
		- 异常点检测即是对那些罕见事件进行识别。<span style="color:red;">异常点检测是有什么特殊的地方吗？与分类问题相比？</span>
		- 变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别。<span style="color:red;">什么是变化趋势检测？什么的变化趋势？</span>

1. 将问题细化分析
	- 对问题进行分析与挖掘，将问题划分成多个更小的问题，看这些小问题是否更容易解决。<span style="color:red;">哇塞，这个倒是之前没有注意过的，可以吧问题进行拆解，这样可能是一小撮样本跟另一小撮样本的分类。</span>





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions) 原文
