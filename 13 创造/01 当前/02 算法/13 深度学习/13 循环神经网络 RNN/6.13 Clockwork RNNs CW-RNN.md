---
title: 6.13 Clockwork RNNs CW-RNN
toc: true
date: 2019-09-03
---

### 6.13.7 Clockwork RNNs(CW-RNNs)

<span style="color:red;">没懂。</span>

CW-RNNs是 RNNs 的改良版本，其使用时钟频率来驱动。它将隐藏层分为几个块(组，Group/Module)，每一组按照自己规定的时钟频率对输入进行处理。为了降低 RNNs 的复杂度，CW-RNNs 减少了参数数量，并且提高了网络性能，加速网络训练。

CW-RNNs 通过不同隐藏层模块在不同时钟频率下工作来解决长时依赖问题。将时钟时间进行离散化，不同的隐藏层组将在不同时刻进行工作。因此，所有的隐藏层组在每一步不会全部同时工作，这样便会加快网络的训练。并且，时钟周期小组的神经元不会连接到时钟周期大组的神经元，只允许周期大的神经元连接到周期小的(组与组之间的连接以及信息传递是有向的)。周期大的速度慢，周期小的速度快，因此是速度慢的神经元连速度快的神经元，反之则不成立。<span style="color:red;">怎么做到的？结构是什么样的？</span>

CW-RNNs 与 SRNs 网络结构类似，也包括输入层(Input)、隐藏层(Hidden)、输出层(Output)，它们之间存在前向连接，输入层到隐藏层连接，隐藏层到输出层连接。但是与 SRN 不同的是，隐藏层中的神经元会被划分为若干个组，设为 $g​$，每一组中的神经元个数相同，设为 $k​$，并为每一个组分配一个时钟周期 $T_i\epsilon\{T_1,T_2,...,T_g\}​$，每一组中的所有神经元都是全连接，但是组 $j​$ 到组 $i​$ 的循环连接则需要满足 $T_j​$ 大于 $T_i​$。如下图所示，将这些组按照时钟周期递增从左到右进行排序，即 $T_1<T_2<...<T_g​$，那么连接便是从右到左。

例如：隐藏层共有 $256$ 个节点，分为四组，周期分别是 $[1,2,4,8]$，那么每个隐藏层组 $256/4=64$ 个节点，第一组隐藏层与隐藏层的连接矩阵为 $64\times​64$ 的矩阵，第二层的矩阵则为 $64\times​128$ 矩阵，第三组为 $64\times​(3\times​64)=64\times192$ 矩阵，第四组为 $64\times​(4\times​64)=64\times​256$ 矩阵。这就解释了上一段中速度慢的组连接到速度快的组，反之则不成立。

**CW-RNNs的网络结构如下图所示**：

<center>

![](http://images.iterate.site/blog/image/20190722/QSj5TUI78yJo.png?imageslim){ width=95% }

</center>
