---
title: 1.04 强化学习与监督学习的区别
toc: true
date: 2019-09-04
---


### 10.3.1 强化学习和监督式学习的区别：

监督式学习就好比你在学习的时候，有一个导师在旁边指点，他知道怎么是对的怎么是错的，但在很多实际问题中，例如 chess，go，这种有成千上万种组合方式的情况，不可能有一个导师知道所有可能的结果。

而这时，强化学习会在没有任何标签的情况下，通过先尝试做出一些行为得到一个结果，通过这个结果是对还是错的反馈，调整之前的行为，就这样不断的调整，算法能够学习到在什么样的情况下选择什么样的行为可以得到最好的结果。

就好比你有一只还没有训练好的小狗，每当它把屋子弄乱后，就减少美味食物的数量（惩罚），每次表现不错时，就加倍美味食物的数量（奖励），那么小狗最终会学到一个知识，就是把客厅弄乱是不好的行为。

两种学习方式都会学习出输入到输出的一个映射，监督式学习出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出，强化学习出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。<span style="color:red;">这个地方的关键的区别是什么？</span>

另外强化学习的结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏，而监督学习做了比较坏的选择会立刻反馈给算法。<span style="color:red;">嗯，这个也是的。</span>

而且强化学习面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入，而监督学习的输入是独立同分布的。<span style="color:red;">嗯，这个是的。</span>

通过强化学习，一个 agent 可以在探索和开发（exploration and exploitation）之间做权衡，并且选择一个最大的回报。

- exploration 会尝试很多不同的事情，看它们是否比以前尝试过的更好。
- exploitation 会尝试过去经验中最有效的行为。

一般的监督学习算法不考虑这种平衡，就只是 exploitative。<span style="color:red;">是的，只是开发，没有探索。</span>



# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
