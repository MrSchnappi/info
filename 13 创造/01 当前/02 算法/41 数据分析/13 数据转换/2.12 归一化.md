---
title: 2.12 归一化
toc: true
date: 2019-09-20
---
# 可以补充进来的

- 这些是归一化的方法吗？



# 归一化

将数据特征缩放至某一范围(scaling features to a range)

另外一种标准化方法是将数据缩放至给定的最小值与最大值之间，通常是０与１之间，可用 MinMaxScaler 实现。或者将最大的绝对值缩放至单位大小，可用 MaxAbsScaler 实现。

使用这种标准化方法的原因是，有时数据集的标准差非常非常小，有时数据中有很多很多零（稀疏数据）需要保存住０元素。

## 1 MinMaxScaler(最小最大值标准化)

公式：

X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) ;

X_scaler = X_std/ (max - min) + min


```
#例子：将数据缩放至[0, 1]间
X_train = np.array([[1., -1., 2.], [2., 0., 0.], [0., 1., -1.]])
min_max_scaler = preprocessing.MinMaxScaler()
X_train_minmax = min_max_scaler.fit_transform(X_train)
#out:
array([[ 0.5       ,  0.        ,  1.        ],
[ 1.        ,  0.5       ,  0.33333333],
[ 0.        ,  1.        ,  0.        ]])
#将上述得到的 scale 参数应用至测试数据
X_test = np.array([[ -3., -1., 4.]])
X_test_minmax = min_max_scaler.transform(X_test) #out: array([[-1.5 ,  0. , 1.66666667]])
#可以用以下方法查看 scaler 的属性
min_max_scaler.scale_        #out: array([ 0.5 ,  0.5,  0.33...])
min_max_scaler.min_         #out: array([ 0.,  0.5,  0.33...])
```




## 2 MaxAbsScaler（绝对值最大标准化）

与上述标准化方法相似，但是它通过除以最大值将训练集缩放至 $[-1,1]$。这意味着数据已经以０为中心或者是含有非常非常多０的稀疏数据。


```
X_train = np.array([[ 1., -1.,  2.],
                     [ 2.,  0.,  0.],
                    [ 0.,  1., -1.]])
max_abs_scaler = preprocessing.MaxAbsScaler()
X_train_maxabs = max_abs_scaler.fit_transform(X_train)
# out:
array([[ 0.5, -1.,  1. ], [ 1. , 0. ,  0. ],       [ 0. ,  1. , -0.5]])
X_test = np.array([[ -3., -1.,  4.]])
X_test_maxabs = max_abs_scaler.transform(X_test)
#out:
array([[-1.5, -1. ,  2. ]])
max_abs_scaler.scale_
#out:
array([ 2.,  1.,  2.])
```

其实在 scale 模块里，也提供了这两种方法： `minmax_scale` 和 `maxabs_scale`



## 3 对稀疏数据进行标准化

对稀疏数据进行中心化会破坏稀疏数据的结构，这样做没什么意义。但是我们可以对稀疏数据的输入进行标准化，尤其是特征在不同的标准时。`MaxAbsScaler` 和 `maxabs_scale` 是专门为稀疏数据设计的，也是常用的方法。但是 scale 和 StandardScaler 只接受 scipy.sparse的矩阵作为输入，并且必须设置 with_centering=False。否则会出现 ValueError且破坏稀疏性，而且还会无意中分配更多的内存导致内存崩溃。RobustScaler不适用于稀疏数据的输入，但是你可以用 transform 方法。

scalers接受压缩的稀疏行（Compressed Sparse Rows）和压缩的稀疏列（Compressed Sparse Columns）的格式（具体参考`scipy.sparse.csr_matrix 和``scipy.sparse.csc_matrix`）。其他的稀疏格式会被转化成压缩的稀疏行（Compressed Sparse Rows）格式。为了避免这种不必要的内存拷贝，推荐使用 CSR 或者 CSC 的格式。如果数据很小，可以在稀疏矩阵上运用 toarray 方法。


## 4 对离群点进行标准化

如果你的数据有离群点（上一篇我们提到过），对数据进行均差和方差的标准化效果并不好。这种情况你可以使用 `robust_scale` 和 `RobustScaler` 作为替代。它们有对数据中心化和数据的缩放鲁棒性更强的参数。



# 相关

- [机器学习基础与实践（二）----数据转换](https://www.cnblogs.com/charlotte77/p/5622325.html)
