
### 视频识别

因为和图像的紧密联系，视频当然少不了深度学习的方法。深度学习在图像分类任务上大行其道之后，视频识别的研究立刻就跟进了上来，比较有代表性的工作从 2014 年起相继出现。<span style="color:red;">原来从 2014 年就开始了。</span>

2014年的 CVPR 上，斯坦福大学的 Fei-Fei Li组发表了一篇视频识别的论文。其基本思路是用视频中的多帧作为输入，再通过不同的顺序和方式将多帧信息进行融合。其方法并没什么特别出彩的地方，但随着论文发布了 Sport-1M数据集，包含了 Youtube 上 487 类 共计 113 万的体育视频，是目前最大的视频分类数据集。

2014年的 NIPS 上，牛津大学传统视觉强组 VGG (Visual Geometry Group)发表了一 篇更经典的视频识别的文章，将图像的空间信息，也就是画面信息，用一个称为 Spatial Stream ConvNet 的网络处理，而视频中帧之间的时序信息用另一个称为 Temporal Stream ConNet 的网络处理，最后融合称为 Two Streams，直译就是二流法。这个方法后来被改来改去，发展出了更深网络的双流法，以及更炫融合方式的双流法，甚至是除了双流还加入音频流的三流法。不过影响最大的改进还是马里兰大学和 Google 的一篇论文，其对时序信息进行了处理和改进，加入了本章提到过的 LSTM，以及改进版二流合并的方法，成为了主流框架之一。<span style="color:red;">这么厉害，想深入了解这个，而且，这个是用来做什么的，感觉真的是非常厉害。</span>

因为视频有时间的维度，所以还有一个很自然的想法是用三维卷积去处理视频帧，这样自然能将时序信息包括进来，这也是一个流行的思路。<span style="color:red;">这个思路现在有人在做吗？</span>

更近的一些研究中，最新的深度学习概率框架生成式对抗网络(Generative Adversarial Networks, GAN)也被用到了视频处理当中。2016年，Comma AI 的实习生 Eder Santana 和被称为天才黑客的 George Hotz 将 GAN 用于对视频输入进行降维，然后用低维表达和 LSTM 进行处理，从而对视频的未来帧进行预测，可以比较准确地预测沿直线前进时未来的画面。<span style="color:red;">怎么对视频输入进行降维的？感觉像是 GAN 的正规的用法，想什么了解下这个项目</span>

视频作为比图像更高一维度的数据，并且还带有时序信息和声音等信息，可探索的空间更大，相信未来会有更多精彩有趣的深度学习相关应用出现。<span style="color:red;">是呀，视频感觉直接与用摄像头和麦克风来捕捉现实社会的信息挂钩。</span>

