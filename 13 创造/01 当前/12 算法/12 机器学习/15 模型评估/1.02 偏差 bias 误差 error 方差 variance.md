---
title: 1.02 偏差 bias 误差 error 方差 variance
toc: true
date: 2019-08-27
---
# 偏差 bias 误差 error 方差 variance



### 2.16.2 误差、偏差和方差有什么区别和联系

在机器学习中，Bias(偏差)，Error(误差)，和 Variance(方差)存在以下区别和联系：

**对于 Error**：

- 误差（error）：一般地，我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差”。
- Error = Bias + Variance + Noise，Error反映的是整个模型的准确度。

**对于 Noise:**

噪声：描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。<span style="color:red;">嗯，期望泛化误差的下界。</span>

**对于 Bias：**

- Bias 衡量模型拟合训练数据的能力（训练数据不一定是整个 training dataset，而是只用于训练它的那一部分数据，例如：mini-batch），Bias 反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度。
- Bias 越小，拟合能力越高（可能产生 overfitting）；反之，拟合能力越低（可能产生 underfitting）。
- 偏差越大，越偏离真实数据，如下图第二行所示。

**对于 Variance：**

- 方差公式：$S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}$
- Variance 描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，模型的稳定程度越差。
- Variance 反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。
- Variance 越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。
- 如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差劣，则方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。 如下图右列所示。

<center>

![](http://images.iterate.site/blog/image/20190722/Q1u3r4lOEvOW.png?imageslim){ width=45% }

</center>


## 13.13 什么是泛化误差，如何理解方差和偏差？

一般情况下，我们评价模型性能时都会使用泛化误差。泛化误差越低，模型性能越好。泛化误差可分解为方差、偏差和噪声三部分。这三部分中，噪声是个不可控因素，它的存在是算法一直无法解决的问题，很难约减，所以我们更多考虑的是方差和偏差。

 方差和偏差在泛化误差上可做如下分解，假设我们的预测值为 g(x)，真实值为 f(x)，则均方误差为
$$
E((g(x)−f(x))2)
$$
这里假设不考虑噪声，g来代表预测值，f代表真实值，g¯=E(g)代表算法的期望预测，则有如下表达：
$$
\begin{align}
E(g-f)^2&=E(g^2-2gf+f^2)
\\&=E(g^2)-\bar g^2+(\bar g-f)^2
\\&=E(g^2)-2\bar g^2+\bar g^2+(\bar g-f)^2
\\&=E(g^2-2g\bar g^2+\bar g^2)+(\bar g-f)^2
\\&=\underbrace{E(g-\bar g)^2}_{var(x)}+\underbrace{(\bar g-f)^2}_{bias^2(x)}
\end{align}
$$
有上述公式可知，方差描述是理论期望和预测值之间的关系，这里的理论期望通常是指所有适用于模型的各种不同分布类型的数据集；偏差描述为真实值和预测值之间的关系，这里的真实值通常指某一个特定分布的数据集合。

所以综上方差表现为模型在各类分布数据的适应能力，方差越大，说明数据分布越分散，而偏差则表现为在特定分布上的适应能力，偏差越大越偏离真实值。




## 知乎上的总结


<center>

![mark](http://images.iterate.site/blog/image/20190826/46JXI1pijVxo.png?imageslim)


</center>

- **准**：bias描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距，简单讲，就是在样本上拟合的好不好。要想在 bias 上表现好，low bias，就得复杂化模型，增加模型的参数，但这样容易过拟合 (overfitting)，过拟合对应上图是 high variance，点很分散。low bias对应就是点都打在靶心附近，所以瞄的是准的，但手不一定稳。
- **确**：varience描述的是样本上训练出来的模型在测试集上的表现，要想在 variance 上表现好，low varience，就要简化模型，减少模型的参数，但这样容易欠拟合(unfitting)，欠拟合对应上图是 high bias，点偏离中心。low variance对应就是点都打的很集中，但不一定是靶心附近，手很稳，但是瞄的不准。

这个靶子上的点(hits)可以理解成一个一个的拟合模型，如果许多个拟合模型都聚集在一堆，位置比较偏，如图中 high bias low variance 这种情景，意味着无论什么样子的数据灌进来，拟合的模型都差不多，这个模型过于简陋了，参数太少了，复杂度太低了，这就是欠拟合；但如果是图中 low bias high variance 这种情景，你看，所有拟合模型都围绕中间那个 correct target 均匀分布，但又不够集中，很散，这就意味着，灌进来的数据一有风吹草动，拟合模型就跟着剧烈变化，这说明这个拟合模型过于复杂了，不具有普适性，就是过拟合。

所以 bias 和 variance 的选择是一个 tradeoff，过高的 variance 对应的概念，有点『剑走偏锋』『矫枉过正』的意思，如果说一个人 variance 比较高，可以理解为，这个人性格比较极端偏执，眼光比较狭窄，没有大局观。而过高的 bias 对应的概念，有点像『面面俱到』『大巧若拙』的意思，如果说一个人 bias 比较高，可以理解为，这个人是个好好先生，谁都不得罪，圆滑世故，说话的时候，什么都说了，但又好像什么都没说，眼光比较长远，有大局观。（感觉好分裂 ）

**注：关于这个偏执和好好先生的表述，不是非常严谨，对这两个词的不同理解会导致截然相反的推理，如果你看完这段觉得有点困惑，可以去看评论区的讨论，不得不感叹一下，在准确描述世界运行的规律这件事上，数学比文学要准确且无歧义的多。**
在林轩田的课中，对 bias 和 variance 还有这样一种解释，我试着不用数学公式抽象的简单概括一下：

我们训练一个模型的最终目的，是为了让这个模型在测试数据上拟合效果好，也就是 Error(test)比较小，但在实际问题中，test data我们是拿不到的，也根本不知道 test data的内在规律（如果知道了，还 machine learning个啥 ），所以我们通过什么策略来减小 Error(test)呢？

分两步：

1. 让 Error(train)尽可能小
2. 让 Error(train)尽可能等于 Error(test)

三段论，因为 A 小，而且 A=B，这样 B 就小。

那么怎么让 Error(train)尽可能小呢？-> 把模型复杂化，把参数搞得多多的，这个好理解，十元线性回归，肯定 error 要比二元线性回归低啊。-> low bias

然后怎么让 Error(train)尽可能等于 Error(test)呢？-> 把模型简单化，把参数搞得少少的。什么叫 Error(train)=Error(test)？就是模型没有偏见，对 train test一视同仁。那么怎样的模型更容易有这这种一视同仁的特性，换句话说，更有『通用性』，对局部数据不敏感？那就是简单的模型。-> low variance





# 相关

- [Understanding the Bias-Variance Tradeoff](https://link.zhihu.com/?target=http%3A//scott.fortmann-roe.com/docs/BiasVariance.html)
- [机器学习中的 Bias(偏差)，Error(误差)，和 Variance(方差)有什么区别和联系？](https://www.zhihu.com/question/27068705)
