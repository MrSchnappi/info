---
title: 44 贝叶斯网的推断
toc: true
date: 2018-06-28 12:10:27
---

# 贝叶斯网的推断


贝叶斯网训练好之后就能用来回答“查询”(query)，即通过一些属性变量的观测值来推测其他属性变量的取值。例如在西瓜问题中，若我们观测到西瓜 色泽青绿、敲声浊响、根蒂蜷缩，想知道它是否成熟、甜度如何。这样通过已知变量观测值来推测待查询变量的过程称为 “推断”(inference)，已知变量观 测值称为 “证据” (evidence).


最理想的是直接根据贝叶斯网定义的联合概率分布来精确计算后验概率, 不幸的是，这样的“精确推断”已被证明是 NP 难的[Cooper, 1990]；换言之，当网络结点较多、连接稠密时，难以进行精确推断，此时需借助“近似推断”， 通过降低精度要求，在有限时间内求得近似解。

在现实应用中，贝叶斯网的近似推断常使用吉布斯采样(Gibbs sampling)来完成，这是一种随机采样方法，我们来看看它是如何工作的.

令 $\mathbf{Q}=\left\{Q_{1}, Q_{2}, \ldots, Q_{n}\right\}$ 表示待查询变量， $\mathbf{E}=\left\{E_{1}, E_{2}, \dots, E_{k}\right\}$ 为证据变量，已知其取值为 $\mathbf{e}=\left\{e_{1}, e_{2}, \ldots, e_{k}\right\}$ 。目标是计算后验概率 $P(\mathbf{Q}=\mathbf{q} | \mathbf{E}=\mathbf{e})$ , 其中 $\mathbf{q}=\left\{q_{1}, q_{2}, \dots, q_{n}\right\}$ 是待查询变量的一组取值。以西瓜问题为例，待查询变量为 $\mathbf{Q}=\{好瓜，甜度\}$ ，证据变量为 $\mathbf{E}=\{色泽，敲声，根蒂\} 且已知其取值为 $\mathbf{e} = \{青绿，浊响，蜷缩\}$ ，查询的目标值是 $\mathbf{q} = \{是，高\}$，即这是好瓜且甜度高的概率有多大.

如图 7.5 所示，吉布斯采样算法先隨机产生一个与证据 $\mathbf{E}=\mathbf{e}$  一致的样本 $\mathbf{q}^{0}$ 作为初始点，然后每步从当前样本出发产生下一个样本。具体来说，在第 $t$ 次采样中，算法先假设 $\mathbf{q}^{t}=\mathbf{q}^{t-1}$ ，然后对非证据变量逐个进行采样改变其取值，采样概率根据贝叶斯网 $B$ 和其他变量的当前取值(即 $\mathbf{Z}=\mathbf{z}$ )计算获得。假定经过 $T$ 次采样得到的与 $\mathbf{q}$ 一致的样本共有 $n_{q}$ 个，则可近似估算出后验概率：

$$
P(\mathbf{Q}=\mathbf{q} | \mathbf{E}=\mathbf{e}) \simeq \frac{n_{q}}{T}\tag{7.33}
$$


实质上，吉布斯采样是在贝叶斯网所有变量的联合状态空间与证据 $\mathbf{E}=\mathbf{e}$ 一致的子空间中进行“随机漫步” (random walk)。每一步仅依赖于前一步 的状态，这是一个“马尔可夫链” (Markov chain)。在一定条件下，无论从 什么初始状态开始，马尔可夫链第 $t$ 步的状态分布在 $t\rightarrow \infty$ 时必收敛于一个平稳分布(stationary distribution)；对于吉布斯采样来说，这个分布恰好是 $P(\mathbf{Q} | \mathbf{E}=\mathbf{e})$ 。因此，在 $T$ 很大时，吉布斯采样相当于根据 $P(\mathbf{Q} | \mathbf{E}=\mathbf{e})$ 采样，从而保证了式(7.33)收敛于 $P(\mathbf{Q}=\mathbf{q} | \mathbf{E}=\mathbf{e})$。

<center>

![](http://images.iterate.site/blog/image/180628/4KGAIC68l4.png?imageslim){ width=55% }


</center>

需注意的是，由于马尔可夫链通常需很长时间才能趋于平稳分布，因此吉布斯采样算法的收敛速度较慢。此外，若贝叶斯网中存在极端概率 “0” 或 “1”，则不能保证马尔可夫链存在平稳分布，此时吉布斯采样会给出错误的估计结果。






# 相关

- 《机器学习》周志华
