---
title: 1.21 PCA 算法流程
toc: true
date: 2019-09-03
---
# PCA 算法流程总结

输入：$n​$ 维样本集 $D = \left( x^{(1)},x^{(2)},...,x^{(m)} \right)​$ ，目标降维的维数 $n'​$ 。

输出：降维后的新样本集 $D'  = \left( z^{(1)},z^{(2)},...,z^{(m)} \right)$ 。

主要步骤如下：

1. 对所有的样本进行中心化，$x^{(i)} = x^{(i)} - \frac{1}{m} \sum^m_{j=1} x^{(j)}$ 。
2. 计算样本的协方差矩阵 $XX^T​$ 。
3. 对协方差矩阵 $XX^T$ 进行特征值分解。
4. 取出最大的 $n'$ 个特征值对应的特征向量 $\{ w_1,w_2,...,w_{n'} \}$ 。
5. 标准化特征向量，得到特征向量矩阵 $W$ 。<span style="color:red;">怎么标准化特征向量的？</span>
6. 转化样本集中的每个样本 $z^{(i)} = W^T x^{(i)}$ 。
7. 得到输出矩阵 $D' = \left( z^{(1)},z^{(2)},...,z^{(n)} \right)​$ 。


注：在降维时，有时不明确目标维数，而是指定降维到的主成分比重阈值 $k(k \in (0,1])​$ 。假设 $n​$ 个特征值为 $\lambda_1 \geqslant \lambda_2 \geqslant ... \geqslant \lambda_n​$ ，则 $n'​$ 可从 $\sum^{n'}_{i=1} \lambda_i \geqslant k \times \sum^n_{i=1} \lambda_i ​$ 得到。<span style="color:red;">嗯。</span>





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions) 原文
