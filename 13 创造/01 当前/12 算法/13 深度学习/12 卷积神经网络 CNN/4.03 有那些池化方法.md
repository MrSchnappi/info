---
title: 4.03 有那些池化方法
toc: true
date: 2019-09-03
---

## 5.7 有哪些池化方法？

池化操作通常也叫做子采样(Subsampling)或降采样(Downsampling)，在构建卷积神经网络时，往往会用在卷积层之后，通过池化来降低卷积层输出的特征维度，有效减少网络参数的同时还可以防止过拟合现象。

池化操作可以降低图像维度的原因，本质上是因为图像具有一种“静态性”的属性，这个意思是说在一个图像区域有用的特征极有可能在另一个区域同样有用。<span style="color:red;">一个区域有用的特征极有可能在另一个区域同样有用，是什么意思？为什么这个是池化操作的原理？池化操作跟这个有关系吗？</span>

因此，为了描述一个大的图像，很直观的想法就是对不同位置的特征进行聚合统计。例如，可以计算图像在固定区域上特征的平均值 (或最大值)来代表这个区域的特征。<span style="color:red;">嗯，来表达这个区域的特征，这个是理解的。</span>

|                   池化类型                   |                                           示意图                                            | 作用                                                                                                                                                                                                                                                 |
|:--------------------------------------------:|:-------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|          一般池化(General Pooling)           | ![](http://images.iterate.site/blog/image/20190722/o3iss32MWmXU.png?imageslim){ width=100% } | 通常包括最大池化(Max Pooling)和平均池化(Mean Pooling)。以最大池化为例，池化范围 $(2\times2)$ 和滑窗步长 $(stride=2)$ 相同，仅提取一次相同区域的范化特征。                                                                                            |
|        重叠池化(Overlapping Pooling)         | ![](http://images.iterate.site/blog/image/20190722/prEf5VXD3Ifu.png?imageslim){ width=100% } | 与一般池化操作相同，但是池化范围 $P_{size}$ 与滑窗步长 $stride$ 关系为 $P_{size}>stride$，同一区域内的像素特征可以参与多次滑窗提取，得到的特征表达能力更强，但计算量更大。<span style="color:red;">嗯，特征表达能力更强，那么需不需要进行重叠池化？还是说一般池化已经够了？</span>                                                                           |
| 空间金字塔池化 $^*$(Spatial Pyramid Pooling) | ![](http://images.iterate.site/blog/image/20190722/B8jQmlnCq3hc.png?imageslim){ width=100% } | 在进行多尺度目标的训练时，卷积层允许输入的图像特征尺度是可变的，紧接的池化层若采用一般的池化方法会使得不同的输入特征输出相应变化尺度的特征，而卷积神经网络中最后的全连接层则无法对可变尺度进行运算，因此需要对不同尺度的输出特征采样到相同输出尺度。<span style="color:red;">怎么把不同尺度的输出特征采样到相同输出尺度？</span><span style="color:blue;">嗯，下面说明中有写。</span> |

> 表 5.6 池化分类
>
> SPPNet$^{[3]}$ 就引入了空间池化的组合，对不同输出尺度采用不同的滑窗大小和步长以确保输出尺度相同 $(win_{size}=\lceil \frac{in}{out}\rceil; stride=\lfloor \frac{in}{out}\rfloor; )$，同时用如金字塔式叠加的多种池化尺度组合，以提取更加丰富的图像特征。常用于多尺度训练和目标检测中的区域提议网络(Region Proposal Network)的兴趣区域(Region of Interest)提取。<span style="color:red;">嗯，不错呀，是可以这么做，但是怎么使用多种池化尺度组合的？什么是区域提议网络？什么是兴趣提取？</span>








# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
