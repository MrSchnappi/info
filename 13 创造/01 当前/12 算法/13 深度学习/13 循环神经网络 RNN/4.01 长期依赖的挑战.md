---
title: 4.01 长期依赖的挑战
toc: true
date: 2019-06-05
---
# 可以补充进来的

- 许多资料提供了更深层次的讨论


# 长期依赖的挑战

学习循环网络长期依赖的数学挑战之前有介绍过。

根本问题是，经过许多阶段传播后的梯度倾向于消失（大部分情况）或爆炸（很少，但对优化过程影响很大）。

即使我们假设循环网络是参数稳定的（可存储记忆，且梯度不爆炸），但长期依赖的困难来自比短期相互作用指数小的权重（涉及许多 Jacobian 相乘）。


循环网络涉及相同函数的多次组合，每个时间步一次。这些组合可以导致极端非线性行为，如图 10.15 所示。



<center>

![](http://images.iterate.site/blog/image/20190718/94NLmpYPetLU.png?imageslim){ width=55% }

</center>

> 10.15 重复组合函数。当组合许多非线性函数（如这里所示的线性 tanh 层）时，结果是高度非线性的，通常大多数值与微小的导数相关联，也有一些具有大导数的值，以及在增加和减小之间的多次交替。% ??此处，我们绘制从 100 维隐藏状态降到单个维度的线性投影，绘制于 $y$ 轴上。$x$ 轴是 100 维空间中沿着随机方向的初始状态的坐标。因此，我们可以将该图视为高维函数的线性截面。曲线显示每个时间步之后的函数，或者等价地，转换函数被组合一定次数之后。




特别地，循环神经网络所使用的函数组合有点像矩阵乘法。我们可以认为，循环联系


$$\begin{aligned}
 \boldsymbol h^{(t)} = \boldsymbol W^\top \boldsymbol h^{(t-1)}
\end{aligned}$$


是一个非常简单的、缺少非线性激活函数和输入 $\boldsymbol x$ 的循环神经网络。由之前的长期依赖的学习我们知道，这种递推关系本质上描述了幂法。

它可以被简化为


$$\begin{aligned}
 \boldsymbol h^{(t)} = (\boldsymbol W^t)^\top \boldsymbol h^{(0)},
\end{aligned}$$


而当 $\boldsymbol W$ 符合下列形式的特征分解


$$\begin{aligned}
 \boldsymbol W = \boldsymbol Q \boldsymbol \Lambda \boldsymbol Q^\top,
\end{aligned}$$


其中 $\boldsymbol Q$ 正交，循环性可进一步简化为


$$\begin{aligned}
 \boldsymbol h^{(t)} = \boldsymbol Q^\top \boldsymbol \Lambda^t \boldsymbol Q \boldsymbol h^{(0)}.
\end{aligned}$$


特征值提升到 $t$ 次后，导致幅值不到一的特征值衰减到零，而幅值大于一的就会激增。任何不与最大特征向量对齐的 $\boldsymbol h^{(0)}$ 的部分将最终被丢弃。


这个问题是针对循环网络的。在标量情况下，想象多次乘一个权重 $w$。该乘积 $w^t$ 消失还是爆炸取决于 $w$ 的幅值。然而，如果每个时刻使用不同权重 $w^{(t)}$ 的非循环网络，情况就不同了。如果初始状态给定为 $1$，那么时刻 $t$ 的状态可以由 $\prod_t w^{(t)}$ 给出。假设 $w^{(t)}$ 的值是随机生成的，各自独立，且有 $0$ 均值 $v$ 方差。乘积的方差就为 $\mathcal O(v^n)$。为了获得某些期望的方差 $v^*$，我们可以选择单个方差为 $v=\sqrt[n]{v^*}$ 权重。因此，非常深的前馈网络通过精心设计的比例可以避免梯度消失和爆炸问题，如 {Sussillo14}所主张的。


RNN 梯度消失和爆炸问题是由不同研究人员独立发现。有人可能会希望通过简单地停留在梯度不消失或爆炸的参数空间来避免这个问题。不幸的是，为了储存记忆并对小扰动具有鲁棒性，RNN 必须进入参数空间中的梯度消失区域。具体来说，每当模型能够表示长期依赖时，长期相互作用的梯度幅值就会变得指数小（相比短期相互作用的梯度幅值）。这并不意味着这是不可能学习的，由于长期依赖关系的信号很容易被短期相关性产生的最小波动隐藏，因而学习长期依赖可能需要很长的时间。实践中，{Bengio1994ITNN}的实验表明，当我们增加了需要捕获的依赖关系的跨度，基于梯度的优化变得越来越困难，SGD 在长度仅为 10 或 20 的序列上成功训练传统 RNN 的概率迅速变为 0。

将循环网络作为动力系统更深入探讨的资料见 Doya93,Bengio1994ITNN,Siegelmann+Sontag-1995 及 Pascanu-et-al-ICML2013 的回顾。

本章的其余部分将讨论目前已经提出的降低学习长期依赖（在某些情况下，允许一个 RNN 学习横跨数百步的依赖）难度的不同方法，但学习长期依赖的问题仍是深度学习中的一个主要挑战。



# 相关

- 《深度学习》花书
