---
title: 1.04 GAN 的 Loss 为什么降不下去
toc: true
date: 2019-09-03
---

### 7.1.5 GAN 的 Loss 为什么降不下去？

对于很多 GAN 的初学者在实践过程中可能会纳闷，为什么 GAN 的 Loss 一直降不下去。GAN 到底什么时候才算收敛？

其实，作为一个训练良好的 GAN，其 Loss 就是降不下去的。衡量 GAN 是否训练好了，只能由人肉眼去看生成的图片质量是否好。不过，对于没有一个很好的评价是否收敛指标的问题，也有许多学者做了一些研究，后文提及的 WGAN 就提出了一种新的 Loss 设计方式，较好的解决了难以判断收敛性的问题。下面我们分析一下 GAN 的 Loss 为什么降不下去？

对于判别器而言，GAN 的 Loss 如下：

$$
\mathop {\min }\limits_G \mathop {\max }\limits_D V(D,G) = {\rm E}_{x\sim{p_{data}(x)}}[\log D(x)] + {\rm E}_{z\sim{p_z}(z)}[\log (1 - D(G(z)))]
$$

从 $\mathop {\min }\limits_G \mathop {\max }\limits_D V(D,G)​$ 可以看出，生成器和判别器的目的相反，也就是说两个生成器网络和判别器网络互为对抗，此消彼长。不可能 Loss 一直降到一个收敛的状态。


- 对于生成器，其 Loss 下降快，很有可能是判别器太弱，导致生成器很轻易的就"愚弄"了判别器。
- 对于判别器，其 Loss 下降快，意味着判别器很强，判别器很强则说明生成器生成的图像不够逼真，才使得判别器轻易判别，导致 Loss 下降很快。

也就是说，无论是判别器，还是生成器。loss 的高低不能代表生成器的好坏。一个好的 GAN 网络，其 GAN Loss 往往是不断波动的。

看到这里可能有点让人绝望，似乎判断模型是否收敛就只能看生成的图像质量了。实际上，后文探讨的 WGAN，提出了一种新的 loss 度量方式，让我们可以通过一定的手段来判断模型是否收敛。<span style="color:red;">嗯，什么度量方法？</span>
