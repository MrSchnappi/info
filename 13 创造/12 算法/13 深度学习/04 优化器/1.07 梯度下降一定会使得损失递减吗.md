---
title: 1.07 梯度下降一定会使得损失递减吗
toc: true
date: 2019-08-27
---

# 梯度下降的理论基础

## 问题

当用梯度下降解决问题：

$$\theta^∗= \underset{ \theta }{\operatorname{arg\ max}}  L(\theta) \tag1$$

每次更新参数 $\theta$，都得到一个新的 $\theta$，它都使得损失函数更小。即：

$$L(\theta^0) >L(\theta^1)>L(\theta^2)>···\tag{13}$$

上述结论正确吗？

结论是不正确的。。。

## 数学理论

![mark](http://images.iterate.site/blog/image/20190818/NrhM4jvfCzi4.png?imageslim)

比如在 $\theta^0$ 处，可以在一个小范围的圆圈内找到损失函数细小的 $\theta^1$，不断的这样去寻找。

接下来就是如果在小圆圈内快速的找到最小值？


### 泰勒展开式

先介绍一下泰勒展开式

#### 定义
若 $h(x)$ 在 $x=x_0$ 点的某个领域内有无限阶导数（即无限可微分，infinitely differentiable），那么在此领域内有：

$$
\begin{aligned}
h(x)  &= \sum_{k=0}^{\infty }\frac{h^k(x_0)}{k!}(x-x_0)^k  \\
& =h(x_0)+{h}'(x_0)(x−x_0)+\frac{h''(x_0)}{2!}(x−x_0)^2+⋯
\tag{14}
\end{aligned}
$$


当 $x$ 很接近 $x_0$ 时，有 $h(x)≈h(x_0)+{h}'(x_0)(x−x_0)$
式 14 就是函数 $h(x)$ 在 $x=x_0$ 点附近关于 $x$ 的幂函数展开式，也叫泰勒展开式。

举例：

![mark](http://images.iterate.site/blog/image/20190818/v9LmdQJUIA9O.png?imageslim)

图中 3 条蓝色线是把前 3 项作图，橙色线是 $sin(x)$。

#### 多变量泰勒展开式
下面是两个变量的泰勒展开式

![mark](http://images.iterate.site/blog/image/20190818/UoRfjDczbdUs.png?imageslim)

### 利用泰勒展开式简化
回到之前如何快速在圆圈内找到最小值。基于泰勒展开式，在 $(a,b)$ 点的红色圆圈范围内，可以将损失函数用泰勒展开式进行简化：

![mark](http://images.iterate.site/blog/image/20190818/10cNPfMaM9Ho.png?imageslim)

将问题进而简化为下图：

![mark](http://images.iterate.site/blog/image/20190818/DN8EQVTDaaPm.png?imageslim)

不考虑 s 的话，可以看出剩下的部分就是两个向量 $(\triangle \theta_1,\triangle \theta_2)$ 和  $(u,v)$ 的内积，那怎样让它最小，就是和向量 $(u,v)$ 方向相反的向量

![mark](http://images.iterate.site/blog/image/20190818/xnoU6od1GBrQ.png?imageslim)

然后将 u 和 v 带入。

![mark](http://images.iterate.site/blog/image/20190818/i0zVBtNjTSyg.png?imageslim)
$$L(\theta)\approx s+u(\theta_1 - a)+v(\theta_2 - b) \tag{14}$$

发现最后的式子就是梯度下降的式子。但这里用这种方法找到这个式子有个前提，泰勒展开式给的损失函数的估算值是要足够精确的，而这需要红色的圈圈足够小（也就是学习率足够小）来保证。所以理论上每次更新参数都想要损失函数减小的话，即保证式 1-2 成立的话，就需要学习率足够足够小才可以。

所以实际中，当更新参数的时候，如果学习率没有设好，是有可能式 1-2是不成立的，所以导致做梯度下降的时候，损失函数没有越来越小。

式 1-2只考虑了泰勒展开式的一次项，如果考虑到二次项（比如牛顿法），在实际中不是特别好，会涉及到二次微分等，多很多的运算，性价比不好。







# 相关

- [leeml-notes](https://github.com/datawhalechina/leeml-notes)
