---
title: 1.01 添加正则化项
toc: true
date: 2019-08-31
---
# 可以补充进来的

- 常通过交叉验证法来估计


# 参数范数惩罚

正则化在深度学习的出现前就已经被使用了数十年。并不是新东西。

线性模型，如线性回归和逻辑回归可以使用简单、直接、有效的正则化策略。

许多正则化方法通过对目标函数 $J$ 添加一个参数范数惩罚 $\Omega(\boldsymbol \theta)$，限制模型（如神经网络、线性回归或逻辑回归）的学习能力。

我们将正则化后的目标函数记为 $\tilde{J}$：


$$
\begin{aligned}
\tilde{J}(\boldsymbol \theta;\boldsymbol X, \boldsymbol y) = J(\boldsymbol \theta;\boldsymbol X, \boldsymbol y) + \alpha \Omega(\boldsymbol \theta),
\end{aligned}
$$

其中 $\alpha \in [0, \infty)$ 是权衡范数惩罚项 $\Omega$ 和标准目标函数 $J(\boldsymbol X;\boldsymbol \theta)$ 相对贡献的超参数。将 $\alpha$ 设为 0 表示没有正则化。$\alpha$ 越大，对应正则化惩罚越大。<span style="color:red;">嗯， $\alpha$ 要怎么设定呢？</span>

当我们的训练算法最小化正则化后的目标函数 $\tilde{J}$ 时，它会降低原始目标 $J$ 关于训练数据的误差并同时减小在某些衡量标准下参数 $\boldsymbol \theta$（或参数子集）的规模。选择不同的参数范数 $\Omega$ 会偏好不同的解。

在神经网络的情况下，有时希望对网络的每一层使用单独的惩罚，并分配不同的 $\alpha$ 系数。寻找合适的多个超参数的代价很大，因此为了减少搜索空间，我们会在所有层使用相同的权重衰减。<span style="color:red;">嗯。那么有没有每层使用不同的 $\alpha$ 系数的？</span>



下面，我们会讨论各种范数惩罚对模型的影响。<span style="color:red;">嗯。</span>


# 相关

- 《深度学习》花书
