# 多进程


## 多进程 multiprocessing

举例：

```python
from multiprocessing import Process
import os


# 子进程要执行的代码
def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))


if __name__ == '__main__':
    print('Parent process %s.' % os.getpid())
    p = Process(target=run_proc, args=('test',))
    print('Child process will start.')
    p.start()
    p.join()
    print('Child process end.')
```

输出：

```
Parent process 5816.
Child process will start.
Run child process test (1304)...
Child process end.
```

说明：

- `multiprocessing` 模块提供了一个 `Process` 类来代表一个进程对象
- `join()` 方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。<span style="color:red;">嗯，好的。</span>
- multiprocessing 模块是跨平台的。



## 进程池 Pool

如果要启动大量的子进程，可以用进程池的方式批量创建子进程：

```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    p = Pool(4)
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))
    print('Waiting for all subprocesses done...')
    p.close()
    print('close pool...')
    p.join()
    print('All subprocesses done.')
```

执行结果如下：

```
Parent process 8788.
Waiting for all subprocesses done...
close pool...
Run task 0 (3564)...
Run task 1 (6680)...
Run task 2 (3484)...
Run task 3 (13212)...
Task 2 runs 0.01 seconds.
Run task 4 (3484)...
Task 4 runs 0.72 seconds.
Task 3 runs 0.96 seconds.
Task 1 runs 1.27 seconds.
Task 0 runs 1.50 seconds.
All subprocesses done.
```

说明：

- <span style="color:red;">好像是 `p.close()` 之后，线程池里面的子进程才开始运行</span>
- 对 `Pool` 对象调用 `join()` 方法会等待所有子进程执行完毕，调用 `join()` 之前必须先调用 `close()`，调用 `close()` 之后就不能继续添加新的 `Process` 了。<span style="color:red;">那么能动态添加子进程吗？还是说线程池只能这样？</span>
- 请注意输出的结果，task `0`，`1`，`2`，`3` 是立刻执行的，而 task `4` 要等待前面某个 task 完成后才执行，这是因为 `Pool` 的默认大小在我的电脑上是 4，因此，最多同时执行 4 个进程。这是`Pool`有意设计的限制，并不是操作系统的限制。如果改成：`p = Pool(5)` 就可以同时跑 5 个进程。<span style="color:red;">嗯。</span>
- 由于`Pool`的默认大小是 CPU 的核数，如果你拥有 8 核 CPU，你要提交至少 9 个子进程才能看到上面的等待效果。

注意：

- 可以很明显看到，由于设置了 `Pool(4)` ，所以第四个子进程是等线程池里面有一个进程完成之后才开始执行。而这个 4 是跟你的电脑的核数有关的，如果你是 2 核电脑，那么即使你设置了 4，也会只有两个 task 同时运行。也就是说 task 2 要等前面的 task 0 和 task 1 有一个运行完之后才开始运行。可以这只 `Pool(20)`, `range(30)` 看下。



## 启动外部进程当做子进程 subprocess

很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。

`subprocess` 模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。<span style="color:red;">嗯。</span>

下面的例子演示了如何在 Python 代码中运行命令 `nslookup www.Python.org`，这和命令行直接运行的效果是一样的：<span style="color:red;">之前从来没使用过 subprocess</span>

```python
import subprocess

print('$ nslookup www.Python.org')
r = subprocess.call(['nslookup', 'www.Python.org'])
print('Exit code:', r)
```

运行结果：

```
$ nslookup www.Python.org
Server:        192.168.19.4
Address:    192.168.19.4#53

Non-authoritative answer:
www.Python.org    canonical name = Python.map.fastly.net.
Name:    Python.map.fastly.net
Address: 199.27.79.223

Exit code: 0
```

如果子进程还需要输入，则可以通过 `communicate()` 方法输入：<span style="color:red;">好的，还没这么使用过。</span>

```python
import subprocess

print('$ nslookup')
p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
output, err = p.communicate(b'set q=mx\nPython.org\nexit\n')
print(output.decode('utf-8'))
print('Exit code:', p.returncode)
```

上面的代码相当于在命令行执行命令`nslookup`，然后手动输入：

```
set q=mx
Python.org
exit
```

运行结果如下：

```
$ nslookup
Server:        192.168.19.4
Address:    192.168.19.4#53

Non-authoritative answer:
Python.org    mail exchanger = 50 mail.Python.org.

Authoritative answers can be found from:
mail.Python.org    internet address = 82.94.164.166
mail.Python.org    has AAAA address 2001:888:2000:d::a6


Exit code: 0
```



## 进程间通信


`Process` 之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。

Python 的 `multiprocessing` 模块包装了底层的机制，提供了`Queue`、`Pipes` 等多种方式来交换数据。<span style="color:red;">Pipes 也要补充个例子，而且，可以与 C# 的进程进行通信吗？按这个来看感觉应该是可以的吧？确认下。</span><span style="color:red;">进程之间的通信总共有哪些方法？优缺点是什么？要统一单独总结下。</span>

我们以 `Queue` 为例，在父进程中创建两个子进程，一个往 `Queue` 里写数据，一个从 `Queue` 里读数据：

```python
from multiprocessing import Process, Queue
import os, time, random


# 写数据进程执行的代码:
def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())


# 读数据进程执行的代码:
def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)


if __name__ == '__main__':
    # 父进程创建 Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程 pw，写入:
    pw.start()
    # 启动子进程 pr，读取:
    pr.start()
    # 等待 pw 结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()
```

运行结果如下：

```
Process to write: 12404
Put A to queue...
Process to read: 3564
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.
```

在 Unix/Linux下，`multiprocessing` 模块封装了`fork()`调用，使我们不需要关注 `fork()` 的细节。由于 Windows 没有 `fork` 调用，因此，`multiprocessing` 需要“模拟”出 `fork` 的效果，父进程所有 Python 对象都必须通过 pickle 序列化再传到子进程去，所有，如果 `multiprocessing`在 Windows 下调用失败了，要先考虑是不是 pickle 失败了。<span style="color:red;">没很明白，父进程所有 Python 对象是先通过 pickle 序列化之后再传到子进程里面的。弄清楚。</span>



补充：

- <span style="color:red;">Pipes 也要补充个例子，而且，可以与 C# 的进程进行通信吗？按这个来看感觉应该是可以的吧？确认下。</span><span style="color:red;">进程之间的通信总共有哪些方法？优缺点是什么？要统一单独总结下。</span>
- <span style="color:red;">进程间的通信还是要再补充下，包括与别的语言开发的程序之间的通信。</span>



## 分布式进程

在 Thread 和 Process中，应当优选 Process，因为 Process 更稳定，而且，Process 可以分布到多台机器上，而 Thread 最多只能分布到同一台机器的多个 CPU 上。<span style="color:red;">Process 可以分不到多台机器上是什么意思？一个主 Process 的子 Process 可以运行在别的设备上吗？怎么做到的？</span>

Python的 `multiprocessing` 模块不但支持多进程，其中 `managers` 子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于 `managers` 模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。

举个例子：如果我们已经有一个通过 `Queue` 通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？<span style="color:red;">是呀？怎么实现？</span>

原有的 `Queue` 可以继续使用，但是，通过 `managers` 模块把 `Queue` 通过网络暴露出去，就可以让其他机器的进程访问 `Queue` 了。<span style="color:red;">怎么暴露出去？</span>

我们先看服务进程，服务进程负责启动`Queue`，把`Queue`注册到网络上，然后往`Queue`里面写入任务：

```py
# task_master.py

import random, time, queue
from multiprocessing.managers import BaseManager
import dill

# 发送任务的队列:
task_queue = queue.Queue()
# 接收结果的队列:
result_queue = queue.Queue()

def get_task_queue():
    global task_queue
    return task_queue

def get_result_queue():
    global result_queue
    return result_queue

# 从 BaseManager 继承的 QueueManager:
class QueueManager(BaseManager):
    pass


if __name__ == "__main__":
    # 把两个 Queue 都注册到网络上, callable参数关联了 Queue 对象:
    QueueManager.register('get_task_queue', callable=get_task_queue)
    QueueManager.register('get_result_queue', callable=get_result_queue)
    # QueueManager.register('get_task_queue', callable=dill.dumps(lambda: task_queue))
    # QueueManager.register('get_result_queue', callable=dill.dumps(lambda: result_queue))

    # 绑定端口 5000, 设置验证码'abc':
    manager = QueueManager(address=('127.0.0.1', 5010), authkey=b'abc')
    # 启动 Queue:
    manager.start()
    # 获得通过网络访问的 Queue 对象:
    task = manager.get_task_queue()
    result = manager.get_result_queue()
    # 放几个任务进去:
    for i in range(10):
        n = random.randint(0, 10000)
        print('Put task %d...' % n)
        task.put(n)
    # 从 result 队列读取结果:
    print('Try get results...')
    for i in range(10):
        r = result.get(timeout=10)
        print('Result: %s' % r)
    # 关闭:
    manager.shutdown()
    print('master exit.')
```


<span style="color:red;">从原网页上的程序好像有点问题，这个 multiprocess 好像一定要放到函数里面的，不能放在外面。而且，直接用 callable=lambda: result_queue 这样写，好像是有问题的，说 pickle 无法 dump lambda ，这个问题没有解决。</span>

<span style="color:red;">注意，上面这个 py 是跟下面这个 task_worker.py 配合使用的。</span>

请注意，当我们在一台机器上写多进程程序时，创建的`Queue`可以直接拿来用，但是，在分布式多进程环境下，添加任务到`Queue`不可以直接对原始的`task_queue`进行操作，那样就绕过了`QueueManager`的封装，必须通过`manager.get_task_queue()`获得的`Queue`接口添加。

然后，在另一台机器上启动任务进程（本机上启动也可以）：

```py
# task_worker.py

import time, sys, queue
from multiprocessing.managers import BaseManager

# 创建类似的 QueueManager:
class QueueManager(BaseManager):
    pass

# 由于这个 QueueManager 只从网络上获取 Queue，所以注册时只提供名字:
QueueManager.register('get_task_queue')
QueueManager.register('get_result_queue')

# 连接到服务器，也就是运行 task_master.py的机器:
server_addr = '127.0.0.1'
print('Connect to server %s...' % server_addr)
# 端口和验证码注意保持与 task_master.py设置的完全一致:
m = QueueManager(address=(server_addr, 5000), authkey=b'abc')
# 从网络连接:
m.connect()
# 获取 Queue 的对象:
task = m.get_task_queue()
result = m.get_result_queue()
# 从 task 队列取任务，并把结果写入 result 队列:
for i in range(10):
    try:
        n = task.get(timeout=1)
        print('run task %d * %d...' % (n, n))
        r = '%d * %d = %d' % (n, n, n*n)
        time.sleep(1)
        result.put(r)
    except Queue.Empty:
        print('task queue is empty.')
# 处理结束:
print('worker exit.')
```

任务进程要通过网络连接到服务进程，所以要指定服务进程的 IP。

现在，可以试试分布式进程的工作效果了。先启动`task_master.py`服务进程：

```
$ Python3 task_master.py
Put task 3411...
Put task 1605...
Put task 1398...
Put task 4729...
Put task 5300...
Put task 7471...
Put task 68...
Put task 4219...
Put task 339...
Put task 7866...
Try get results...
```

`task_master.py`进程发送完任务后，开始等待`result`队列的结果。现在启动`task_worker.py`进程：

```
$ Python3 task_worker.py
Connect to server 127.0.0.1...
run task 3411 * 3411...
run task 1605 * 1605...
run task 1398 * 1398...
run task 4729 * 4729...
run task 5300 * 5300...
run task 7471 * 7471...
run task 68 * 68...
run task 4219 * 4219...
run task 339 * 339...
run task 7866 * 7866...
worker exit.
```

`task_worker.py`进程结束，在`task_master.py`进程中会继续打印出结果：

```
Result: 3411 * 3411 = 11634921
Result: 1605 * 1605 = 2576025
Result: 1398 * 1398 = 1954404
Result: 4729 * 4729 = 22363441
Result: 5300 * 5300 = 28090000
Result: 7471 * 7471 = 55815841
Result: 68 * 68 = 4624
Result: 4219 * 4219 = 17799961
Result: 339 * 339 = 114921
Result: 7866 * 7866 = 61873956
```

这个简单的 Master/Worker 模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个 worker，就可以把任务分布到几台甚至几十台机器上，比如把计算 `n*n` 的代码换成发送邮件，就实现了邮件队列的异步发送。<span style="color:red;">厉害！是一个简单但真正的分布式计算！厉害。再琢磨下。</span>

Queue对象存储在哪？注意到`task_worker.py`中根本没有创建 Queue 的代码，所以，Queue对象存储在`task_master.py`进程中：

```ascii
                                             │
┌─────────────────────────────────────────┐     ┌──────────────────────────────────────┐
│task_master.py                           │  │  │task_worker.py                        │
│                                         │     │                                      │
│  task = manager.get_task_queue()        │  │  │  task = manager.get_task_queue()     │
│  result = manager.get_result_queue()    │     │  result = manager.get_result_queue() │
│              │                          │  │  │              │                       │
│              │                          │     │              │                       │
│              ▼                          │  │  │              │                       │
│  ┌─────────────────────────────────┐    │     │              │                       │
│  │QueueManager                     │    │  │  │              │                       │
│  │ ┌────────────┐ ┌──────────────┐ │    │     │              │                       │
│  │ │ task_queue │ │ result_queue │ │<───┼──┼──┼──────────────┘                       │
│  │ └────────────┘ └──────────────┘ │    │     │                                      │
│  └─────────────────────────────────┘    │  │  │                                      │
└─────────────────────────────────────────┘     └──────────────────────────────────────┘
                                             │

                                          Network
```

而`Queue`之所以能通过网络访问，就是通过`QueueManager`实现的。由于`QueueManager`管理的不止一个`Queue`，所以，要给每个`Queue`的网络调用接口起个名字，比如`get_task_queue`。<span style="color:red;">嗯。</span>

`authkey`有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果`task_worker.py`的`authkey`和`task_master.py`的`authkey`不一致，肯定连接不上。<span style="color:red;">嗯。想想还真的有些厉害！</span>

### 小结

Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。

注意 Queue 的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由 Worker 进程再去共享的磁盘上读取文件。<span style="color:red;">嗯。好。</span>


补充：

- 感觉对于这个的理解还是有点不够深，平时的工作中有可以使用这个的场景吗？
- <span style="color:red;">补充真实的例子进来。</span>
