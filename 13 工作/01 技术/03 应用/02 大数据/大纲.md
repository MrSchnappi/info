# 大纲

Spark是可以脱离hadoop运行的，比如数据可以从数据库或者本地文件里面抽取。不过毕竟大数据时代，大家都习惯于将Spark和hadoop通过mesos或者yarn结合起来用；主要用Hadoop的HDFS，当然HBASE或者HIVE这种HDFS之上的组件，Spark也支持。








大数据与数据挖掘的关系是啥？


- 云计算: SaaS/PaaS/Iaas, Openstack, Docker
- 大数据通用处理平台: Spark, Hadoop, ELK
- 资源调度: Yarn, Mesos
- SQL: MySQL, Sqlite, AWS RDS, PostgreSQL
- NoSQL: 
- 缓存: Memcached, Redis, AWS ElastiCache
- 检索: Solr, ElasticSearch, AWS ElasticSearch
- 数据分析: Pig, Hive, Spark SQL, Spark DataFrame, Impala, Phoenix, ELK
- 消息队列: Kafka, RocketMQ, ZeroMQ, ActiveMQ, RabbitMQ
- 流式计算: Storm/JStorm, Spark Streaming, AWS Kinesis
- 日志收集: ELK, Scribe, Flume, Fluentd, AWS CloudTrail
- 机器学习: Mahout, Spark Mlib, TensorFlow(Google), Amazon Machine Learning, DMTK(MS), scikit learn



## 可以补充进来的

