# 特征组合


- 实际上，观察数据，可能能看出更多特征。
- 可能会有各种trick，比如窗口滑动、离散化、归一化、开方、平方、笛卡尔积、多重笛卡尔积等等。在深度学习出来之后，很少使用了。以前是 复杂特征+简单模型，现在是简单特征+复杂模型
- 深度学习只是缓解了特征工程的压力：
  - 除了图像这种特定领域，在个性化推荐等领域，深度学习目前还没有完全取得绝对的优势；究其原因，可能还是数据自身内在结构的问题，使得在其他领域目前还没有发现类似图像+CNN这样的完美CP。
  - 深度学习在缓解特征工程的同时，也带来了模型复杂、不可解释的问题。算法工程师在网络结构设计方面一样要花很多心思来提升效果。概括起来，深度学习代表的简单特征+复杂模型是解决实际问题的另一种方式。



## 数值型特征组合

- 指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征。

比如：


<p align="center">
    <img width="50%" height="70%" src="http://images.iterate.site/blog/image/180728/j43iJd9B7l.png?imageslim">
</p>

这是一个非线性分类问题，但是可以增添一个特征 $x_3=x_1*x_2$ 将其转换为一个线性模型。

常见的特征组合方法：

- [A X B]：将两个特征的值相乘形成的特征组合。
- [A x B x C x D x E]：将五个特征的值相乘形成的特征组合。
- [A x A]：对单个特征的值求平方形成的特征组合。


借助特征组合，线性学习器可以很好扩展到大量数据，并有助于构建复杂模型解决非线性问题。





# 组合特征的抽象

为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。

如：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190826/VRtguwv5ELdc.png?imageslim">
</p>

修改为：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190826/JWAU9qiMbarv.png?imageslim">
</p>


以逻辑回归为例，假设数据的特征向量为 $X=(x_1,x_2,\cdots,x_k)$，则有：

$$Y=sigmoid(\sum_{i}\sum_jw_{ij}<x_i,x_j>)$$

其中 $<x_i，x_j>$ 表示 $x_i$ 和 $x_j$ 的组合特征，$w_{ij}$的维度等于$|x_i|·|x_j|$，$|x_i|$和$|x_j|$分别代表第 $i$ 个特征和第 $j$ 个特征不同取值的个数。


## 使用梯度提升决策树找到有效的组合特征

上述问题：

- 简单地两两组合，依然容易存在参数过多、过拟合等问题，而且并不是所有的特征组合都是有意义的。

需要一种有效的方法来帮助我们找到应该对哪些特征进行组合。


解决方法：

- 一种基于决策树的特征组合寻找方法。<span style="color:red;">还有别的吗？</span>


举例：

原始特征：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190826/VRSNjR74j0Db.png?imageslim">
</p>

构建决策树：如何有效地构造决策树呢？可以采用梯度提升决策树，该方法的思想是每次都在之前构建的决策树的残差上构建下一棵决策树。**？**<span style="color:red;">补充</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190323/mEQ590psryDn.png?imageslim">
</p>

因此：

- 每一条从根节点到叶节点的路径都可以看成一种特征组合的方式。具体来说：
  - “年龄<=35”且“性别=女”。
  - “年龄<=35”且“物品类别=护肤”。
  - “用户类型=付费”且“物品类型=食品”。
  - “用户类型=付费”且“年龄<=40”。

因此，按照上述 4 个特征组合：

- 第 1 个样本 编码为（1，1，0，0），因为同时满足（1）（2），但不满足（3）（4）。
- 第 2 个样本可以编码为（0，0，1，1），因为它同时满足（3）（4），但不满足（1）（2）。



# ID 类特征


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190826/a0aOyM4H8RvH.png?imageslim">
</p>

如果按照组合特征进行拆分：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190826/RqmJtBi7T6wF.png?imageslim">
</p>

那么几乎无法学习。

在这种情况下，一种行之有效的方法是将用户和物品分别用 k 维的低维向量表示（$k<<m$，$k<<n$）

$$Y=sigmoid(\sum_{i}\sum_jw_{ij}<x_i,x_j>)$$

其中，$w_{ij}=x'_i\cdot x'_j$，$x'_i$ 和 $x'_j$ 分别表示 xi 和 xj 对应的低维向量。在上述问题中，需要学习的参数的规模变为 $m×k＋n×k$。熟悉推荐算法的同学很快可以看出来，这其实等价于矩阵分解。

所以，这里也提供了另一个理解推荐系统中矩阵分解的思路。

<span style="color:red;">这个地方没怎么明白，是怎么进行矩阵分解的？</span>
