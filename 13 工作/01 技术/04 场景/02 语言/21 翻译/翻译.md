
![img](http://img.mp.itc.cn/upload/20170614/d86bf319ce1b4fc1875d9b9d6e8a5a73_th.jpg)

神经网络机器翻译

图1概括了神经网络机器翻译，简要的说，就是对源语言的句子进行编码，一般都是用长短时记忆（LSTM）进行编码。编码的结果就是有很多隐节点，每个隐节点代表从句首到当前词汇为止，与句子的语义信息。基于这些隐节点，通过一个注意力的模型来体现不同隐节点对于翻译目标词的作用。通过这样的一个模式对目标语言可以逐词进行生成，直到生成句尾。中间在某一阶段可能会有多个翻译，我们会保留最佳的翻译，从左到右持续。

这里最重要的技术是对于源语言的编码，还有体现不同词汇翻译的，不同作用的注意力模型。我们又持续做了一些工作，引入了语言知识。因为在编码的时候是仅把源语言和目标语言看成字符串，没有体会内在的词汇和词汇之间的修饰关系。我们把句法知识引入到神经网络编码、解码之中，这是传统的长短时记忆LSTM，这是模型，我们引入了句法，得到了更佳的翻译，这使大家看到的指标有了很大程度的提升。

![img](http://img.mp.itc.cn/upload/20170614/c04bbebf364b4dba871f1a3593f7df03_th.jpg)

图2 将知识图谱纳入传统的神经网络机器翻译中

此外，我们还考虑到在很多领域是有知识图谱的，我们想把知识图谱纳入到传统的神经网络机器翻译当中，来规划语言理解的过程。我们的一个假设就是虽然大家的语言可能不一样，但是体现在知识图谱的领域上可能是一致的，就用知识图谱增强编码、解码。具体来讲，就是对于输入句子，先映射到知识图谱，然后再基于知识图谱增强解码过程，使得译文得到进一步改善。

以上两个工作都发表在本领域最重要的会议ACL上，得到很多学者的好评。

![img](http://img.mp.itc.cn/upload/20170614/b5e66e4b471b44ea8a5a26e8b7cf5c7c_th.jpg)

图3 Microsoft Translator Live Feature工作场景
