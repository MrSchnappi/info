---
title: 2
toc: true
date: 2018-07-30
---
推导反向传播理论的四个公式。


2.语言相关
编程语言不算是硬性要求，有的面试官问了，有的干脆没问。我用的最熟的是 c++，Java和 python 也会用，有些面试官听了就会问我一些 c++相关的问题，多数都会问到虚函数和纯虚函数，用 c++面试的同学可以重点看一下这个。工程性开发性的问题问的不多，就一次面试遇到过问我一些预处理、链接库之类的问题。
3.算法 coding
这个基本到哪都会考，动态规划、贪心、树、链表都是常考题。为了应对这种问题我的做法是在 leetcode 上刷题，我也就做了 100 道左右，基本就能应对面试中的算法 coding 了。如果用 c++的话在 leetcode 上可以锻炼使用 STL 容器，许多算法 coding 题用 STL 容器来写非常方便（我个人写这种题已经不用数组了）。另外把答案用一个函数的形式写出来是个很简洁的方法。
4.机器学习
不用说这部分是机器学习面试的重点。面试中遇到的机器学习算法主要有线性回归、朴素贝叶斯、决策树、GDBT、随机森林、Adaboost、逻辑回归（和 Softmax）、SVM、神经网络和卷积神经网络。遇到很多次让写逻辑回归的极大似然估计的推导。SVM会问思想，我 SVM 掌握的太少答的不好。神经网络会问随机梯度下降和反向传播，要写出式子来的。卷积神经网络就遇到过一次，当时不知道后来上网学习了一下挺有意思的。
损失函数、过拟合、算法的优缺点是经常问到的点，另外遇到的其他问题有这么几个：机器学习算法中哪些是回归算法哪些是分类的。他们的产品要做用户流失预测须要提取哪些特征的。其他我还遇到过倒排索引、推荐算法之类的问题。
以上，希望能给即将找工作的同学们带来帮助(●'◡'●)



面试大概会考传统机器学习、深度学习、最优化、coding四个方面。

**传统机器学习：**
lr、svm、gmm、k means、隐马尔科夫、朴素贝叶斯

决策树，信息增益，基尼系数

ensemble method：bagging、stacking、boosting，具体的比如 random forest、adaboost、gbdt等

如何进行 feature selection

降维，比如 pca、lda

bias vs variance

**深度学习：**
手推 bp
梯度消失/爆炸原因，以及解决方法
各种 loss，比如 hinge loss、cross entropy loss等等
bn的原理
防止过拟合有哪些方法
im2col原理

**最优化：**
sgd
momentum
rmsprop
adam
拟牛顿法
拉格朗日乘子法、对偶问题、kkt条件

**coding：**

好好刷 leetcode

主要题型如排序、双指针、dp、贪心、分治、递归、回溯、字符串、树、链表、trie、bfs、dfs等等



- 用过哪些 DL 的 library 呀?
- 现在的 DL 的 state of art model有哪些呀?
- 如果如理 diminishing gradient的问题呀?
- 如果同时处理文本文档+图片呀?
- 如果防止 overfitting 呀?
- 如何 pre-train model呀?
- 能否自己在服务器上用 distributed computing部署一个现有的 model 呀?


- 解决网络过拟合的手段有些什么呀
- Dropout的为什么可以解决过拟合呀
- Batch-normalization的思想是什么呀
- 类别不平衡的时候怎么办啊
- 目标检测中 anchor box的做法和 adaboost 人脸检测中的滑窗检测有什么区别啊？
- 跟踪和检测有什么区别啊？
- 用过几个框架？它们的优劣分析一下
就酱
