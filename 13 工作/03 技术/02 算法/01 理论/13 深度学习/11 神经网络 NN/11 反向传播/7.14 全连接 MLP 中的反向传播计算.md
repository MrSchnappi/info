---
title: 7.14 全连接 MLP 中的反向传播计算
toc: true
date: 2019-08-31
---


# 全连接 MLP 中的反向传播计算


为了阐明反向传播的上述定义，让我们考虑一个与全连接的多层 MLP 相关联的特定图。

算法 6.3 首先给出了前向传播，它将参数映射到与单个训练样本（输入，目标） $(\boldsymbol x,\boldsymbol y)$ 相关联的监督损失函数 $L(\hat{\boldsymbol y}, \boldsymbol y)$，其中 $\hat{\boldsymbol y}$ 是当 $\boldsymbol x$ 提供输入时神经网络的输出。



<center>

![](http://images.iterate.site/blog/image/20190712/sWEzaBHQYgCf.png?imageslim){ width=55% }

</center>


算法 6.4 随后说明了将反向传播应用于该图所需的相关计算。



<center>

![](http://images.iterate.site/blog/image/20190712/uASwJntePnAv.png?imageslim){ width=55% }

</center>


算法 6.3 和算法 6.4 是简单而直观的演示。然而，它们专门针对特定的问题。

现在的软件实现基于之后一般化的反向传播中描述的一般形式的反向传播，<span style="color:red;">什么是一般形式的反向传播？</span>它可以通过显式地操作表示符号计算的数据结构，来适应任何计算图。






# 相关

- 《深度学习》花书
