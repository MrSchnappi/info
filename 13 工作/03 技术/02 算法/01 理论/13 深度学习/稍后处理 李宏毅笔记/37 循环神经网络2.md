---
title: 37 循环神经网络2
toc: true
date: 2019-08-18
---
![mark](http://images.iterate.site/blog/image/20190818/fLKU3AUOHYLX.png?imageslim)
## RNN怎么学习？

![mark](http://images.iterate.site/blog/image/20190818/uXEPVRQwh4jA.png?imageslim)
如果要做 learning 的话，你要定义一个 cost function来 evaluate 你的 model 是好还是不好，选一个 parameter 要让你的 loss 最小。那在 Recurrent Neural
Network里面，你会怎么定义这个 loss 呢，下面我们先不写算式，先直接举个例子。

假设我们现在做的事情是 slot filling，那你会有 train data，那这个 train data是说:我给你一些 sentence，你要给 sentence 一些 label，告诉 machine 说第一个 word 它是属于 other slot，“Taipei是”Destination slot,"on"属于 other
slot，“November”和“2nd”属于 time slot，然后接下来你希望说：你的 cost 咋样定义呢。那“arrive”丢到 Recurrent Neural Network的时候，Recurrent Neural Network会得到一个 output $y^1$，接下来这个 $y^1​$ 会看它的 reference vector算它的 cross entropy。你会希望说，如果我们丢进去的是“arrive”，那他的 reference vector应该对应到 other slot的 dimension(其他为 0)，这个 reference vector的长度就是 slot 的数目(这样四十个 slot，reference vector的 dimension 就是 40)，那 input 的这个 word 对应到 other slot的话，那对应到 other slot dimension为 1，其它为 0。

那现在把“Taipei”丢进去之后，因为“Taipei”属于 destination slot，就希望说把 $x^2$ 丢进去的话，$y^2$ 它要跟 reference vector距离越近越好。那 $y^2$ 的 reference vector是对应到 destination slot是 1，其它为 0。

那这边注意的事情就是，你在丢 $x_2$ 之前，你一定要丢 $x_1$(在丢“Taipei”之前先把“arrive''丢进去)，不然你就不知道存到 memory 里面的值是多少。所以在做 training 的时候，你也不能够把这些 word 打散来看，word sentence仍然要当做一个整体来看。把“on”丢进去，reference vector对应的 other 的 dimension 是 1，其它是 0.

RNN的损失函数 output 和 reference vector的 entropy 的和就是要最小化的对象。

![mark](http://images.iterate.site/blog/image/20190818/IJ4UThduuBCV.png?imageslim)
有了这个 loss function以后，对于 training，也是用梯度下降来做。也就是说我们现在定义出了 loss function(L)，我要 update 这个 neural network里面的某个参数 w，就是计算对 w 的偏微分，偏微分计算出来以后，就用 GD 的方法去 update 里面的参数。在讲 feedforward neural network的时候，我们说 GD 用在 feedforward neural network里面你要用一个有效率的算法叫做 Backpropagation。那 Recurrent Neural Network里面，为了要计算方便，所以也有开发一套算法是 Backpropagation 的进阶版，叫做 BPTT。它跟 Backpropagation 其实是很类似的，只是 Recurrent Neural Network它是在 high sequence上运作，所以 BPTT 它要考虑时间上的 information。

![mark](http://images.iterate.site/blog/image/20190818/oVymVPyJlqnF.png?imageslim)

不幸的是，RNN的 training 是比较困难的。一般而言，你在做 training 的时候，你会期待，你的 learning curve是像蓝色这条线，这边的纵轴是 total loss，横轴是 epoch 的数目，你会希望说：随着 epoch 的数目越来越多，随着参数不断的 update，loss会慢慢的下降最后趋向收敛。但是不幸的是你在训练 Recurrent Neural Network的时候，你有时候会看到绿色这条线。如果你是第一次 trai Recurrent Neural Network，你看到绿色这条 learning curve非常剧烈的抖动，然后抖到某个地方，这时候你会有什么想法，我相信你会：这程序有 bug 啊。

![mark](http://images.iterate.site/blog/image/20190818/Xq9WwGFeIyi2.png?imageslim)
分析了下 RNN 的性质，他发现说 RNN 的 error surface是 total loss的变化是非常陡峭的/崎岖的(error surface有一些地方非常的平坦，一些地方非常的陡峭，就像是悬崖峭壁一样)，纵轴是 total loss，x和 y 轴代表是两个参数。这样会造成什么样的问题呢？假设你从橙色的点当做你的初始点，用 GD 开始调整你的参数(updata你的参数，可能会跳过一个悬崖，这时候你的 loss 会突然爆长，loss会非常上下剧烈的震荡)。有时候你可能会遇到更惨的状况，就是以正好你一脚踩到这个悬崖上，会发生这样的事情，因为在悬崖上的 gradient 很大，之前的 gradient 会很小，所以你措手不及，因为之前 gradient 很小，所以你可能把 learning rate调的比较大。很大的 gradient 乘上很大的 learning rate结果参数就 update 很多，整个参数就飞出去了。

用工程的思想来解决，这一招蛮关键的，在很长的一段时间，只有他的 code 可以把 RNN 的 model 给 train 出来。

这一招就是 clipping(当 gradient 大于某一个 threshold 的时候，不要让它超过那个 threshold)，当 gradient 大于 15 时，让 gradient 等于 15 结束。因为 gradient 不会太大，所以你要做 clipping 的时候，就算是踩着这个悬崖上，也不飞出来，会飞到一个比较近的地方，这样你还可以继续做你得 RNN 的 training。

问题：为什么 RNN 会有这种奇特的特性。有人会说，是不是来自 sigmoid function，我们之前讲过 Relu activation function的时候，讲过一个问题 gradient vanish，这个问题是从 sigmoid function来的，RNN会有很平滑的 error surface是因为来自于 gradient vanish，这问题我是不认同的。等一下来看这个问题是来自 sigmoid function，你换成 Relu 去解决这个问题就不是这个问题了。跟大家讲个秘密，一般在 train neural network时，一般很少用 Relu 来当做 activation function。为什么呢？其实你把 sigmoid function换成 Relu，其实在 RNN performance通常是比较差的。所以 activation function并不是这里的关键点。

![mark](http://images.iterate.site/blog/image/20190818/gXwLi4iyA7PY.png?imageslim)
如果说我们今天讲 BPTT，你可能会从式子更直观的看出为什么会有这个问题。那今天我们没有讲 BPTT。没有关系，我们有更直观的方法来知道一个 gradient 的大小。

你把某一个参数做小小的变化，看它对 network output的变化有多大，你就可以测出这个参数的 gradient 的大小。

举一个很简单的例子，只有一个 neuron，这个 neuron 是 linear。input没有 bias，input的 weight 是 1，output的 weight 也是 1，transition的 weight 是 w。也就是说从 memory 接到 neuron 的 input 的 weight 是 w。

现在我假设给 neural network的输入是(1,0,0,0)，那这个 neural network的 output 会长什么样子呢？比如说，neural network在最后一个时间点(1000个 output 值是 $w^{999}$)。

现在假设 w 是我们要 learn 的参数，我们想要知道它的 gradient，所以是知道当我们改变 w 的值时候，对 neural 的 output 有多大的影响。现在假设 w=1，那现在 $y^{1000}=1$，假设 w=1.01，$y^{1000}\approx 20000$，这个就跟蝴蝶效应一样，w有一点小小的变化，会对它的 output 影响是非常大的。所以 w 有很大的 gradient。有很大的 gradient 也并没有，我们把 learning rate设小一点就好了。但我们把 w 设为 0.99，那 $y^{1000}\approx0$，那如果把 w 设为 0.01，那 $y^{1000}\approx0$。也就是说在 1 的这个地方有很大的 gradient，但是在 0.99这个地方就突然变得非常非常的小，这个时候你就需要一个很大的 learning rate。设置 learning rate很麻烦，你的 error surface很崎岖，你的 gardient 是时大时小的，在非常小的区域内，gradient有很多的变化。从这个例子你可以看出来说，为什么 RNN 会有问题，RNN training的问题其实来自它把同样的东西在 transition 的时候反复使用。所以这个 w 只要一有变化，它完全由可能没有造成任何影响，一旦造成影响，影响都是天崩地裂的(所以 gradient 会很大，gradient会很小)。

所以 RNN 不好训练的原因不是来自 activation function而是来自于它有 high sequence同样的 weight 在不同的时间点被反复的使用。

## 如何解决 RNN 梯度消失或者爆炸

![mark](http://images.iterate.site/blog/image/20190818/RXzQh1Ce19x0.png?imageslim)
有什么样的技巧可以告诉我们可以解决这个问题呢？其实广泛被使用的技巧就是 LSTM，LSTM可以让你的 error surface不要那么崎岖。它可以做到的事情是，它会把那些平坦的地方拿掉，解决 gradient vanish的问题，不会解决 gradient explode的问题。有些地方还是非常的崎岖的(有些地方仍然是变化非常剧烈的，但是不会有特别平坦的地方)。

如果你要做 LSTM 时，大部分地方变化的很剧烈，所以当你做 LSTM 的时候，你可以放心的把你的 learning rate设置的小一点，保证在 learning rate很小的情况下进行训练。

那为什么 LSTM 可以解决梯度消失的问题呢，为什么可以避免 gradient 特别小呢？

我听说某人在面试某国际大厂的时候被问到这个问题，那这个问题怎么答比较好呢(问题：为什么我们把 RNN 换成 LSTM)。如果你的答案是 LSTM 比较潮，LSTM比较复杂，这个就太弱了。正在的理由就是 LSTM 可以 handle gradient vanishing的问题。接下里面试官说：为什么 LSTM 会 handle gradient vanishing的问题呢？用这边的式子回答看看，若考试在碰到这样的问题时，你就可以回答了。

RNN跟 LSTM 在面对 memory 的时候，它处理的操作其实是不一样的。你想想看，在 RNN 里面，在每一个时间点，memory里面的值都是会被洗掉，在每一个时间点，neuron的 output 都要 memory 里面去，所以在每一个时间点，memory里面的值都是会被覆盖掉。但是在 LSTM 里面不一样，它是把原来 memory 里面的值乘上一个值再把 input 的值加起来放到 cell 里面。所以它的 memory input是相加的。所以今天它和 RNN 不同的是，如果今天你的 weight 可以影响到 memory 里面的值的话，一旦发生影响会永远都存在。不像 RNN 在每个时间点的值都会被 format 掉，所以只要这个影响被 format 掉它就消失了。但是在 LSTM 里面，一旦对 memory 造成影响，那影响一直会被留着(除非 forget gate要把 memory 的值洗掉)，不然 memory 一旦有改变，只会把新的东西加进来，不会把原来的值洗掉，所以它不会有 gradient vanishing的问题

那你想说们现在有 forget gate可能会把 memory 的值洗掉。其实 LSTM 的第一个版本其实就是为了解决 gradient vanishing的问题，所以它是没有 forget gate，forget gate是后来才加上去的。甚至，现在有个传言是：你在训练 LSTM 的时候，你要给 forget gate特别大的 bias，你要确保 forget gate在多数的情况下都是开启的，只要少数的情况是关闭的

那现在有另外一个版本用 gate 操控 memory cell，叫做 Gates Recurrent Unit(GRU)，LSTM有三个 Gate，而 GRU 有两个 gate，所以 GRU 需要的参数是比较少的。因为它需要的参数量比较少，所以它在 training 的时候是比较鲁棒的。如果你今天在 train LSTM，你觉得 overfitting 的情况很严重，你可以试下 GRU。GRU的精神就是：旧的不去，新的不来。它会把 input gate跟 forget gate联动起来，也就是说当 input gate打开的时候，forget gate会自动的关闭(format存在 memory 里面的值)，当 forget gate没有要 format 里面的值，input gate就会被关起来。也就是说你要把 memory 里面的值清掉，才能把新的值放进来。

### 其他方式

![mark](http://images.iterate.site/blog/image/20190818/XUkiQ1m0tqzM.png?imageslim)
其实还有其他的 technique 是来 handle gradient vanishing的问题。比如说 clockwise RNN或者说是 Structurally Constrained Recurrent Network (SCRN)等等。

有一个蛮有趣的 paper 是这样的：一般的 RNN 用 identity matrix（单位矩阵）来 initialized transformation weight+ReLU activaton function它可以得到很好的 performance。刚才不是说用 ReLU 的 performance 会比较呀，如果你说一般 train 的方法 initiaed weight是(这个单词没懂)，那 ReLU 跟 sigmoid function来比的话，sigmoid performance 会比较好。但是你今天用了 identity matrix的话，这时候用 ReLU performance会比较好。

## RNN其他应用

![mark](http://images.iterate.site/blog/image/20190818/JMIhuOgrC14L.png?imageslim)
其实 RNN 有很多的 application，前面举得那个 solt filling的例子。我们假设 input 跟 output 的数目是一样的，也就是说 input 有几个 word，我们就给每一个 word slot label。那其实 RNN 可以做到更复杂的事情

### 多对一序列

#### 情感识别



![mark](http://images.iterate.site/blog/image/20190818/9EOm1tyKKUOM.png?imageslim)
那其实 RNN 可以做到更复杂的事情，比如说 input 是一个 sequence，output是一个 vector，这有什么应用呢。比如说，你可以做 sentiment analysis。sentiment analysis现在有很多的应用：

某家公司想要知道，他们的产品在网上的评价是 positive 还是 negative。他们可能会写一个爬虫，把跟他们产品有关的文章都爬下来。那这一篇一篇的看太累了，所以你可以用一个 machine learning 的方法 learn 一个 classifier 去说哪些 document 是正向的，哪些 document 是负向的。或者在电影上，sentiment analysis所做的事就是给 machine 看很多的文章，然后 machine 要自动的说，哪些文章是正类，哪些文章是负类。怎么样让 machine 做到这件事情呢？你就是 learn 一个 Recurrent Neural Network，这个 input 是 character sequence，然后 Recurrent Neural Network把这个 sequence 读过一遍。在最后一个时间点，把 hidden layer拿出来，在通过几个 transform，然后你就可以得到最后的 sentiment analysis(这是一个分类的问题，但是因为 input 是 sequence，所以用 RNN 来处理)

![mark](http://images.iterate.site/blog/image/20190818/1aCFjtF1IhGt.png?imageslim)
用 RNN 来作 key term extraction。key term extraction意思就是说给 machine 看一个文章，machine要预测出这篇文章有哪些关键词汇。那如果你今天能够收集到一些 training data(一些 document，这些 document 都有 label，哪些词汇是对应的，那就可以直接 train 一个 RNN)，那这个 RNN 把 document 当做 input，通过 Embedding layer，然后用 RNN 把这个 document 读过一次，然后把出现在最后一个时间点的 output 拿过来做 attention，你可以把这样的 information 抽出来再丢到 feedforward neural network得到最后的 output

### 多对多序列

#### 语音识别

![mark](http://images.iterate.site/blog/image/20190818/jD2whTzszVko.png?imageslim)
那它也可以是多对多的，比如说当你的 input 和 output 都是 sequence，但是 output sequence比 input sequence短的时候，RNN可以处理这个问题。什么样的任务是 input sequence长，output sequence短呢。比如说，语音辨识就是这样的任务。在语音辨识这个任务里面 input 是 acoustic sequence(说一句话，这句话就是一段声音讯号)。我们一般处理声音讯号的方式，在这个声音讯号里面，每隔一小段时间，就把它用 vector 来表示。这个一小段时间是很短的(比如说，0.01秒)。那 output sequence是 character sequence。

如果你是原来的 RNN(slot filling的那个 RNN)，你把这一串 input 丢进去，它充其量只能做到说，告诉你每一个 vector 对应到哪一个 character。加入说中文的语音辨识的话，那你的 output target理论上就是这个世界上所有可能中文的词汇，常用的可能是八千个，那你 RNNclassifier 的数目可能就是八千个。虽然很大，但也是没有办法做的。但是充其量只能做到说：每一个 vector 属于一个 character。每一个 input 对应的时间间隔是很小的(0.01秒)，所以通常是好多个 vector 对应到同一个 character。所以你的辨识结果为“好好好棒棒棒棒棒”。你会说：这不是语音辨识的结果呀，有一招叫做“trimming”(把重复的东西拿掉)，就变成“好棒”。这这样会有一个严重的问题，因为它没有辨识“好棒棒”。

#### CTC语音识别

![mark](http://images.iterate.site/blog/image/20190818/kLMXoOpWnSJo.png?imageslim)
需要把“好棒”跟“好棒棒”分开来，怎么办，我们有一招叫做“CTC”(这招很神妙)，它说：我们在 output 时候，我们不只是 output 所有中文的 character，我们还有 output 一个符号，叫做"null""(没有任何东西)。所以我今天 input 一段 acoustic feature sequence，它的 output 是“好 null null 棒 null null null null”，然后我就把“null”的部分拿掉，它就变成“好棒”。如果我们输入另外一个 sequence，它的 output 是“好 null null 棒 null 棒 null null”，然后把“null”拿掉，所以它的 output 就是“好棒棒”。这样就可以解决叠字的问题了。



![mark](http://images.iterate.site/blog/image/20190818/rUOeAul1rokJ.png?imageslim)
那在训练 neuron 怎么做呢(CTC怎么做训练呢)。CTC在做 training 的时候，你手上的 train data就会告诉你说，这一串 acoustic features对应到这一串 character sequence，但它不会告诉你说“好”是对应第几个 character 到第几个 character。这该怎么办呢，穷举所有可能的 alignments。简单来说就是，我们不知道“好”对应到那几个 character，“棒”对应到哪几个 character。假设我们所有的状况都是可能的。可能第一个是“好 null 棒 null null null”，可能是“好 null null 棒 null null”，也可能是“好 null null null 棒 null”。我们不知道哪个是对的，那假设全部都是对的。在 training 的时候，全部都当做是正确的，然后一起 train。穷举所有的可能，那可能性太多了，有没有巧妙的算法可以解决这个问题呢？那今天我们就不细讲这个问题。

![mark](http://images.iterate.site/blog/image/20190818/dxufFbLbEpsV.png?imageslim)
以下是在文献 CTC 上得到的结果。在做英文辨识的时候，你的 RNN output target 就是 character(英文的字母+空白)。直接 output 字母，然后如果字和字之间有 boundary，就自动有空白。

假设有一个例子，第一个 frame 是 output h，第二个 frame 是 output null，第三个 frame 是 output null，第四个 frame 是 output I等等。如果你看到 output 是这样子话，那最后把“null”的地方拿掉，那这句话的辨识结果就是“HIS FRIEND'S”。你不需要告诉 machine 说："HIS"是一个词汇，“FRIEND's”是一个词汇,machine通过 training data会自己学到这件事情。那传说，Google的语音辨识系统已经全面换成 CTC 来做语音辨识。如果你用 CTC 来做语音辨识的话，就算是有某一个词汇(比如是：英文中人名，地名)在 training data中从来没有出现过，machine也是有机会把它辨识出来。

### Sequence to sequence learning

![mark](http://images.iterate.site/blog/image/20190818/6FIBv7qml22E.png?imageslim)
另外一个神奇 RNN 的应用叫做 sequence to sequence learning，在 sequence to sequence learning里面,RNN的 input 跟 output 都是 sequence(但是两者的长度是不一样的)。刚在在 CTC 时，input比较长，output比较短。在这边我们要考虑的是不确定 input 跟 output 谁比较长谁比较短。

比如说，我们现在做 machine translation，input英文 word sequence把它翻译成中文的 character sequence。那我们并不知道说，英文跟中文谁比较长谁比较短(有可能是 output 比较长，output比较短)。所以改怎么办呢？

现在假如说 input machine learning ，然后用 RNN 读过去，然后在最后一个时间点，这个 memory 里面就存了所有 input sequence的 information。

![mark](http://images.iterate.site/blog/image/20190818/nIdCzcMczdlN.png?imageslim)
然后接下来，你让 machine 吐一个 character(机)，然后就让它 output 下一个 character，把之前的 output 出来的 character 当做 input，再把 memory 里面的值读进来，它就会 output “器”。那这个“机”怎么接到这个地方呢，有很多支支节节的技巧，还有很多不同的变形。在下一个时间 input “器”，output“学”，然后 output“习”，然后一直 output 下去

![mark](http://images.iterate.site/blog/image/20190818/5Ld4ltieSukJ.png?imageslim)
这就让我想到推文接龙，有一个人推超，下一个人推人，然后推正，然后后面一直推推，等你推好几个月，都不会停下来。你要怎么让它停下来呢？推出一个“断”，就停下来了。



![mark](http://images.iterate.site/blog/image/20190818/SqWk4qta5JVt.png?imageslim)
要怎么阻止让它产生词汇呢？你要多加一个 symbol “断”，所以现在 manchine 不只是 output 说可能 character，它还有一个可能 output 叫做“断”。所以今天“习”后面是“===”(断)的话，就停下来了。你可能会说这个东西 train 的起来吗，这是 train 的起来的。

![mark](http://images.iterate.site/blog/image/20190818/3lEAQqJrRo7T.png?imageslim)
这篇的 papre 是这样做的，sequence to sequence learning我们原来是 input 某种语言的文字翻译成另外一种语言的文字(假设做翻译的话)。那我们有没有可能直接 input 某种语言的声音讯号，output另外一种语言的文字呢？我们完全不做语音辨识。比如说你要把英文翻译成中文，你就收集一大堆英文的句子，看看它对应的中文翻译。你完全不要做语音辨识，直接把英文的声音讯号丢到这个 model 里面去，看它能不能 output 正确的中文。这一招居然是行得通的。假设你今天要把台语转成英文，但是台语的语音辨识系统不好做，因为台语根本就没有 standard 文字系统，所以这项技术可以成功的话，未来你在训练台语转英文语音辨识系统的时候，你只需要收集台语的声音讯号跟它的英文翻译就可以刻了。你就不需要台语语音辨识的结果，你也不需要知道台语的文字，也可以做这件事。

#### Beyond Sequence

![mark](http://images.iterate.site/blog/image/20190818/GqPb1Giyxewf.png?imageslim)
利用 sequence to sequence的技术，甚至可以做到 Beyond Sequence。这个技术也被用到 syntactic parsing。synthetic parsing这个意思就是说，让 machine 看一个句子，它要得到这个句子的结构树，得到一个树状的结构。怎么让 machine 得到这样的结构呢？，过去你可能要用 structured learning的技术能够解这个问题。但是现在有了 sequence to sequence learning的技术以后，你只要把这个树状图描述成一个 sequence(具体看图中 john has a dog)。所以今天是 sequence to sequence learning 的话，你就直接 learn 一个 sequence to sequence model。它的 output 直接就是 syntactic parsing tree。这个是可以 train 的起来的，非常的 surprised

你可能想说 machine 它今天 output 的 sequence 不符合文法结构呢(记得加左括号，忘记加右括号)，神奇的地方就是 LSTM 不会忘记右括号。

### Document转成 Vector

![mark](http://images.iterate.site/blog/image/20190818/TASzbbRTIM12.png?imageslim)
那我们要将一个 document 表示成一个 vector 的话，往往会用 bag-of-word的方法，用这个方法的时候，往往会忽略掉 word order information。举例来说，有一个 word sequence是“white blood cells destroying an infection”，另外一个 word sequence是：“an infection destroying white blood cells”，这两句话的意思完全是相反的。但是我们用 bag-of-word的方法来描述的话，他们的 bag-of-word完全是一样的。它们里面有完全一摸一样的六个词汇，因为词汇的 order 是不一样的，所以他们的意思一个变成 positive，一个变成 negative，他们的意思是很不一样的。

那我们可以用 sequence to sequence Auto-encoder这种做法来考虑 word sequence order的情况下，把一个 document 变成一个 vector。

## Sequence-to-sequence -Text



![mark](http://images.iterate.site/blog/image/20190818/8FOSlecc4c2d.png?imageslim)
input一个 word sequence，通过 Recurrent Neural  Network变成一个 invalid vector，然后把这个 invalid vector当做 decoder 的输入，然后让这个 decoder，找回一模一样的句子。如果今天 Recurrent Neural Network可以做到这件事情的话，那 Encoding 这个 vector 就代表这个 input sequence里面重要的 information。在 trian Sequence-to-sequence Auto-encoder的时候，不需要 label data，你只需要收集大量的文章，然后直接 train 下去就好了。

Sequence-to-sequence 还有另外一个版本叫 skip thought，如果用 Sequence-to-sequence的，输入输出都是同一个句子，如果用 skip thought的话，输出的目标就会是下一个句子，用 sequence-to-sequence得到的结果通常容易表达，如果要得到语义的意思的，那么 skip thought会得到比较好的结果。

![mark](http://images.iterate.site/blog/image/20190818/Cwg18z1gsru3.png?imageslim)

这个结构甚至可以是 hierarchical，你可以每一个句子都先得到一个 vector(Mary was hungry得到一个 vector，she didn't find any food得到一个 vector)，然后把这些 vector 加起来，然后变成一个整个 document high label vector，在让这整个 vector 去产生一串 sentence vector，在根据每一个 sentence vector再去解回 word sequence。这是一个四层的 LSTM(从 word 变成 sentence sequence ，变成 document lable，再解回 sentence sequence，再解回 word sequence)

## Sequence-to-sequence -Speech

![mark](http://images.iterate.site/blog/image/20190818/lWsDmuawCP0y.png?imageslim)
这个也可以用到语音上，在语音上，它可以把一段 audio segment变成一个 fixed length vector。比如说，左边有一段声音讯号，长长短短都不一样，那你把他们变成 vector 的话，可能 dog 跟 dogs 比较接近，never和 ever 比较接近。我称之为 audio auto vector。一般的 auto vector它是把 word 变成 vector，这个是把一段声音讯号变成一个 vector。

![mark](http://images.iterate.site/blog/image/20190818/4Jo5Ap4MHvn0.png?imageslim)
那这个东西有什么用呢？它可以做很多的事。比如说，我们可以拿来做语音的搜寻。什么是语音的搜寻呢？你有一个声音的 data base(比如说，上课的录音，然后你说一句话，比如说，你今天要找跟美国白宫有关的东西，你就说美国白宫，不需要做语音辨识，直接比对声音讯号的相似度，machine 就可以从 data base里面把提到的部分找出来)

怎么实现呢？你就先把一个 audio data base，把这个 data base做 segmentation 切成一段一段的。然后每一个段用刚才讲的 audio segment to vector这个技术，把他们通通变成 vector。然后现再输入一个 spoken query，可以通过 audio segment to vector技术也变成 vector，接下来计算他们的相似程度。然后就得到搜寻的结果

![mark](http://images.iterate.site/blog/image/20190818/FdoSigm17RA4.png?imageslim)
如何把一个 audio segment变成一个 vector 呢？把 audio segment抽成 acoustic features，然后把它丢到 Recurrent neural network里面去，那这个 recurrent neural network它的角色就是 Encoder，那这个 recurrent neural network读过 acoustic features之后，最后一个时间点它存在 memory 里面的值就代表了 input 声音讯号它的 information。它存到 memory 里面的值是一个 vector。这个其实就是我们要拿来表示整段声音讯号的 vector。

但是只要 RNN Encoder我没有办法去 train，同时你还要 train 一个 RNN Decoder，Decoder的作用就是，它把 Encoder 得到的值存到 memory 里面的值，拿进来当做 input，然后产生一个 acoustic features sequence。然后希望这个 $y_1$ 跟 $x_1$ 越接近越好。然后再根据 $y_1$ 产生 $y_2$，以此类推。今天训练的 target$y_1,y_2,y_3,y_4$ 跟 $x_1,x_2,x_3,x_4$ 越接近越好。那在训练的时候，RNN Encoder跟 RNN Decoder是一起 train 的

![mark](http://images.iterate.site/blog/image/20190818/t169XaP2Ldvq.png?imageslim)
我们在实验上得到一些有趣的结果，图上的每个点其实都是一段声音讯号，你把声音讯号用刚才讲的
Sequence-to-sequence Auto-encoder技术变成平面上一个 vector。发现说：fear这个位置在左上角，near的位置在右下角，他们中间这样的关系(fame在左上角，name在右下角)。你会发现说：把 fear 的开头 f 换成 n，跟 fame 的开头 f 换成 n，它们的 word vector的变化方向是一样的。现在这个技术还没有把语义加进去。

## Demo：聊天机器人

![mark](http://images.iterate.site/blog/image/20190818/KyyMurdjr13H.png?imageslim)
现在有一个 demo，这个 demo 是用 Sequence-to-sequence Auto-encoder来训练一个 chat-bot(聊天机器人)。怎么用 sequence to sequence learning来 train chat-bot呢？你就收集很多的对话，比如说电影的台词，在电影中有一个台词是“How are you”，另外一个人接“I am fine”。那就告诉 machine 说这个 sequence to sequence learning当它 input 是“How are you”的时候，这个 model 的 output 就要是“I am fine”。你可以收集到这种 data，然后就让 machine 去 train。这里我们就收集了四万句和美国总统辩论的句子，然后让 machine 去学这个 sequence to sequence这个 model。

![mark](http://images.iterate.site/blog/image/20190818/Xv6cBoa3LUPA.png?imageslim)

![mark](http://images.iterate.site/blog/image/20190818/RwVVxJ2HEE1F.png?imageslim)
现在除了 RNN 以外，还有另外一种有用到 memory 的 network，叫做 Attention-based Model，这个可以想成是 RNN 的进阶的版本。

那我们知道说，人的大脑有非常强的记忆力，所以你可以记得非常非常多的东西。比如说，你现在同时记得早餐吃了什么，同时记得 10 年前夏天发生的事，同时记得在这几门课中学到的东西。那当然有人问你说什么是 deep learning的时候，那你的脑中会去提取重要的 information，然后再把这些 information 组织起来，产生答案。但是你的脑中会自动忽略那些无关的事情，比如说，10年前夏天发生的事情等等。

## Attension-based Model



![mark](http://images.iterate.site/blog/image/20190818/m14vvtCUhMXc.png?imageslim)
其实 machine 也可以做到类似的事情，machine也可以有很大的记忆的容量。它可以有很大的 data base，在这个 data base里面，每一个 vector 就代表了某种 information 被存在 machine 的记忆里面。

当你输入一个 input 的时候，这个 input 会被丢进一个中央处理器，这个中央处理器可能是一个 DNN/RNN，那这个中央处理器会操控一个 Reading Head
Controller，这个 Reading Head Controller会去决定这个 reading head放的位置。machine再从这个 reading head 的位置去读取 information，然后产生最后的 output

![mark](http://images.iterate.site/blog/image/20190818/gLfqJD5xWpEr.png?imageslim)
这个 model 还有一个 2.0的版本，它会去操控 writing head controller。这个 writing head controller会去决定 writing head 放的位置。然后 machine 会去把它的 information 通过这个 writing head写进它的 data base里面。所以，它不仅有读的功能，还可以 discover 出来的东西写入它的 memory 里面去。这个就是大名鼎鼎的 Neural Turing Machine

### 阅读理解

![mark](http://images.iterate.site/blog/image/20190818/loA4ahI2wojI.png?imageslim)
Attention-based Model 常常用在 Reading Comprehension里面。所谓的 Reading Comprehension就是让 machine 读一堆 document，然后把这些 document 里面的内容(每一句话)变成一个 vector。每一个 vector 就代表了每一句话的语义。比如你现在想问 machine 一个问题，然后这个问题被丢进中央处理器里面，那这个中央处理器去控制而来一个 reading head controller，去决定说现在在这个 data base里面哪些句子是跟中央处理器有关的。假设 machine 发现这个句子是跟现在的问题是有关的，就把 reading head放到这个地方，把 information 读到中央处理器中。读取 information 这个过程可以是重复数次，也就是说 machine 并不会从一个地方读取 information，它先从这里读取 information 以后，它还可以换一个位置读取 information。它把所有读到的 information 收集起来，最后给你一个最终的答案。

![mark](http://images.iterate.site/blog/image/20190818/7HPsktVlnvjp.png?imageslim)

上图是在 baby corpus上的结果，baby corpus是一个 Q&A的一个简单的测试。我们需要做的事就是读过这五个句子，然后说：what color is Grey?，得到正确的答案，yes。那你可以从 machine attention的位置(也就是 reading head 的位置)看出 machine 的思路。图中蓝色代表了 machine reading head 的位置，Hop1，Hop2，Hop3代表的是时间，在第一个时间点，machine先把它的 reading head放在“greg is a frog”，把这个 information 提取出来。接下来提取“brian is a frog” information ，再提取“brian is yellow”information。最后它得到结论说：greg 的颜色是 yellow。这些事情是 machine 自动 learn 出来的。也就是 machine attention在哪个位置，这些通过 neural network学到该怎么做，并不是去写程序，你要先看这个句子，在看这个句子。这是 machine 自动去决定的。

### Visual Question Answering

![mark](http://images.iterate.site/blog/image/20190818/lUlgxScvtfcs.png?imageslim)
也可以做 Visual Question Answering，让 machine 看一张图，问它这是什么，如果它可以正确回答说：这是香蕉，这就非常厉害了。

![mark](http://images.iterate.site/blog/image/20190818/wze3zrxN2vim.png?imageslim)
这个 Visual Question Answering该怎么做呢？先让 machine 看一张图，然后通过 CNN 你可以把这张图的一小块 region 用一小块的 vector 来表示。接下里，输入一个 query，这个 query 被丢到中央处理器中，这个中央处理器去操控这个 reading head controller，这个 reading head controller决定读取的位置(是跟现在输入的问题是有关系的，这个读取的 process 可能要好几个步骤，machine会分好几次把 information 读到中央处理器，最后得到答案。

### Speech Question Answering

![mark](http://images.iterate.site/blog/image/20190818/WqCeTrquU4Nv.png?imageslim)
那可以做语音的 Question Answering 。比如说：在语音处理实验上我们让 machine 做 TOEFL Listening Comprehension Test 。让 machine 听一段声音，然后问它问题，从四个选项里面，machine选择出正确的选项。那 machine 做的事情是跟人类考生做的事情是一模一样的。

![mark](http://images.iterate.site/blog/image/20190818/rIF2HYGlyeus.png?imageslim)
那用的 Model Architecture跟我们刚才看到的其实大同小异。你让 machine 先读一个 question，然后把 question 做语义的分析得到 question 的语义，声音的部分是让语音辨识先转成文字，在把这些文字做语音的分析，得到这段文字的语义。那 machine 了解 question 的语义然后就可以做 attention，决定在 audio story里面哪些部分是回答问题有关的。这就像画重点一样，machine画的重点就是答案，它也可以回头去修正它产生的答案。经过几个 process 以后，machine最后得到的答案跟其他几个选项计算相似度，然后看哪一个想项的相似度最高，它就选那一个选项。那整个 test 就是一个大的 neural network。除了语音辨识以外 question semantic部分和 audio semantic部分都是 neural network，所以他们就可以训练的。

![mark](http://images.iterate.site/blog/image/20190818/ekqDCcf3aF70.png?imageslim)
这些是一些实验结果，这个实验结果是：random 正确率是 25 percent。有两个方法要比 25 percent要强的。

这五个方法都是 naive 的方法，也就是完全不管文章的内容，直接看问题跟选项就猜答案。我们发现说，如果你选最短的那个选项，你就会得到 35 percent的正确率。如果分析四个选项的 semantic，用 sequence-to-sequence autoencoder，去把一个选项的 semantic 找出来，然后再去看某个选项和另外三个选项的相似度，如果比较高的话，那就把该选项选出来。和人的直觉是相反的，直觉应该是选一个语义和另外三个语义是不像的，但是别人已经计算到会这么做的了，所以用了计中计，如果要选和其他选项语义比较相似的答案，反而比随便选得到正确答案的概率要高，如果选最不像的那个选项，得到的答案就会接近随机，都是设计好的。

![mark](http://images.iterate.site/blog/image/20190818/PXmkQiHaggMW.png?imageslim)

另外还可以用 memory network可以得到 39.2 %正确率，如果用我们刚才讲的那个 model 的话，可以做到 48.8%正确率。

### RNN 和 Structured learning关系

![mark](http://images.iterate.site/blog/image/20190818/5Tj9eYHjY1kd.png?imageslim)
使用 deep learning跟 structure learning的技术有什么不同呢？首先假如我们用的是 unidirectional RNN/LSTM，当你在  decision的时候，你只看了 sentence 的一半，而你是用 structure learning的话，比如用 Viterbi algrithm你考虑的是整个句子。从这个结果来看，也许 HMM，SVM等还是占到一些优势的。但是这个优势并不是很明显，因为 RNN 和 LSTM 他们可以做 Bidirectional ，所以他们也可以考虑一整个句子的 information

在 HMM/SVM里面，你可以 explicitly 的考虑 label 之间的关系

举例说，如果做 inference 的时候，再用 Viterbi algrithm求解的时候（假设每个 label 出现的时候都要出现五次）这个算法可以轻松做到，因为可以修改机器在选择分数最高的时候，排除掉不符合 constraint 的那些结果，但是如果是 LSTM/RNN，直接下一个 constraint 进去是比较难的，因为没办法让 RNN 连续吐出某个 label 五次才是正确的。所以在这点上，structured learning似乎是有点优势的。如果是 RNN/LSTM，你的 cost function跟你实际上要考虑的 error 往往是没有关系的，当你做 RNN/LSTM的时候，考虑的 cost 是每一个时间点的 cross entropy(每一个时间的 RNN 的 output cross entropy)，它跟你的 error 不见得是直接相关的。但是你用 structure learning的话，structure learning 的 cost 会影响你的 error，从这个角度来看，structured learning也是有一些优势的。最重要的是，RNN/LSTM可以是 deep，HMMM,SVM等它们其实也可以是 deep，但是它们要想拿来做 deep learning 是比较困难的。在我们上一堂课讲的内容里面。它们都是 linear，因为他们定义的 evaluation 函数是线性的。如果不是线性的话也会很麻烦，因为只有是线性的我们才能套用上节课讲的那些方法来做 inference。

最后总结来看，RNN/LSTM在 deep 这件事的表现其实会比较好，同时这件事也很重要，如果只是线性的模型，function space就这么大，可以直接最小化一个错误的上界，但是这样没什么，因为所有的结果都是坏的，所以相比之下，deep learning占到很大的优势。

## Integerated Together

![mark](http://images.iterate.site/blog/image/20190818/2KaIi7m3Lcla.png?imageslim)
deep learning和 structured learning结合起来。input features 先通过 RNN/LSTM，然后 RNN/LSTM的 output 再做为 HMM/svm的 input。用 RNN/LSTM的 output 来定义 HMM/structured SVM的 evaluation function，如此就可以同时享有 deep learning的好处，也可以有 structure learning的好处。

![mark](http://images.iterate.site/blog/image/20190818/JeXuLl6xO706.png?imageslim)
在语音上，我们常常把 deep learning 和 structure learning 合起来(CNN/LSTM/DNN + HMM)，所以做语音的时候一般 HMM 都还在，这样得到的结果往往是最好的。

这个系统工作流程：
在 HMM 里面，必须要去计算 $x$，$y$ 的 probability，而在 structured learning里面，我们要计算 $x$，$y$ 的 evaluation function，在语音辨识里面，x是声音讯号，y是语音辨识的结果。
在 HMM 里面，有 transition 的部分和 emission 的部分，DNN做的事情其实就是去取代的 emission 的部分，原来在 HMM 的 emission 部分就是去统计高斯混合模型，但是把它换成 DNN 以后，会得到很好的 performance。
换的方法：把 $P(y_l | x_l)$ 转换成 $P(x_l | y_l)$，公式是

$$P(x_l | y_l)=\frac{P(x_l,y_l)}{P(y_l)}=\frac{P(y_l|x_l)P(x_l)}{P(y_l)}$$

其中 $P(y_l|x_l)$ 可以从 RNN 里面来，$P(y_l)$ 则可以直接 count，$P(x_l)$ 可以直接无视，因为在得到几率的时候，$x_l$ 是输入（已知的），穷举所有的 $y_l$ 让 $P(y_l)$ 最大，所有和 x 有关的项不影响 inference 的结果，所有我们可以不用把 x 考虑进来。

其实加上 HMM 在语音辨识里很有帮助，就算是用 RNN，但是在辨识的时候，常常会遇到问题，假设我们是一个 frame，用 RNN 来问这个 frame 属于哪个 form，往往会产生奇怪的结果，比如说一个 frame 往往是蔓延好多个 frame，比如理论是是看到第一个 frame 是 A，第二个 frame 是 A，第三个是 A，第四个是 A，然后 BBB，但是如果用 RNN 做的时候，RNN每个产生的 label 都是独立的，所以可能会在前面若无其事的改成 B，然后又是 A，RNN很容易出现这个现象。HMM则可以把这种情况修复。因为 RNN 在训练的时候是分来考虑的，假如不同的错误对语音辨识结果影响很大，结果就会不好。所以加上 HMM 会很有帮助。

![mark](http://images.iterate.site/blog/image/20190818/o0VcvDlgRbkY.png?imageslim)

先用 Bi-directional LSTM做 feature，然后把这些 feature 拿来在做 CRF 或者 Structured SVM，然后学习一个权重 w，这个 $\phi(x,y)$ 的 feature，要直接从 Bidirectional LSTM的输出可以得到比较好的结果。

### Structure learning practical？

![mark](http://images.iterate.site/blog/image/20190818/iBKSpeYijElc.png?imageslim)

有人说 structured learning是否现实？

structured learning需要解三个问题，其中 input 的问题往往很困难，因为要穷举所有的 y 让其最大，解一个 optimization 的问题，其实大部分状况都没有好的解决办法，只有少数有，其他都是不好的状况。所有有人说 structured learning应用并不广泛，但是未来未必是这样的。

其实 GAN 就是一种 structured learning，可以把 discriminator 看做是 evaluation function（也就是 problem 1）最后要解一个 inference 的问题，我们要穷举我们未知的东西，看看哪个可以让我们的 evaluation function最大。这步往往比较困难，因为 x 的可能性太多了。但其实这个可以就是 generator，我们可以想成 generator 就是用所给的 noise，输出一个 update，它输出的这个高斯模型，就是让 discriminator 分辨不出的高斯模型，如果 discriminator 就是 evaluation function的话，那 output 的值就是让 evaluation function的值很大的那个对应值，所以这个 generator 就是在解这个问题，其实 generator 的输出就是 argmax 的输出，可以把 generator 当做在解 inference 这个问题，然后就直接求 problem 3。structured learning过程和 GAN 模型 generator 不断产生让 discriminator 最大的那个值，然后再去训练 discriminator 不断识别真实值，然后更新值的过程是异曲同工的。

![mark](http://images.iterate.site/blog/image/20190818/asybGj4pcYJQ.png?imageslim)

GAN也可以是 conditional 的 GAN，现在的任务是给定 x，找出最有可能的 y，想象成语音辨识，x是声音讯号，y是辨识出来的文字，如果是用 conditional 的概念，generator输入一个 x，就会 output 一个 y，discriminator是去检查 y 的 pair 是不是对的，如果给他一个真正的 x，y的 pair，会得到一个比较高的分数，给一个 generator 输出的一个 y 配上输入的 x，所产生的一个假的 pair，就会给他一个比较低的分数。训练的过程就和原来的 GAN 就是一样的，这个已经成功运用在文字产生图片这个 task 上面。这个 task 的 input 就是一句话，output就是一张图，generator做的事就是输入一句话，然后产生一张图片，而 discriminator 要做的事就是给他一张图片，要他判断这个 x，y的 pair 是不是真的，如果把 discriminator换成 evaluation function，把 generator 换成解 inference 的 problem，其实 conditional GAN和 structured learning就是可以类比，或者说 GAN 就是训练 structured learning的一种方法。


![mark](http://images.iterate.site/blog/image/20190818/Bdd24no55mgv.png?imageslim)
很多人都有类似的想法，比如 GAN 可以和 Energy—based模型一起做。这里给出一些 Reference。





# 相关

- [leeml-notes](https://github.com/datawhalechina/leeml-notes)


