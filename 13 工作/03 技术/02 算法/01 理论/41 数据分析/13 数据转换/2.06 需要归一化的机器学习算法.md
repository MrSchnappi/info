---
title: 2.06 需要归一化的机器学习算法
toc: true
date: 2019-09-20
---

# 需要归一化的机器学习算法


在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型：

- 有些模型在各个维度进行不均匀伸缩后，最优解与原来不等价，例如 SVM（距离分界面远的也拉近了，支持向量变多？）。对于这样的模型，除非本来各维数据的分布范围就比较接近，否则必须进行标准化，以免模型参数被分布范围较大或较小的数据 dominate。

- 有些模型在各个维度进行不均匀伸缩后，最优解与原来等价，例如 logistic regression（因为θ的大小本来就自学习出不同的 feature 的重要性吧？）。对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛（模型结果不精确）。所以对于具有伸缩不变性的模型，最好也进行数据标准化。


不需要归一化的模型和特征：

- 0/1 取值的特征通常不需要归一化，归一化会破坏它的稀疏性。
- 有些模型不受归一化影响，如 决策树。以 C4.5 为例，决策树在进行节点分裂时主要依据数据集 D 关于特征 x 的信息增益比，而信息增益比跟特征是否经过归一化是无关的，因为归一化并不会改变样本在特征 x 上的信息增益。
- ICA 好像不需要归一化（因为独立成分如果归一化了就不独立了？）。<span style="color:red;">没懂</span>
- 基于平方损失的最小二乘法 OLS 不需要归一化。<span style="color:red;">没懂</span>



# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
- [数据标准化/归一化 normalization](https://blog.csdn.net/pipisorry/article/details/52247379)
- 《百面机器学习》
