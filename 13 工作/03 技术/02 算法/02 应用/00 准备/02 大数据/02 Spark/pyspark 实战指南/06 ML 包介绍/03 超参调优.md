---
title: 03 超参调优
toc: true
date: 2019-07-02
---
6.3 超参调优
我们的第一个模型几乎不可能是我们能做的最好的模型。仅仅只是查看一系列指标便因为它通过了我们预先设定的性能阈值从而接受模型并不是寻求最佳模型的科学方法。
超参调优的概念是找到模型的最佳参数：例如正确估计逻辑回归模型所需的最大迭代次数或决策树的最大深度。
在本节中，我们将探讨两个概念，使我们能够为模型找到最佳参数：grid search和 train-validation splitting。
6.3.1 网格搜索法
网格搜索是一种详尽的算法，根据给定评估指标，循环遍历定义的参数值列表，估计各个单独的模型，从而选择一个最佳的模型。
这里要非常注意：如果你定义的要优化的参数太多或这些参数的值太多，则可能需要大量时间才能选出最佳模型，因为随着参数和参数值的增加，要估计的模型数量将迅速增长。
例如，如果要微调两个参数，每个参数有两个参数值，则需要拟合四个模型。增加一个带有两个值的参数，需要评估八个模型，而给我们的前两个参数再加一个额外的值（每个参数有 3 个参数值）则需要评估九个模型。如你所见，如果不小心，可能会很快就会失控。请看下面的图表来直观的感受一下：
警示之后，让我们来调整参数空间。首先，我们加载包的.tuning部分：
接下来，指定模型和要循环遍历的参数列表：
首先，指定要优化参数的模型。接下来，确定要优化的参数以及要测试的参数的值。我们使用.tuning子包中的 ParamGridBuilder（）对象，并使用.addGrid（……）方法继续将参数添加到网格中：第一个参数是要优化的模型的参数对象（在本例中为 logistic.maxIter和 logistic.regParam），而第二个参数是要循环的值的列表。在.ParamGridBuilder上调用.build（）方法构建网格。


接下来，我们需要某种比较模型的方法：
所以，我们再次使用 BinaryClassificationEvaluator。现在可以开始创建验证逻辑了：
使用 CrossValidator 需要评估器、estimatorParamMaps和 evaluator。该模型循环遍历值的网格，评估各个模型，并使用 evaluator 比较其性能。
我们不能直接使用数据（因为 births_train和 births_test中的 BIRTHS_PLACE列未编码），所以我们创建一个只用于转换的管道：
完成这一步后，就可以开始寻找模型的最佳参数组合了：
cvModel将返回估计的最佳模型。现在可以使用它来看看其是否比以前的模型更好：
以上代码产生如下结果：
如你所见，结果稍微好一点。最佳模型的参数都是什么？答案有点复杂，不过这里展示了如何提取它：


上面的代码产生结果如下：
6.3.2 Train-validation划分
为了选择最佳模型，TrainValidationSplit模型对输入的数据集（训练数据集）执行随机划分，划分成两个子集：较小的训练集和验证集。划分仅执行一次。
本例中，我们还是使用 ChiSqSelector 只选出前五个特征，以此来限制模型的复杂度：
numTopFeatures指定要返回的特征的数量。把 selector 放在 featuresCreator 的后面，以便我们在 featuresCreator 上调用.getOutputCol（）。
之前提到了如何创建 LogisticRegression 和管道，所以这里不再解释如何创建它们了：
TrainValidationSplit对象的创建方式与 CrossValidator 模型相同：
与之前一样，将数据拟合到模型，并计算结果：
如上代码打印如下输出：
当然，特征少的模型比完整的模型表现要差些，但差别并没有那么明显。最终它成了对使用一个复杂模型还是简单点的模型之间的权衡。
