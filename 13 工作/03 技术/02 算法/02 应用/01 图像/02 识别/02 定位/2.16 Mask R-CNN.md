---
title: 2.16 Mask R-CNN
toc: true
date: 2019-09-03
---

# Mask R-CNN

2017年 Kaiming He等提出了 Mask R-CNN ，并获得 ICCV2017 Best Paper Award。作者指出，Faster R-CNN在做下采样和 RoI Pooling时都对特征图大小做了取整操作，这种做法对于分类任务基本没有影响，但对检测任务会有一定影响，对语义分割这种像素级任务的精度影响则更为严重。为此，作者对网络中涉及特征图尺寸变化的环节都不使用取整操作，而是通过双线性差值填补非整数位置的像素。这使得下游特征图向上游映射时没有位置误差，不仅提升了目标检测效果，还使得算法能满足语义分割任务的精度要求。

![mark](http://images.iterate.site/blog/image/20190905/S3ulcHsKxd2y.png?imageslim)

以上介绍的检测方法都属于 two-stage的方案，即分为候选区域生成和区域分类两步，接下来我们将介绍几种 single-stage的经典方法。


<span style="color:red;">嗯，这个 RoI Align 还是很清楚的，不过补充下怎么执行的插值运算。</span>

**Mask R-CNN 有哪些创新点？**

1. Backbone：ResNeXt-101+FPN
2. RoI Align 替换 RoI Pooling

Mask R-CNN 是一个实例分割（Instance segmentation）算法，主要是在目标检测的基础上再进行分割。Mask R-CNN 算法主要是 Faster R-CNN+FCN，更具体一点就是 ResNeXt+RPN+RoI Align+Fast R-CNN+FCN。

<center>

![](http://images.iterate.site/blog/image/20190722/Y4ddCER6wtMI.png?imageslim){ width=55% }

</center>


**Mask R-CNN 算法步骤**

1. 输入一幅你想处理的图片，然后进行对应的预处理操作，或者预处理后的图片；
2. 将其输入到一个预训练好的神经网络中（ResNet 等）获得对应的 feature map；
3. 对这个 feature map 中的每一点设定预定个的 RoI，从而获得多个候选 RoI；<span style="color:red;">每一点设定多个 ROI 吗？</span>
4. 将这些候选的 RoI 送入 RPN 网络进行二值分类（前景或背景）和 BB 回归，过滤掉一部分候选的 RoI；<span style="color:red;">什么是 BB 回归？</span>
5. 对这些剩下的 RoI 进行 RoI Align 操作（即先将原图和 feature map 的 pixel 对应起来，然后将 feature map 和固定的 feature 对应起来）；
6. 对这些 RoI 进行分类（N 类别分类）、BB 回归和 MASK 生成（在每一个 RoI 里面进行 FCN 操作）。<span style="color:red;">什么是 Mask 生成？</span>

**RoI Pooling 和 RoI Align 有哪些不同？**

ROI Align 是在 Mask-RCNN 中提出的一种区域特征聚集方式，很好地解决了 RoI Pooling 操作中两次量化造成的区域不匹配(mis-alignment)的问题。实验显示，在检测任务中将 RoI Pooling 替换为 RoI Align 可以提升检测模型的准确性。

在常见的两级检测框架（比如 Fast-RCNN，Faster-RCNN，RFCN）中，RoI Pooling 的作用是根据预选框的位置坐标在特征图中将相应区域池化为固定尺寸的特征图，以便进行后续的分类和包围框回归操作。由于预选框的位置通常是由模型回归得到的，一般来讲是浮点数，而池化后的特征图要求尺寸固定。故 RoI Pooling 这一操作存在两次量化的过程：

- 将候选框边界量化为整数点坐标值。
- 将量化后的边界区域平均分割成 $k\times k$ 个单元(bin)，对每一个单元的边界进行量化。

事实上，经过上述两次量化，此时的候选框已经和最开始回归出来的位置有一定的偏差，这个偏差会影响检测或者分割的准确度。在论文里，作者把它总结为 “不匹配问题（misalignment）”。

下面我们用直观的例子具体分析一下上述区域不匹配问题。如下图所示，这是一个 Faster-RCNN 检测框架。输入一张 $800\times 800$ 的图片，图片上有一个 $665\times 665$ 的包围框（框着一只狗）。图片经过主干网络提取特征后，特征图缩放步长（stride）为 32。因此，图像和包围框的边长都是输入时的 1/32。800 正好可以被 32 整除变为 25。但 665 除以 32 以后得到 20.78，带有小数，于是 RoI Pooling 直接将它量化成 20。接下来需要把框内的特征池化 $7\times 7$ 的大小，因此将上述包围框平均分割成 $7\times 7$ 个矩形区域。显然，每个矩形区域的边长为 2.86，又含有小数。于是 ROI Pooling 再次把它量化到 2。经过这两次量化，候选区域已经出现了较明显的偏差（如图中绿色部分所示）。更重要的是，该层特征图上 0.1 个像素的偏差，缩放到原图就是 3.2 个像素。那么 0.8 的偏差，在原图上就是接近 30 个像素点的差别，这一差别不容小觑。<span style="color:red;">是的，这个对于精准度影响很大。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/oYUJzui2h5yu.png?imageslim){ width=75% }

</center>


为了解决 RoI Pooling 的上述缺点，作者提出了 RoI Align 这一改进的方法(如图 2)。

<center>

![](http://images.iterate.site/blog/image/20190722/sog0q0jx9XOE.png?imageslim){ width=75% }

</center>


RoI Align 的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值，从而将整个特征聚集过程转化为一个连续的操作。

值得注意的是，在具体的算法操作上，RoI Align 并不是简单地补充出候选区域边界上的坐标点，然后将这些坐标点进行池化，而是重新设计了一套比较优雅的流程，如下图所示：

1. 遍历每一个候选区域，保持浮点数边界不做量化。
2. 将候选区域分割成 $k\times k$ 个单元，每个单元的边界也不做量化。
3. 在每个单元中计算固定四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化操作。<span style="color:red;">嗯。</span>

这里对上述步骤的第三点作一些说明：这个固定位置是指在每一个矩形单元（bin）中按照固定规则确定的位置。比如，如果采样点数是 $1$，那么就是这个单元的中心点。如果采样点数是 $4$，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。<span style="color:red;">怎么使用插值的方法得到像素值的？</span>在相关实验中，作者发现将采样点设为 $4$ 会获得最佳性能，甚至直接设为 $1$ 在性能上也相差无几。事实上，RoI Align 在遍历取样点的数量上没有 RoI Pooling 那么多，但却可以获得更好的性能，这主要归功于解决了 mis alignment 的问题。值得一提的是，我在实验时发现，RoI Align 在 VOC 2007 数据集上的提升效果并不如在 COCO 上明显。经过分析，造成这种区别的原因是 COCO 上小目标的数量更多，而小目标受 mis alignment 问题的影响更大（比如，同样是 0.5 个像素点的偏差，对于较大的目标而言显得微不足道，但是对于小目标，误差的影响就要高很多）。<span style="color:red;">嗯，是的。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/EYPww8AE8Xp0.png?imageslim){ width=55% }

</center>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
