---
title: 03 想要使用机器学习来发掘表示本身
toc: true
date: 2019-08-31
---
# 使用机器学习来发掘表示本身

然而，对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想编写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车轮的存在与否作为特征。遗憾的是，我们难以准确地根据像素值来描述车轮看上去像什么。虽然车轮具有简单的几何形状，但它的图像可能会因场景而异，如落在车轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的前景物体等。

解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。<span style="color:red;">嗯，的确，用机器学习来发掘表示本身，而不仅仅把表示映射到输出。</span>这种方法我们称之为表示学习(representation learning)。<span style="color:red;">这个地方为什么称这种情况为表示学习？我们有必要给这个单独起一个名字吗？那么跟它同一层级的还有什么？</span>学习到的表示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让 AI 系统迅速适应新的任务。表示学习算法只需几分钟就可以为简单的任务发现一个很好的特征集，对于复杂任务则需要几小时到几个月。<span style="color:red;">还是没明白表示学习到底指的那些？感觉也就是从随机树中抽取特征或者从神经网络中抽取特征比较像是表示学习，还有别的表示学习吗？还是说这两种实际上并不是表示学习？表示学习的关键是什么？抽取特征吗？</span><span style="color:blue;">嗯，下面有说自编码器。嗯。</span>手动为一个复杂的任务设计特征需要耗费大量的人工、时间和精力，甚至需要花费整个社群研究人员几十年的时间。

表示学习算法的典型例子是自编码器(autoencoder)。<span style="color:red;">哦，好的，好的，自编码器。嗯之前又看到过，但是忘记了，补充下。</span>自编码器由一个编码器(encoder)函数和一个解码器(decoder)函数组合而成。编码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换回原来的形式。我们期望当输入数据经过编码器和解码器之后尽可能多地保留信息，同时希望新的表示有各种好的特性，这也是自编码器的训练目标。为了实现不同的特性，我们可以设计不同形式的自编码器。<span style="color:red;">这句话是什么意思？为了实现不同的特性，我们可以设计不同形式的自编码器。有那些形式的自编码器？感觉之前就记得是通过网络把输入不断降维，相当于编码，然后又不断升维，相当于解码。</span>

当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观察数据的变差因素(factors of variation)。<span style="color:red;">厉害这个名词，特征抽取的目的是为了分离出能解释观察数据的变差因素 factors of variation。嗯。</span>在此背景下，“因素”这个词仅指代影响的不同来源；<span style="color:red;">因素通常不是乘性组合。因素通常不是乘性组合是什么意思？为什么不是乘性组合？可以是吗？</span>这些因素通常是不能被直接观察到的量。嗯。相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量。为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的形式存在于人类的思维中。<span style="color:red;">嗯，是的。</span>它们可以被看作数据的概念或者抽象，帮助我们了解这些数据的丰富多样性。当分析语音记录时，变差因素包括说话者的年龄、性别、他们的口音和他们正在说的词语。当分析汽车的图像时，变差因素包括汽车的位置、它的颜色、太阳的角度和亮度。

在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能够观察到的每一个数据。比如，在一张包含红色汽车的图片中，其单个像素在夜间可能会非常接近黑色。汽车轮廓的形状取决于视角。大多数应用需要我们理清变差因素并忽略我们不关心的因素。<span style="color:red;">嗯，这个如果人工设定真的是难。</span>

显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。



# 相关

- 《深度学习》花书
