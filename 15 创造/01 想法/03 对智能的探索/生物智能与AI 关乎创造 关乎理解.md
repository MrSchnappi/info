---
title: 生物智能与AI 关乎创造 关乎理解
toc: true
date: 2019-10-01
---
# 可以补充进来的

# 生物智能与AI 关乎创造 关乎理解


**摘要：** 原来人工智能跟人类智能有那么深的联系！



几百万年前，第一次人类智能的星火出现在非洲大陆，并且持续发展，最终在大约10万年前在智人的大脑中达到顶峰。作为现代人类，我们只能想象我们的古代祖先在窥视夜空时所经历的事情，以思考物理现实的本质，以及从内心窥视自己心理现实的本质。在过去的几百年里，我们的物种通过发现控制空间、时间、物质和能量的基本数学定律。在发展对物理现实的精确理解方面取得了巨大的智力进步，现在已经在量子力学的大框架中被编纂。然而，我们正处于探索心理现实本质的最初阶段。尤其是人类智能是如何从100亿个突触连接的1000亿个神经元的生物湿件中产生的？神经科学，心理学和认知科学等现代学科在过去100年中取得了重要进展，为解决这一重大问题奠定了基础。

但是，当涉及到我们的心智能力时，对于现代人来说，仅仅理解它们是不够的，我们非常希望在无生命系统中重现这些功能。本质上，人类作为进化的产物，有时也渴望扮演创造者的角色。这种向往渗透在人类文学的作品，事实上，人工智能（AI）这个新兴领域，通常与神经科学，心理学和认知科学领域合作，在创造具有类似人类能力的机器方面取得了巨大进步。在这篇文章中，我将进一步探讨人工智能，神经科学，心理学和认知科学以及数学，物理和社会科学中的联合学科在过去和未来将继续如何共同努力追求交织在一起的理解和创造智能系统的过程。

## **生物学与人工智能之间的富有成效的合作**

在过去的60多年中，AI的发展受到了神经科学和心理学的深刻影响，其中也受到了神经科学和心理学的启发。在早期的几十年中，许多AI从业者在神经科学和心理学方面进行了很好的研究。在这里，我提供了神经科学，心理学和AI之间过去的相互作用：

- 这种相对简单的元素（神经元）的分布式网络能够实现源于神经科学的人类智能的显着计算，并且现在以神经网络的形式渗透到AI系统中。这个想法并不总是显而易见的，在大约一百年前，在高尔基和卡哈尔之间的著名辩论之后，它才变得坚定。
- 包括多维尺度和因子分析在内的各种降维技术最初是在心理测量学研究的背景下开发的。
- 著名的神经科学家霍勒斯·巴洛（Horace Barlow）发明了分解代码的概念，这反过来启发了独立成分分析（ICA）和当前的AI研究，旨在解开数据变异的独立因素。
- 托尔曼在认知图上的工作提供了方向，使得我们可以使用这些模型进行规划和导航。这巩固了内部模型形成作为动物智能的关键组成部分的思想，这部分目前处于人工智能研究的前沿。
- Hopfield网络是理论神经科学的一个模型，为思考分布式、可寻址的存储器和检索提供了一个统一的框架，也启发了Boltzmann机器，这反过来又为证明深度神经网络模型的成功提供了关键的第一步。它还启发了许多弱约束的分布式以满足作为AI计算模型的想法。
- 目前主导机器视觉的深层卷积网络的关键核心直接受到大脑的启发。其中包括腹侧流中的分层视觉处理，它表明深度的重要性;视网膜的发现是整个视觉皮层的组织原理，导致卷积的出现;发现简单和复杂的细胞激发了最大池化等操作。
- 关于稀疏编码的研究工作是为了理解初级视觉皮层中定向边缘检测器，导致稀疏编码成为现代AI系统中的基本构建块。
- 时序差分学习等算法现在是强化学习领域的基础，它受到经典条件反射的动物实验的启发。
- 反过来，强化学习对基底神经节功能的解释具有显着影响，其中多巴胺能为基底神经节提供了非常重要的奖励预测误差信号，该信号也驱动许多强化学习算法。
- 大脑中存储系统的模块化启发了现代记忆神经网络，其在一定程度上将存储器存储和执行控制电路的操作分开，其决定何时从存储器读取和写入。
- 人类注意力系统激发了注意力机制和神经网络的结合，这些神经网络可以被训练以动态地注意力或忽略其状态和输入的不同方面以进行未来的计算决策。
- 语言学和认知科学中正式生成语法的发展导致概率语法的发展和CS的解析。
- Dropout等现代正则化技术的灵感来自于神经动力学的内在随机性。

## **人工智能未来的生物学启示**

尽管当前人工智能系统在监督模式识别任务方面取得了显著的商业成功，但仿真人类智能仍然有很长的路要走。在这里，我将概述一些个人观点，其中我认为生物学和人工智能领域可以携手前进。

**1、生物学上可信的信用分配（plausible credit assignment）**

信用分配问题可能是神经科学和人工智能领域最大的开放性问题之一。很明显，假设你正在打网球而且你没有击中球。你的100万亿个突触中有哪一个应该受到指责？大脑如何在你的运动系统中专门找到并纠正突触组，尤其是在错误发生后几百毫秒内通过视觉系统传递错误时？在AI中，这种信用分配问题在许多情况下通过多层计算的反向传播来解决。然而，目前尚不清楚大脑如何解决这个问题。真实的情况是，大脑使用本地学习规则解决它：即每个突触仅使用物理上可用的信息来调整其强度，例如，由突触连接的两个神经元的电活动来奖励和惩罚的任何神经调节输入。解释这些本地突触规则是什么以及它们如何工作可能会对AI产生巨大影响，这可以一定程度上减少反向传播的通信开销。但更一般地说，解决困扰神经科学和人工智能的常见未解决问题应该通过将突触生理学家，计算神经科学家和AI从业者聚集在一起来集体解决生物学上可信的信用分配问题来推动进步。

**2、融合突触复杂性**

生物和人工神经模型之间的主要区别在于我们模拟连接神经元的突触的方式。在人工网络中，突触由单个标量值建模，反映乘法增益因子，转换神经元的输入如何影响神经元的输出。相反，每个生物突触都隐藏在极其复杂的分子信号通路中。例如，我们对最近事件记忆的海马突触各自包含数百种不同类型分子的化学反应网络，同时它具有整个复杂时间处理能力的动力系统。

在看到这种复杂性后，理论家或工程师可能会试图简单地将其视为生物学上的混乱，而这种混乱就是一种进化的偶然事件。然而，理论研究表明，这种突触复杂性可能确实对学习和记忆至关重要。事实上，在突触具有有限动态范围的记忆网络模型中，这样的突触本身就要求是具有复杂时间滤波特性的动态系统，以实现合理的网络存储容量。此外，最近在AI中正在利用更智能的突触作为解决灾难性遗忘问题的一种方法，其中训练学习两个任务的网络只能学习第二个任务，因为学习第二个任务会改变突触权重以这种方式消除从学习第一项任务中获得的知识。

一般地说，我们的人工智能系统很可能通过忽略生物突触的动态复杂性而取得重大的性能提升。正如我们为我们的网络添加空间深度以实现复杂的层次表示一样，我们可能还需要为突触添加动态深度以实现复杂的时间学习功能。



<center>

![mark](http://images.iterate.site/blog/image/20190930/ptOdQmn24FWn.png?imageslim)


</center>

单个突触内的复杂分子状态可以帮助学习和记忆。



## **从系统级模块化大脑架构中获取灵感**

通常，当前的商业AI系统涉及具有相对均匀的分层或循环架构的训练网络，其从随机权重开始。但是，对于更复杂的任务来说，这可能是一个难以解决的问题。事实上，生物进化的道路却截然不同。所有脊椎动物的最后共同祖先生活在5亿年前。从那以后，它的基本大脑一直在发展，导致大约1亿年前出现哺乳动物大脑，以及几百万年前的人类大脑。这种不间断的进化链导致了一个错综复杂的大脑结构，具有高度保守的计算元素和巨大的系统级模块化。事实上，我们目前缺乏工程设计原则，来解释像大脑一样复杂的传感，通信，控制和记忆网络可以在5亿年的时间内不断扩大规模和复杂性，同时永远不会失去在动态环境中自适应运行的能力。因此，AI从大脑的系统级结构中获取灵感可能非常有趣。

一个关键的系统属性是功能和结构的模块化。大脑不像我们目前的AI架构是同质的，而是有不同的模块，如海马（保留情节记忆和导航），基底神经节（潜在的强化学习和动作选择）和小脑（自动化的运动控制和通过监督学习获得更高层次的认知）。此外，人脑中的记忆系统（习惯记忆，运动技能，短期记忆，长期记忆，情景记忆，语义记忆）也是功能模块化的。此外，在运动系统中，嵌套反馈环架构占主导地位，通过简单的快速循环在20毫秒内实现自动运动校正，稍慢的智能循环通过运动皮层在50毫秒内实现更复杂的运动校正，最后经过整个大脑的视觉反馈实现对运动错误的有意识的校正。最后，所有哺乳动物大脑的一个主要特征是由大量相似的6层皮质柱组成的新皮层，所有这些都被认为是在单个规范计算模块上实现的变异。

总体而言，现代哺乳动物大脑具有显著的模块性，通过1亿年的进化保存下来，表明这种系统级模块化可能有利于在AI系统中实施。目前从白板上训练神经网络的方法是不可能走向更普遍的人类智能的途径。实际上，系统级模块化的组合带来的不同类型的纠错嵌套循环和动态复杂的突触可能都是解决生物学上可信的信用分配的关键因素。



<center>

![mark](http://images.iterate.site/blog/image/20190930/K3mLNk4C7CkE.png?imageslim)

</center>


5亿年的脊椎动物大脑进化创造了一个高度异构和模块化的计算系统。


**无监督学习，迁移学习和工程设计**

AI系统与人类学习之间的另一个主要差异在于AI系统所需的大量标记数据才可以达到人类级别的性能。例如，最近的语音识别系统在11940小时的语音训练后才能对齐转录。如果我们每天大声地听到另一个人类阅读文本两个小时，那么我们需要16年才能获取到这个数据集。AlphaGozero练习了490万场才击败人类围棋大师。如果一个人每天玩围棋30年，那么他每天必须玩450场比赛才能达到AlphaGozero的练习量。此外，最近关于视觉问答的数据集包含了0.25M图像，0.76M问题和10M答案。如果我们每天收到关于图像的100个问题的答案，我们需要274年的时间来吸收这种规模的数据集。很明显人类接受的标记训练数据量要少得多，但他们可以识别语音，玩围棋并很好地回答有关图像的问题。

其中，人工智能和生物智能之间差距的几个关键在于人类从未标记数据中学习的能力（无监督学习），以及在解决先前任务时获得的强大先验知识，并将这些知识转移到新任务中（迁移学习）。最后，人类社会建立了教育系统，精心挑选一些学习任务进行教学，以促进知识获取。为了在人工系统中有效地实例化这些概念，我们需要更深入地理解和数学形式化人类和其他动物如何进行无监督学习及知识如何在任务之间转移，这需要计算机科学家、心理学家和教育工作者的参与。因为这对于在标记数据稀缺的领域中训练AI是至关重要。



<center>

![mark](http://images.iterate.site/blog/image/20190930/mT8F5cp301ds.png?imageslim)

</center>


Taskonomy：斯坦福大学进行了26个不同的视觉任务之间迁移学习的研究。

**建立理解，规划和主动因果学习的世界模型**

当前AI在商业环境中的成功很多是通过监督方法实现的，其中AI系统被动地接收输入，被告知正确的输出，并且它调整其参数以匹配每个输入-输出组合。相比之下，婴儿就像活跃的科学家一样探索他们的环境。例如：利用魔术，婴儿会看到两个“魔法”物体：物体A，它似乎穿过墙壁，而物体B，它在掉落时不会掉落。给婴儿A，B，婴儿将尝试将物体A穿过墙壁，然后放下物体B以查看它是否会掉落。这项非凡的实验表明，婴儿就像科学家一样，积极地探索他们的世界。

因此，与当前大多数的商业AI系统不同，婴儿具有学习和利用世界模型的卓越能力。我们需要在神经科学和人工智能方面进一步研究从经验中学习世界模型，使用这些世界模型进行规划（即，根据当前行动想象不同的未来），并使用这些未来的计划来做出决策。这种基于模型的规划和决策可能是当前无模型强化学习系统的有力支持，该系统简单地将世界状态映射到值或预期的未来奖励。人工智能中的这项工作可以与神经科学的工作携手并进，揭示动物的神经活动如何与想象的和未来相关。像好奇心这样的基本驱动可以形式化为强化学习系统，以此来促进学习和探索。更一般地，深入理解多个系统和促进动物和人类学习的内在生物驱动可能对加速人工系统的学习非常有益。



<center>

![mark](http://images.iterate.site/blog/image/20190930/qlj7QW9T6pql.png?imageslim)

</center>

科学家发现他的感官体验统计数据有变化

**在后摩尔定律时代实现节能计算**

生物系统和AI系统之间的另一个数量级差异在于它们的能量消耗。人脑仅消耗20瓦的功率，而超级计算机则以兆瓦的功率运行。造成这种差异的一个关键原因可能是过度依赖数字计算本身，虽然数字革命推动了现代信息技术的兴起，但现在我们对实现人工智能的追求被认为是次优遗留技术。原因是数字计算需要在计算的中间阶段以极高的可靠性翻转每一位。然而，热力学定律则为每个快速可靠的位翻转确定了相当大的能量成本。

相比之下，生物的细胞内的分子以及脑内神经元的计算看起来令人惊讶地嘈杂和不精确。然而，生物计算的每个中间步骤都足够可靠，以使最终答案足够好。此外，大脑智能地向上或向下调节能量成本根据所需的通信速度。例如，考虑大脑中通过目标神经元的单位的成本。它开始于囊泡的随机释放，其以1毫米/秒的速度扩散到源神经元和目标神经元之间的空间，仅燃烧2.3毫微微焦耳（fj）。速度刚刚好，因为神经元连接之间的空间只有20纳米。该化学信号被转换为无源电信号，其以1米/秒的速度流过神经元细胞体，燃烧23fj横穿约10微米。最后，它到达轴突终端并转换为长轴，沿着轴突每秒行进100米，燃烧6000 fJ行进1厘米。因此，在从化学信号传递到被动电信号时，大脑动态地将通信速度上调1000倍，以跨越增加1000倍的距离，从而导致能量消耗增加10倍。

因此，只有在需要更高速度且仅需要更高可靠性时，大脑才会消耗更多能量。相比之下，数字计算机在刚性同步时钟上运行，并且在每个时钟周期，许多晶体管必须可靠地翻转状态。总之，生物计算的明显混乱不一定是不可避免的混乱，而是可能反映出高能效设计的理想原则。为了在我们的AI硬件中实现这样的效率，遵循生物计算的这些原则可能是必要的。



<center>

![mark](http://images.iterate.site/blog/image/20190930/bEltIUHTqEIE.png?imageslim)

</center>

Neurogrid：由斯坦福大脑开发的一种生物启发的神经形态计算机。

**用于AI的神经科学和神经科学的AI：一种良性的科学螺旋**

最近神经科学和AI之间相互作用促进了深度和递归神经网络模型的发展。在许多情况下，当训练深度或递归网络来解决任务时，其内部表现看起来与训练为解决相同任务的动物中测量的内部神经活动模式非常相似。因此，我们通常会在不同的任务中获得不同大脑区域操作的高度复杂但令人惊讶的真实模型，从而提出了一个基本问题：我们如何理解这些模型正在做什么以及它们如何工作？更确切地说，学习网络连接和神经动态如何产生高性能？AI目前在理解它的神经模型正在做什么时面临同样的问题，虽然一些工程师认为没有必要了解神经网络是如何工作的。然而，对于当前网络的成功和失败如何因其连通性和动态性而产生的更深入的科学理解将导致网络的优化。然而，科学与技术之间的相互作用历史上几乎没有更深入的科学认识，也不会导致更好的技术。但是，在AI的某些应用中，特别是在医学诊断或法律中，可解释的AI是必不可少的。例如，如果医生和法官无法理解为什么这些系统做出了他们做出的决定，他们就不会在他们的案件中使用人工智能系统的建议。

因此，神经科学需要共享理解网络性能和决策如何作为网络连接和动态的新兴属性。因此，理论神经科学，应用物理学和数学的思想和理论的发展可以帮助分析AI系统。此外，AI系统的行为可能会改变神经科学中实验设计的本质，将实验工作集中在AI中难以理解的网络功能方面。总体而言，神经科学，人工智能和许多其他理论学科之间的紧密联系可以获得很多灵感，这可能会为生物和人工系统中的智能的出现带来统一的规律。



<center>

![mark](http://images.iterate.site/blog/image/20190930/l3N0vns7Q4Li.png?imageslim)

</center>

任务驱动的视觉系统卷积循环模型可以同时执行机器视觉任务并解释猴子视觉系统的动态

**寻求管理生物和人工智能的普遍规律**

在人工智能系统设计中，一种经常被引用的无视生物学的争论常涉及到飞机与鸟类的比较。然而，仔细观察这个想法会发现更多的细微差别。飞行的一般问题涉及解决两个基本问题：（1）为了前进而产生推力，（2）升力的大小使我们不会脱离天空。鸟类和飞机用不同方法解决了推力问题：鸟儿拍翅膀和飞机使用喷气发动机。但是，它们以完全相同的方式解决升力问题，通过使用弯曲的翼形，在低于和低于上方的气压下产生更高的气压。因此，滑翔的鸟类和飞机的运作非常相似。

实际上，我们知道空气动力学的一般物理定律：不同形状通过空气时，都可以用计算的方法来预测产生的力，如升力和推力。而且，任何解决飞行问题的方法，无论是生物还是人工，都必须遵守空气动力学定律。

更一般地说，在我们对物理世界的研究中，我们习惯于存在管理其行为的原则或规律。例如，正如空气动力学控制飞行物体的运动一样，广义相对论控制着空间和时间的曲率，量子力学控制着纳米世界的演化。我们认为，可能存在普世原则或法律来管理智能行为如何从大型互连神经元网络的合作活动中产生。这些法律可以连接和统一神经科学、心理学、认知科学和人工智能的相关学科，他们的阐述也需要帮助分析和计算领域，如物理，数学和统计学。事实上，这篇文章的作者使用了动力系统理论、统计力学、黎曼几何、随机矩阵理论和自由概率理论等技术，获得了对生物和人工网络运作的概念性见解。然而，为了阐明管理非线性分布式网络中出现智能的一般规律和设计原则，还需要进一步的工作，包括开发新概念，分析方法和工程能力。最终，就像鸟类，飞机和空气动力学的故事一样，创造智能机器的问题可能存在多种解决方案，其中一些组件在生物解决方案和人工解决方案之间共享，而其他组件则可能不同。通过寻求一般的智力法则，发现适用于生物和人工系统的新兴智能的潜在法则，以及建立受神经科学和心理学启发的新型AI，需要许多研究人员共同努力：计算机科学家追求更好的AI系统，神经科学家，心理学家和认知科学家探索大脑和思想的属性，数学家，物理学家，统计学家和其他理论家寻求形式化我们的综合知识并发现一般的法律和原则。

## 相关

- [生物智能与AI——关乎创造、关乎理解（上）](https://zhuanlan.zhihu.com/p/52567784)
- [生物智能与AI——关乎创造、关乎理解（下）](https://www.jianshu.com/p/f077a36a0fab)
