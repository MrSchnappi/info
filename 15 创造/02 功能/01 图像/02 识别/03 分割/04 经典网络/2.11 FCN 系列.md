---
title: 2.11 FCN 系列
toc: true
date: 2019-09-01
---

**三种模型 FCN-32S, FCN-16S, FCN-8S**

**主要贡献：**

不含全连接层(fc)的全卷积(fully conv)网络。可适应任意尺寸输入。
增大数据尺寸的反卷积(deconv)层。能够输出精细的结果。
结合不同深度层结果的跳级(skip)结构。同时确保鲁棒性和精确性。



### 9.3.1 FCN 改变了什么?

对于一般的分类 CNN 网络，如 VGG 和 Resnet，都会在网络的最后加入一些全连接层，经过 softmax 后就可以获得类别概率信息。但是这个概率信息是 1 维的，即只能标识整个图片的类别，不能标识每个像素点的类别，所以这种全连接方法不适用于图像分割。

而 FCN 提出可以把后面几个全连接都换成卷积，这样就可以获得一张 2 维的 feature map，后接 softmax 层获得每个像素点的分类信息，从而解决了分割问题，如图 4。<span style="color:red;">嗯，有点机智。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/Cl8ftVKmSkx1.jpg?imageslim){ width=75% }

</center>




### 9.3.2 FCN 网络结构？

FCN 对图像进行像素级的分类，从而解决了语义级别的图像分割（semantic segmentation）问题。与经典的 CNN 在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的 feature map 进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测，同时保留了原始输入图像中的空间信息，<span style="color:red;">怎么使用反卷积层进行上采样的？</span>最后在上采样的特征图上进行逐像素分类。
下图是语义分割所采用的全卷积网络(FCN)的结构示意图：

<center>

![](http://images.iterate.site/blog/image/20190722/yyKQefop5hWf.jpg?imageslim){ width=75% }

</center>


### 9.3.3 全卷积网络举例？

通常 CNN 网络在卷积层之后会接上若干个全连接层，将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。

以 AlexNet 为代表的经典 CNN 结构适合于图像级的分类和回归任务，因为它们最后都得到整个输入图像的一个概率向量。

<center>

![](http://images.iterate.site/blog/image/20190722/gsw8TyyYb91e.jpg?imageslim){ width=75% }

</center>



如上图所示：

- 在 CNN 中，猫的图片输入到 AlexNet，得到一个长为 1000 的输出向量，表示输入图像属于每一类的概率，其中在“tabby cat”这一类统计概率最高，用来做分类任务。
- FCN与 CNN 的区别在于把 CNN 最后的全连接层转换成卷积层，输出的是一张已经带有标签的图片，而这个图片就可以做语义分割。
- CNN 的强大之处在于它的多层结构能自动学习特征，并且可以学习到多个层次的特征: 较浅的卷积层感知域较小，学习到一些局部区域的特征；较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征。高层的抽象特征对物体的大小、位置和方向等敏感性更低，从而有助于识别性能的提高，所以我们常常可以将卷积层看作是特征提取器。




### 9.2.6 把全连接层的权重 $W$ 重塑成卷积层的滤波器有什么好处？


这样的转化可以在单个向前传播的过程中，使得卷积网络在一张更大的输入图片上滑动，从而得到多个输出(可以理解为一个 label map)。<span style="color:red;">什么是更大的输入图片上滑动？</span>

比如: 我们想让 $224×224$ 尺寸的浮窗，以步长为 $32$ 在 $384×384$ 的图片上滑动，把每个经停的位置都带入卷积网络，最后得到 $6×6$ 个位置的类别得分，那么通过将全连接层转化为卷积层之后的运算过程为:

如果 $224×224$ 的输入图片经过卷积层和下采样层之后得到了 $[7\times 7\times 512]$ 的数组，那么，$384×384$ 的大图片直接经过同样的卷积层和下采样层之后会得到 $[12\times 12\times 512]$ 的数组，然后再经过上面由 $3$ 个全连接层转化得到的 $3$ 个卷积层，<span style="color:red;">什么 3 个全连接层？</span>最终得到 $[6\times 6\times 1000]$ 的输出( $(12 – 7)/1 + 1 = 6$ )，这个结果正是浮窗在原图经停的 $6×6$ 个位置的得分。

一个确定的 CNN 网络结构之所以要固定输入图片大小，是因为全连接层权值数固定，而该权值数和 feature map大小有关，但是 FCN 在 CNN 的基础上把 $1000$ 个结点的全连接层改为含有 $1000$ 个 $1×1$ 卷积核的卷积层，经过这一层，还是得到二维的 feature map，同样我们也不关心这个 feature map大小，所以对于输入图片的 size 并没有限制。

如下图所示，FCN 将传统 CNN 中的全连接层转化成卷积层，对应 CNN 网络 FCN 把最后三层全连接层转换成为三层卷积层:

<center>

![](http://images.iterate.site/blog/image/20190722/wUyoKWK2gURl.png?imageslim){ width=85% }

</center>


<center>一个分类网络</center>
<center>

![](http://images.iterate.site/blog/image/20190722/geUVc0QvFuuu.png?imageslim){ width=85% }

</center>


<center>变为全卷积网络</center>
<center>

![](http://images.iterate.site/blog/image/20190722/PUyrtAjbJK3m.png?imageslim){ width=85% }

</center>


<center>End-to-end，pixels-to pixels网络</center>
<center>

![](http://images.iterate.site/blog/image/20190722/bTyMVA7zBoJa.jpg?imageslim){ width=85% }

</center>

<span style="color:red;">看到这个理解了，这个的确与输入图片尺寸无关。</span>

1. 全连接层转化为全卷积层 : 在传统的 CNN 结构中，前 $5$ 层是卷积层，第 $6$ 层和第 $7$ 层分别是一个长度为 $4096$ 的一维向量，第 $8$ 层是长度为 $1000$ 的一维向量，分别对应 $1000$ 个不同类别的概率。FCN 将这 $3$ 层表示为卷积层，卷积核的大小 $(通道数，宽，高)$ 分别为 $(4096,1,1)$、$(4096,1,1)$、$(1000,1,1)$。看上去数字上并没有什么差别，但是卷积跟全连接是不一样的概念和计算过程，使用的是之前 CNN 已经训练好的权值和偏置，但是不一样的在于权值和偏置是有自己的范围，属于自己的一个卷积核。<span style="color:red;">使用的是之前 CNN 训练好的权值和偏置吗？真的可以吗？</span>
2. CNN 中输入的图像大小是统一固定成 $227\times 227$ 大小的图像，第一层 pooling 后为 $55\times 55$，第二层 pooling 后图像大小为 $27\times 27$，第五层 pooling 后的图像大小为 $13\times 13$，而 FCN 输入的图像是 $H * W$ 大小，第一层 pooling 后变为原图大小的 $1/2$，第二层变为原图大小的 $1/4$，第五层变为原图大小的 $1/8$，第八层变为原图大小的 $1/16$。
3. 经过多次卷积和 pooling 以后，得到的图像越来越小，分辨率越来越低。其中图像到 $H/32 * W/32$ 的时候图片是最小的一层时，所产生图叫做 heatmap 热图，热图就是我们最重要的高维特征图，得到高维特征的 heatmap 之后就是最重要的一步也是最后的一步对原图像进行 upsampling，把图像进行放大几次到原图像的大小。

相较于使用被转化前的原始卷积神经网络对所有 36 个位置进行迭代计算优化模型，然后再对 36 个位置做预测，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为 36 次计算都在共享计算资源。这一技巧在实践中经常使用，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。<span style="color:red;">这段没明白。</span>


### 9.2.7 反卷积层理解

Upsampling 的操作可以看成是反卷积(deconvolutional)，卷积运算的参数和 CNN 的参数一样是在训练 FCN 模型的过程中通过 bp 算法学习得到。

反卷积层也是卷积层，不关心 input 大小，滑窗卷积后输出 output。deconv 并不是真正的 deconvolution（卷积的逆变换），最近比较公认的叫法应该是 transposed convolution，<span style="color:red;">嗯，是转置卷积吗？</span>deconv 的前向传播就是 conv 的反向传播。<span style="color:red;">是这样吗？怎么理解？</span>

反卷积参数: 利用卷积过程 filter 的转置（实际上就是水平和竖直方向上翻转 filter）作为计算卷积前的特征图。<span style="color:red;">没明白。</span>

反卷积的运算如下所示:<span style="color:red;">没有理解。具体是怎么计算的？核需要进行旋转吗？怎么填充的？</span>

蓝色是反卷积层的 input，绿色是反卷积层的 outputFull padding，transposed Full padding，transposed。

<center>

![](http://images.iterate.site/blog/image/20190722/yXsCUryYpXlT.png?imageslim){ width=55% }

</center>


上图中的反卷积，input是 2×2，output是 4×4。     Zero padding，non-unit strides，transposed。


<center>

![](http://images.iterate.site/blog/image/20190722/sm8PEswsHrO4.png?imageslim){ width=55% }

</center>

上图中的反卷积，input feature map是 3×3，转化后是 5×5，output是 5×5

<span style="color:red;">怎么 transposed 的？怎么添加中间的 zero padding 的？</span>


### 9.2.8 跳级(skip)结构

对 CNN 的结果做处理，得到了 dense prediction，而作者在试验中发现，得到的分割结果比较粗糙，所以考虑加入更多前层的细节信息，也就是把倒数第几层的输出和最后的输出做一个 fusion，实际上也就是加和：

<center>

![](http://images.iterate.site/blog/image/20190722/xDp7OL0I30wh.png?imageslim){ width=95% }

</center>

实验表明，这样的分割结果更细致更准确。在逐层 fusion 的过程中，做到第三行再往下，结果又会变差，所以作者做到这里就停了。

<span style="color:red;">FCN-16s 是什么意思？最后的几个 prediction 是要怎么合并在一起？</span>

<span style="color:red;">为什么这个是有道理的？</span>

### 9.2.9 模型训练

1. 用 AlexNet，VGG16 或者 GoogleNet 训练好的模型做初始化，在这个基础上做 fine-tuning，全部都 fine-tuning，只需在末尾加上 upsampling，参数的学习还是利用 CNN 本身的反向传播原理。<span style="color:red;">这时候的 fine-tuning 那么最后的全连接层的权重是要加载到卷积里面去吗？怎么加 upsampling ？是直接加一个 upsampling 成原始图片的层吗？</span><span style="color:blue;">全连接的权重丢弃不用的。</span>
2. 采用 whole image 做训练，不进行 patchwise sampling。实验证明直接用全图已经很 effective and efficient。<span style="color:red;">什么是 patchwise sampling？</span>
3. 对 class score 的卷积层做全零初始化。随机初始化在性能和收敛上没有优势。<span style="color:red;">class score 的卷积层？全零初始化？什么意思？这个值得是全连接对应的卷积层吗？为什么随机初始化没有优势？</span><span style="color:blue;">全连接的权重丢弃不用的。</span>


举例：

FCN 例子: 输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为：20类目标+背景=21，模型基于 AlexNet。

- 蓝色：卷积层。
- 绿色：Max Pooling层。
- 黄色: 求和运算，使用逐数据相加，把三个不同深度的预测结果进行融合：较浅的结果更为精细，较深的结果更为鲁棒。<span style="color:red;">图中的 eltwise+ 是怎么计算的？</span>
- 灰色: 裁剪，在融合之前，使用裁剪层统一两者大小，最后裁剪成和输入相同尺寸输出。<span style="color:red;">怎么 crop 的？</span>

对于不同尺寸的输入图像，各层数据的尺寸（height，width）相应变化，深度（channel）不变。

<center>

![](http://images.iterate.site/blog/image/20190722/F8AbVFrJTM1B.png?imageslim){ width=85% }

</center>

（1）全卷积层部分进行特征提取，提取卷积层（3个蓝色层）的输出来作为预测 21 个类别的特征。

（2）图中虚线内是反卷积层的运算，反卷积层（3个橙色层）可以把输入数据尺寸放大。和卷积层一样，升采样的具体参数经过训练确定。

1) 以经典的 AlexNet 分类网络为初始化。最后两级是全连接（红色），参数弃去不用。<span style="color:red;">嗯，全连接的参数丢弃不用的。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/osltrE7SPEjx.png?imageslim){ width=65% }

</center>

2) 从特征小图（）预测分割小图（），之后直接升采样为大图。

<center>

![](http://images.iterate.site/blog/image/20190722/PGSENgYr5PSW.png?imageslim){ width=72% }

</center>


反卷积（橙色）的步长为 32，这个网络称为 FCN-32s

3) 升采样分为两次完成（橙色×2），在第二次升采样前，把第 4 个 pooling 层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。

<center>

![](http://images.iterate.site/blog/image/20190722/LDVCisRvnQQX.png?imageslim){ width=72% }

</center>


第二次反卷积步长为 16，这个网络称为 FCN-16s

4) 升采样分为三次完成（橙色×3），进一步融合了第 3 个 pooling 层的预测结果。

<center>

![](http://images.iterate.site/blog/image/20190722/p7fvs8E0gARk.png?imageslim){ width=72% }

</center>


第三次反卷积步长为 8，记为 FCN-8s


<span style="color:red;">嗯，想问下，按照这个步骤是分三次进行训练的吗？还是说是说的三个网络？</span>

其他参数:

- minibatch：20 张图片。
- learning rate：0.001。
- 初始化：分类网络之外的卷积层参数初始化为 0。<span style="color:red;">为什么不是随机值？</span>
- 反卷积参数初始化为 bilinear 插值。<span style="color:red;">什么是 bilinear 插值？怎么初始化为这个？为什么要初始化为这个？</span>
- 最后一层反卷积固定位 bilinear 插值不做学习。<span style="color:red;">为什么固定插值？什么叫不学习这部分？</span>

<center>

![](http://images.iterate.site/blog/image/20190722/51u8wnxvm3P6.png?imageslim){ width=55% }

</center>

<span style="color:red;">上面这个图说明什么？</span>

### 9.2.10 FCN 缺点

1. 得到的结果还是不够精细。进行 8 倍上采样虽然比 32 倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。<span style="color:red;">嗯，对细节还是不敏感。</span>
2. 对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。<span style="color:red;">为什么忽视了空间规整？为什么缺乏空间的一致性？</span>

# 相关

- [2019年最新基于深度学习的语义分割技术讲解](https://zhuanlan.zhihu.com/p/76418243)
