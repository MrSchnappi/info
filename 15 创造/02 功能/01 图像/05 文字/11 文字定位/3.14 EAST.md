---
title: 3.14 EAST
toc: true
date: 2019-09-15
---
# 可以补充进来的

- [论文阅读一文深入了解文本检测网络 EAST](https://zhuanlan.zhihu.com/p/72039321)

# EAST

EAST（Efficient and Accuracy Scene Text detection pipeline）模型中，首先使用全卷积网络（FCN）生成多尺度融合的特征图，然后在此基础上直接进行像素级的文本块预测。该模型中，支持旋转矩形框、任意四边形两种文本区域标注形式。对应于四边形标注，模型执行时会对特征图中每个像素预测其到四个顶点的坐标差值。对应于旋转矩形框标注，模型执行时会对特征图中每个像素预测其到矩形框四边的距离、以及矩形框的方向角。

根据开源工程中预训练模型的测试，该模型检测英文单词效果较好、检测中文长文本行效果欠佳。或许，根据中文数据特点进行针对性训练后，检测效果还有提升空间。

上述过程中，省略了其他模型中常见的区域建议、单词分割、子块合并等步骤，因此该模型的执行速度很快。

![mark](http://images.iterate.site/blog/image/20190729/E4w4O6i5Oumm.png?imageslim)（选自 arXiv: 1704.03155，’EAST: An Efficient and Accurate Scene Text Detector’）









![img](https://pic1.zhimg.com/80/v2-4b597f99a5225553baddd64e576be6c0_hd.jpg)





旷视科技在 CVPR 2017 收录论文《EAST:An Efﬁcient and Accurate Scene Text Detector》提出一种高度简化的 Pipeline 结构。如上图所示，最左侧是输入图像，最右侧是算法输出结果，中间则是处理步骤， EAST （最下面）把 Pipeline 精简为中间两步，其中一步是通过多通道 FCN 进行几何信息预测以及前景、背景预测；另外一步是 NMS，最终得到多方向文字检测结果。



![img](https://pic3.zhimg.com/80/v2-002c5ea5f8555feff3cb26713ab88626_hd.jpg)





那么如何实现 EAST 呢？很简单，通过单一网络刻画并建模位置、尺度、方向等文字的主要信息，同时加上多个损失函数，即所谓的多任务训练。如上所示，再借助对几何信息的预测即可得到文字检测的结果。



这种方法的好处主要体现在两个方面：1）精度方面，允许端到端的训练和优化，2）效率方面，剔除了中间冗余的处理步骤。



![img](https://pic4.zhimg.com/80/v2-82bb8dd5fdd32be595b74d0366fdf69b_hd.jpg)





上图是多种方法的应用对比，横轴是速度，纵轴是精度，红点是 EAST 的两个变体，可以看到其在精度和速度上都优于传统方法，且在精度和速度质检取得了极佳的平衡。EAST 已成为为行业标准方法，且代码开源，有趣的是，这是由热心网友 @argman 完成的（旷视贡献了部分代码）有兴趣的童鞋可以尝试；如果只想使用不想看源代码，目前 EAST 也作为官方模块，集成到最新版 OpenCV 之中。




# 相关

- [R Talk | 旷视科技姚聪博士：深度学习时代的文字检测与识别技术](https://zhuanlan.zhihu.com/p/51725259)
