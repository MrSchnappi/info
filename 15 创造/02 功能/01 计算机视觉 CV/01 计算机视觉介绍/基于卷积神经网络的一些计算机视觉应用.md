---
title: 基于卷积神经网络的一些计算机视觉应用
toc: true
date: 2018-08-30
---

## 基于卷积神经网络的计算机视觉应用

和计算机关联最紧密的深度学习技术是卷积神经网络。本节来列举一些卷积神经网络 发挥重要作用的计算机视觉的方向。

### 图像分类

顾名思义，图像分类就是对于输入的已知图像，由算法提取特征并最终分 到已知的一个类别里，或者说判断图像中是否包含一个已知类别中的物体，如图 1-9所示。

![](http://images.iterate.site/blog/image/180830/ecbm08F19m.png?imageslim){ width=55% }

前面花了不少篇幅讲述 ILSVRC 从 2010 年到 2016 年的风云变幻，而图像分类是深度 学习在计算机视觉领域大放异彩的第一个方向。不管是最开始的 MNIST，还是后来的 ImageNet，基于深度学习的图像分类在特定任务上早就超过了人的平均水平。

### 物体检测

物体检测和图像分类差不多，也是计算机视觉里最基础的两个方向。它和图像分类的侧重点不同，物体检测要稍微复杂一些，关心的是什么东西出现在了什么地方, 是一种更强的信息。如图 1-10中，经过物体检测，我们得到的信息不仅是照片中包含马和摄影师，还得到了每一样检测到的类别的位置信息，以方框的形式展现出来。


![](http://images.iterate.site/blog/image/180830/jLKhlBGjjI.png?imageslim){ width=55% }

和图像分类相比，物体检测传达的信息更强，例如要分类猫和狗的图片的问题，那么如果图像中既有猫又有狗该怎么分类呢？这时候如果还是坚持用分类则是一个多标签分类问题，或者就进一步用物体检测告诉我们猫在哪，狗在哪。在物体检测领域以基于 Region Proposal 的 R-CNN及后续的衍生算法，以及基于直接回归的 YOLO/SSD 一系的算法为代表。这两类算法都是基于卷积神经网络，借助的不仅仅是深度网络强大的图像特征提取和分类能力，也会用到神经网络的逼近能力。<span style="color:red;">R-CNN 和 YOLO/SSD 不是一个原理吗？基于 RegionProposal 和 基于直接回归的有什么区别？</span>

### 人脸识别

人脸识别是计算机视觉里非常悠久的一个方向，也是和人相关的研究最多 的一个计算机视觉子领域。和我们生活中最相关的应用一般有两个方面：

- 第一个是检测图像中是否存在人脸，这个应用和物体检测很像。主要应用有数码相机中对人脸的检测，网络或手机相册中对人脸的提取等；
- 第二个是人脸匹配，有了第一个方面或是其他手段把人脸部分找到后，人脸的匹配才是一个更主流的应用。主要的思想是把要比对的两个人脸之间的相似度计算出来。计算这种度量，传统的方法叫做度量学习(metric learning)。其基 本思想是通过变换，让变换后的空间中定义为相似的样本距离更近，不相似的样本距离更远。基于深度学习也有相应的方法，比较有代表性的是 Siamese 网络和 Triplet 网络，当然广义上来说都可以算是度量学习。有了这种度量，可以进一步判断是否是一个人。这就是身份辨识，广泛用于罪犯身份确认、银行卡开卡等场景中。2015年马云在德国的汉诺威信息技术博览会上“刷脸”的大新闻，背后就是这种技术。此外还可以利用相似度实现一些好玩的应用，如用自拍照找相似的明星脸等。<span style="color:red;">什么是 Siamese 网络和 Triplet 网络？之前好像没听说过。</span>

人脸领域最流行的测试基准数据是 LFW (Labeled Faces in the Wild)，顾名思义就是从实拍照片中标注的人脸。该图片库由美国麻省理工大学开发，约 13000 多张图片，其中有 1680 人的脸出现了两次或两次以上。在这个数据上，人类判断两张脸是否是同一人能达到的准确率为 99.2%。而在深度学习大行其道之后，自 2014 年起这个记录已经被各种基于深度学习的方法打破。虽然这未必真的代表深度学习胜过了人类，但基于深度学习的人脸算法让相关应用的可用性大大提高。如今人脸识别相关的商业应用已经遍地开花。

### 图像搜索

狭义来说图像搜索还有个比较学术的名字是基于内容的图片检索(Content Based Image Retrieval, CBIR)。图像搜索是个比较复杂的领域，除了单纯的图像算法，还带有搜索和海量数据处理的属性。其中图像部分背后的重要思想之一和人脸识别中提到 的度量学习很像，也是要找到和被搜图像的某种度量最近的图片。最常见的应用如 Google 的 Reverse Image Search 和百度的识图功能，京东和淘宝的拍照购物及相似款推荐等。深度学习在其中的作用主要是把图像转换为一种更适合搜索目的的表达，并且考虑到图像搜索应用场景和海量数据，这个表达常常会哈希/二值化处理，以达到更高的检索/排序效率。

### 图像分割

![](http://images.iterate.site/blog/image/180830/ckBegg9EDC.png?imageslim){ width=55% }

图像分割是个比较传统的视觉应用，指的是以像素为单位将图像划分为不同部分，这些部分代表着不同的感兴趣区域。如图 1-11所示的例子，画面中是山东威海的 一只受伤幼年红隼和背景。经过图像分割后，红隼在画面中所占的像素被标了出来，和背景有了区分。

传统的图像分割算法五花八门，如基于梯度和动态规划路径的 Intelligent Scissors (Photoshop中的磁力套索)；利用高一维空间的超曲面解决当前空间轮廓的水平集(Level Set)方法；直接聚类的 K-means；后期很流行的基于能量最小化的 GraphCut/GrabCut 和随机场的 CRF (Conditional Random Field)等。<span style="color:red;">竟然有这么多方法，都要好好整理下。</span>

后来深度学习出现了。和传统方法相比，深度学习未必能做到很精细的像素级分割。

但是因为深度学习能学到大量样本中的图像语义信息的天然优势，这更贴近人对图像的理解，所以分割的结果可用性通常也更好一些。常见的基于深度学习的图像分割手段是全卷积神经网络(Fully Convolutional Networks, FCN)。Facebook 的人工智能实验室 FAIR(Facebook Artificial Intelligence Research)于 2016 年发布了一套用于分割+物体检测的框 架。其构成是一个大体分割出物体区域的网络 DeepMask，加上利用浅层图像信息精细图像分割的 SharpMask，最后是一个 MultiPathNet 模块进行物体检测。其实在这背后也体现 出学界和业界开始慢慢流行起的另一个很底层的思想：就是图像分割和物体检测背后其实 是一回事，不应该分开来研究。对照物体检测和图像分类的关系，图像分割传达的是比物体检测更进一步、更强的信息。<span style="color:red;">嗯，之前对于图像分割还没有很重视，还没有把他单独列出来，现在看起来图像分割可以划分到物体检测里面</span>

### 视频识别

因为和图像的紧密联系，视频当然少不了深度学习的方法。深度学习在图像分类任务上大行其道之后，视频识别的研究立刻就跟进了上来，比较有代表性的工作从 2014 年起相继出现。<span style="color:red;">原来从 2014 年就开始了。</span>

2014年的 CVPR 上，斯坦福大学的 Fei-Fei Li组发表了一篇视频识别的论文。其基本思路是用视频中的多帧作为输入，再通过不同的顺序和方式将多帧信息进行融合。其方法并没什么特别出彩的地方，但随着论文发布了 Sport-1M数据集，包含了 Youtube 上 487 类 共计 113 万的体育视频，是目前最大的视频分类数据集。

2014年的 NIPS 上，牛津大学传统视觉强组 VGG (Visual Geometry Group)发表了一 篇更经典的视频识别的文章，将图像的空间信息，也就是画面信息，用一个称为 Spatial Stream ConvNet 的网络处理，而视频中帧之间的时序信息用另一个称为 Temporal Stream ConNet 的网络处理，最后融合称为 Two Streams，直译就是二流法。这个方法后来被改来改去，发展出了更深网络的双流法，以及更炫融合方式的双流法，甚至是除了双流还加入音频流的三流法。不过影响最大的改进还是马里兰大学和 Google 的一篇论文，其对时序信息进行了处理和改进，加入了本章提到过的 LSTM，以及改进版二流合并的方法，成为了主流框架之一。<span style="color:red;">这么厉害，想深入了解这个，而且，这个是用来做什么的，感觉真的是非常厉害。</span>

因为视频有时间的维度，所以还有一个很自然的想法是用三维卷积去处理视频帧，这样自然能将时序信息包括进来，这也是一个流行的思路。<span style="color:red;">这个思路现在有人在做吗？</span>

更近的一些研究中，最新的深度学习概率框架生成式对抗网络(Generative Adversarial Networks, GAN)也被用到了视频处理当中。2016年，Comma AI 的实习生 Eder Santana 和被称为天才黑客的 George Hotz 将 GAN 用于对视频输入进行降维，然后用低维表达和 LSTM 进行处理，从而对视频的未来帧进行预测，可以比较准确地预测沿直线前进时未来的画面。<span style="color:red;">怎么对视频输入进行降维的？感觉像是 GAN 的正规的用法，想什么了解下这个项目</span>

视频作为比图像更高一维度的数据，并且还带有时序信息和声音等信息，可探索的空间更大，相信未来会有更多精彩有趣的深度学习相关应用出现。<span style="color:red;">是呀，视频感觉直接与用摄像头和麦克风来捕捉现实社会的信息挂钩。</span>

### 纹理/图像合成

这是一个 2016 年左右才开始进入大众视野的领域，是因为一个叫 Prisma的 App。纹理合成其实也是计算机视觉的一个传统应用，主要实现的是根据一种图 案，进行相似的复制和排列生成纹理。如图 l-12a所示，根据左边照片中间部分的花朵图 案生成右边的图案。

在 2014 年前后，这个领域开始被深度学习大幅攻占。到了 2015 年， 纹理合成上的进展自然而然地拓展到了图片风格学习上。其中最有影响力的是德国的 Leon Gatys 发表的《A Neural Algorithm of Artistic Style》，其中提出的办法可以学习特定图片的 纹理风格并基于其他图片的内容生成风格化的图片。如图 l-12b 所示就是图片风格学习的 例子，左边的图片是拍摄于密云不老屯的射电望远镜和银河，通过深度网络给这张照片加 上了日本浮世绘名家葛饰北斋的作品《神奈川冲浪里》的风格。<span style="color:red;">嗯，风格迁移</span>


![](http://images.iterate.site/blog/image/180830/DgK1J1AHK4.png?imageslim){ width=55% }


其他应用除了上面提到的这些应用，传统图像和视觉领域里很多方向现在都有了基 于深度学习的解决方案，包括图像降噪、图像去模糊、图像复原、超分辨率、图像内容描述、图像深度（立体）信息提取等，在此就不详述了。<span style="color:red;">嗯，每个方向都要好好总结整理下。融汇贯通。</span>




# 相关

- 《深度学习与计算机视觉》
