---
title: 2.13 ZFNet
toc: true
date: 2019-09-03
---

## 4.3 ZFNet

### 4.3.1 模型介绍

ZFNet 是由 $Matthew$ $D. Zeiler$ 和 $Rob$ $Fergus$ 在 AlexNet 基础上提出的大型卷积网络，在 2013 年 ILSVRC 图像分类竞赛中以 11.19%的错误率获得冠军（实际上原 ZFNet 所在的队伍并不是真正的冠军，原 ZFNet以 13.51% 错误率排在第 8，真正的冠军是 $Clarifai$ 这个队伍，而 $Clarifai$ 这个队伍所对应的一家初创公司的 CEO 又是 $Zeiler$，而且 $Clarifai$ 对 ZFNet 的改动比较小，所以通常认为是 ZFNet 获得了冠军）$^{[3-4]}​$。ZFNet 实际上是微调（fine-tuning）了的 AlexNet，并通过反卷积（Deconvolution）的方式可视化各层的输出特征图，进一步解释了卷积操作在大型网络中效果显著的原因。

<span style="color:red;">特别想知道怎么通过反卷积来可视化各层的输出特征图的？</span>


### 4.3.2 模型结构

<center>

![](http://images.iterate.site/blog/image/20190722/DqLUUV2PsY5I.png?imageslim){ width=85% }

</center>


<center>

![](http://images.iterate.site/blog/image/20190722/QkIjXDWAAa8n.jpeg?imageslim){ width=85% }

</center>

> 图 4.4 ZFNet 网络结构图（原始结构图与 AlexNet 风格结构图）

​如图 4.4所示，ZFNet 与 AlexNet 类似，都是由 8 层网络组成的卷积神经网络，其中包含 5 层卷积层和 3 层全连接层。两个网络结构最大的不同在于，ZFNet 第一层卷积采用了 $7\times7\times3/2$ 的卷积核替代了 AlexNet 中第一层卷积核 $11\times11\times3/4$ 的卷积核。



<center>

![](http://images.iterate.site/blog/image/20190722/mBeCvIv9mcoi.png?imageslim){ width=65% }

</center>


<center>

![](http://images.iterate.site/blog/image/20190722/NPV7w5JbbCDc.png?imageslim){ width=85% }

</center>

> 图 4.5
>
> - （a）ZFNet 第一层输出的特征图
> - （b）AlexNet 第一层输出的特征图
> - （c）AlexNet 第二层输出的特征图
> - （d）ZFNet 第二层输出的特征图

图 4.5 中 ZFNet 相比于 AlexNet 在第一层输出的特征图中包含更多中间频率的信息，而 AlexNet 第一层输出的特征图大多是低频或高频的信息，对中间频率特征的缺失导致后续网络层次如图 4.5（c）能够学习到的特征不够细致，而导致这个问题的根本原因在于 AlexNet 在第一层中采用的卷积核和步长过大。<span style="color:red;">这个结论通过看图能够得到吗？不能吧？而且，卷积核和步长过大，那么怎么证明 $7\times7\times3/2$ 就是合适的？</span>


ZFNet网络参数配置：

|        网络层         |               输入尺寸               |                  核尺寸                  |               输出尺寸               |              可训练参数量               |
| :-------------------: | :----------------------------------: | :--------------------------------------: | :----------------------------------: | :-------------------------------------: |
|   卷积层 $C_1$ $^*$  |        $224\times224\times3$         |          $7\times7\times3/2,96$          |        $110\times110\times96$        |      $(7\times7\times3+1)\times96$      |
| 下采样层 $S_{max}$ |        $110\times110\times96$        |               $3\times3/2$               |         $55\times55\times96$         |                    0                    |
|      卷积层 $C_2$ $^*$      |         $55\times55\times96$         |         $5\times5\times96/2,256$         |        $26\times26\times256$        | $(5\times5\times96+1)\times256$ |
|   下采样层 $S_{max}$   | $26\times26\times256$ |       $3\times3/2$       | $13\times13\times256$ |                    0                    |
|   卷积层 $C_3$  |  $13\times13\times256$  | $3\times3\times256/1,384$ | $13\times13\times384$ | $(3\times3\times256+1)\times384$ |
|      卷积层 $C_4$      | $13\times13\times384$ | $3\times3\times384/1,384$ | $13\times13\times384$ | $(3\times3\times384+1)\times384$ |
|      卷积层 $C_5$      | $13\times13\times384$ | $3\times3\times384/1,256$ | $13\times13\times256$ | $(3\times3\times384+1)\times256$ |
|   下采样层 $S_{max}$   | $13\times13\times256$ |       $3\times3/2$       |  $6\times6\times256$  |                    0                    |
|  全连接层 $F_6$  |   $6\times6\times256$   |     $9216\times4096$     | $1\times1\times4096$ |       $(9216+1)\times4096$       |
|     全连接层 $F_7$     |  $1\times1\times4096$  |     $4096\times4096$     | $1\times1\times4096$ |       $(4096+1)\times4096$       |
|     全连接层 $F_8$     | $1\times1\times4096$ |             $4096\times1000$             |         $1\times1\times1000$         |       $(4096+1)\times1000$       |


> 卷积层 $C_1$ 与 AlexNet 中的 $C_1$ 有所不同，采用 $7\times7\times3/2$ 的卷积核代替 $11\times11\times3/4​$，使第一层卷积输出的结果可以包含更多的中频率特征，对后续网络层中多样化的特征组合提供更多选择，有利于捕捉更细致的特征。<span style="color:red;">这个也不能够说明 $7\times7\times3/2$ 是最合适的吧？</span>
>
> 卷积层 $C_2$ 采用了步长 $2$ 的卷积核，区别于 AlexNet 中 $C_2$ 的卷积核步长，所以输出的维度有所差异。

### 4.3.3 模型特性

​ZFNet 与 AlexNet 在结构上几乎相同，此部分虽属于模型特性，但准确地说应该是 ZFNet 原论文中可视化技术的贡献。

<span style="color:red;">非常想知道是怎么进行的可视化操作。</span>

- 可视化技术揭露了激发模型中每层单独的特征图。<span style="color:red;">是呀。</span>
- 可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。
- 可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。
- 可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。
- 可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。
- 可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。







# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
