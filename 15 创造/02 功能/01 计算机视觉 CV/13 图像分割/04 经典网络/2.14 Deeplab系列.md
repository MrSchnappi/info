---
title: 2.14 Deeplab系列
toc: true
date: 2019-09-01
---

**4.Deeplab系列**

**主要有模型 Deeplabv1,Deeplabv2,Deeplabv3,Deeplabv3+。**

将 CNN 编码器-解码器和 CRF 精炼过程相结合以产生目标标签（作者强调了解码器的上采样）。空洞卷积（也称扩张卷积）在每一层都使用大小不同的卷积核，使每一层都能捕获各种比例的特征。

V3+使用深度分离卷积替代了 pooling，并且使用了 Xception，Xception的核心是使用了 Depthwise separable convolution。Depthwise separable convolution的思想来自 inception 结构，是 inception 结构的一种极限情况。Inception 首先给出了一种假设：卷积层通道间的相关性和空间相关性是可以退耦合的，将它们分开映射，能达到更好的效果。在 inception 结构中，先对输入进行 1*1的卷积，之后将通道分组，分别使用不同的 3*3卷积提取特征，最后将各组结果串联在一起作为输出。

![img](https://pic3.zhimg.com/80/v2-fc73c7f8b0e1fa8dbb8f1708cd534896_hd.jpg)

主要贡献：

- 为密集预测任务使用具有上采样的卷积
- 在多尺度上为分割对象进行带洞空间金字塔池化（ASPP）
- 通过使用 DCNNs 提升了目标边界的定位

解决了语义分割的主要挑战，包括：

- 由重复的最大池化和下采样导致的特征分辨率降低
- 检测多尺度目标
- 因为以目标为中心的分类器需要对空间变换具有不变性，因而降低了由 DCNN 的不变性导致的定位准确率。





## 9.8 DeepLab 系列

### 9.8.1 DeepLabv1


DeepLab 是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。<span style="color:red;">什么是概率图模型 DenseCRFs？</span>

在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是 DCNNs 的高级特征的平移不变性，即高层次特征映射，根源于重复的池化和下采样。<span style="color:red;">是的，这种池化和下采样丢失了太多信息了。</span>

针对信号下采样或池化降低分辨率，DeepLab 是采用的 atrous（带孔）算法扩展感受野，获取更多的上下文信息。<span style="color:red;">嗯，又一个新的东西，之前是 pooling ，后来是 dilated conv 现在是 atros。看看。</span>

分类器获取以对象中心的决策是需要空间变换的不变性，<span style="color:red;">为什么需要空间变换的不变性？</span>这天然地限制了 DCNN 的定位精度，DeepLab 采用完全连接的条件随机场（CRF）提高模型捕获细节的能力。

除空洞卷积和 CRFs 之外，论文使用的 tricks 还有 Multi-Scale features。其实就是 U-Net 和 FPN 的思想，在输入图像和前四个最大池化层的输出上附加了两层的 MLP，第一层是 128 个 3×3 卷积，第二层是 128 个 1×1 卷积。最终输出的特征与主干网的最后一层特征图融合，特征图增加 5×128=640 个通道。

实验表示多尺度有助于提升预测结果，但是效果不如 CRF 明显。<span style="color:red;">再补充些。</span>

论文模型基于 VGG16，在 Titan GPU 上运行速度达到了 8FPS，全连接 CRF 平均推断需要 0.5s ，在 PASCAL VOC-2012 达到 71.6% IOU accuracy。<span style="color:red;">厉害。</span>

### 9.8.2 DeepLabv2


DeepLabv2 是相对于 DeepLabv1 基础上的优化。DeepLabv1 在三个方向努力解决，但是问题依然存在：

- 特征分辨率的降低
- 物体存在多尺度
- DCNN 的平移不变性。

因 DCNN 连续池化和下采样造成分辨率降低，DeepLabv2 在最后几个最大池化层中去除下采样，取而代之的是使用空洞卷积，以更高的采样密度计算特征映射。

物体存在多尺度的问题，DeepLabv1 中是用多个 MLP 结合多尺度特征解决，虽然可以提供系统的性能，但是增加特征计算量和存储空间。

论文受到 Spatial Pyramid Pooling (SPP) 的启发，提出了一个类似的结构，在给定的输入上以不同采样率的空洞卷积并行采样，相当于以多个比例捕捉图像的上下文，称为 ASPP (atrous spatial pyramid pooling) 模块。<span style="color:red;">什么是 ASPP？SPP 也补充下。</span>

DCNN 的分类不变形影响空间精度。DeepLabv2 是采用全连接的 CRF 在增强模型捕捉细节的能力。

论文模型基于 ResNet，在 NVidia Titan X GPU 上运行速度达到了 8FPS，全连接 CRF 平均推断需要 0.5s ，在耗时方面和 DeepLabv1 无差异，但在 PASCAL VOC-2012 达到 79.7 mIOU。

<span style="color:red;">厉害。</span>

### 9.8.3 DeepLabv3


好的论文不止说明怎么做，还告诉为什么。DeepLab 延续到 DeepLabv3 系列，依然是在空洞卷积做文章，但是探讨不同结构的方向。

DeepLabv3 论文比较了多种捕获多尺度信息的方式：

<center>

![](http://images.iterate.site/blog/image/20190722/QtHkymYOBj8t.png?imageslim){ width=90% }

</center>


1. Image Pyramid：将输入图片放缩成不同比例，分别应用在 DCNN 上，将预测结果融合得到最终输出。
2. Encoder-Decoder：利用 Encoder 阶段的多尺度特征，运用到 Decoder 阶段上恢复空间分辨率，代表工作有 FCN、SegNet、PSPNet 等工。<span style="color:red;">嗯，是的。</span>
3. Deeper w. Atrous Convolution：在原始模型的顶端增加额外的模块，例如 DenseCRF，捕捉像素间长距离信息。<span style="color:red;">这个没明白。</span>
4. Spatial Pyramid Pooling：空间金字塔池化具有不同采样率和多种视野的卷积核，能够以多尺度捕捉对象。<span style="color:red;">嗯。</span>

DeepLabv1-v2 都是使用带孔卷积提取密集特征来进行语义分割。但是为了解决分割对象的多尺度问题，DeepLabv3 设计采用多比例的带孔卷积级联或并行来捕获多尺度背景。<span style="color:red;">什么是多比例的带孔卷积级联？</span>

此外，DeepLabv3 将修改之前提出的带孔空间金字塔池化模块，该模块用于探索多尺度卷积特征，将全局背景基于图像层次进行编码获得特征，取得 state-of-art 性能，在 PASCAL VOC-2012 达到 86.9 mIOU。

<span style="color:red;">这么厉害！</span>

### 9.8.4 DeepLabv3+


语义分割关注的问题:

1. 实例对象多尺度问题。
2. 因为深度网络存在 stride=2的层，会导致 feature 分辨率下降，从而导致预测精度降低，而造成的边界信息丢失问题。

deeplab V3 新设计的 aspp 结构解决了问题 1，deeplab v3+主要目的在于解决问题 2。

问题 2 可以使用空洞卷积替代更多的 pooling 层来获取分辨率更高的 feature。但是 feature 分辨率更高会极大增加运算量。以 deeplab v3使用的 resnet101 为例，stride=16 将造成后面 9 层 feature 变大，后面 9 层的计算量变为原来的 2*2=4倍大。stride=8 则更为恐怖，后面 78 层的计算量都会变大很多。<span style="color:red;">是呀。</span>

解决方案：

1. 编解码器结构
2. Modified Aligned Xception

<center>

![](http://images.iterate.site/blog/image/20190722/zFakwYoXypxN.png?imageslim){ width=95% }

</center>



在 deeplabv3 基础上加入解码器：

- A 是 aspp 结构，其中 $8\times$  的上采样可以看做是一个解码器。
- B 是编解码结构，它集合了高层和底层的特征。
- C 就是本文采取的结构。

<span style="color:red;">是的，ab 之前都已经讲过了。</span>

OK，我们讲下 DeepLabv3+ 的方法：

（1）Encoder-Decoder with Atrous Convolution

<center>

![](http://images.iterate.site/blog/image/20190722/1xcxhwcFwXMu.png?imageslim){ width=95% }

</center>


- 编码器采用 deeplabv3。
- 解码器部分：
  1. 先从低层级选一个 feature，将低层级的 feature 用 $1 * 1$ 的卷积进行通道压缩（原本为 256 通道，或者 512 通道），目的在于减少低层级的比重。作者认为编码器得到的 feature 具有更丰富的信息，所以编码器的 feature 应该有更高的比重。 这样做有利于训练。<span style="color:red;">嗯。</span>
  2. 再将编码器的输出上采样，使其分辨率与低层级 feature 一致。举个例子，如果采用 resnet conv2 输出的 feature，则这里要 $* 4$ 上采样。将两种 feature 连接后，再进行一次 $3 * 3$ 的卷积（细化作用），<span style="color:red;">为什么要进行细化？</span>然后再次上采样就得到了像素级的预测。后面的实验结果表明这种结构在 stride=16 时既有很高的精度速度又很快。stride=8 相对来说只获得了一点点精度的提升，但增加了很多的计算量。<span style="color:red;">嗯。</span>

（2）Modified Aligned Xception

Xception 主要采用了 deepwish seperable convolution 来替换原来的卷积层。简单的说就是这种结构能在更少参数更少计算量的情况下学到同样的信息。<span style="color:red;">怎么知道能学到相同的信息的？ deepwish seperable convolution 是什么？</span>

这边则是考虑将原来的 resnet-101 骨架网换成 xception。<span style="color:red;">是替换卷积层吗？</span>

<center>

![](http://images.iterate.site/blog/image/20190722/dtSa01mQxgFz.png?imageslim){ width=85% }

</center>

> 更改后的 resnet-101 。**红色部分为修改**，而且，更多层了：重复 8 次改为 16 次（基于 MSRA 目标检测的工作）。

<span style="color:red;">那么这个是要重新训练吗？还是可以使用之前的权重？</span>

<span style="color:red;">为什么还保留了一部分的 Conv？为什么不完全替换？</span>

可见，将原来简单的 pool 层改成了 stride 为 2 的 deepwish seperable convolution。

额外的 RELU 层和归一化操作添加在每个 3 × 3 depthwise convolution之后（原来只在 1 * 1卷积之后）<span style="color:red;">嗯。</span>

<span style="color:red;">要总结下 depthwise convolution 。</span>



# 相关

- [2019年最新基于深度学习的语义分割技术讲解](https://zhuanlan.zhihu.com/p/76418243)
