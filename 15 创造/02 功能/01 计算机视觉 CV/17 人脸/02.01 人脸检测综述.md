---
title: 02.01 人脸检测综述
toc: true
date: 2019-09-15
---

# 人脸检测综述







人脸检测的目标是找出图像中所有的人脸对应的位置，算法的输出是人脸外接矩形在图像中的坐标，可能还包括姿态如倾斜角度等信息。下面是一张图像的人脸检测结果：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SVbU64rG7O8GvsjObB4hDK01ZM6ObrBI41tiaavmsoaicjW1NVC3Ez7wA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

虽然人脸的结构是确定的，由眉毛、眼睛、鼻子和嘴等部位组成，近似是一个刚体，但由于姿态和表情的变化，不同人的外观差异，光照，遮挡的影响，准确的检测处于各种条件下的人脸是一件相对困难的事情。



人脸检测算法要解决以下几个核心问题：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

 人脸可能出现在图像中的任何一个位置

 人脸可能有不同的大小

 人脸在图像中可能有不同的视角和姿态

 人脸可能部分被遮挡

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)



评价一个人脸检测算法好坏的指标是检测率和误报率。我们将检测率定义为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

误报率定义为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

算法要在检测率和误报率之间做平衡，理想的情况是有高检测率，低误报率。



经典的人脸检测算法流程是这样的：用大量的人脸和非人脸样本图像进行训练，得到一个解决 2 类分类问题的分类器，也称为人脸检测模板。这个分类器接受固定大小的输入图片，判断这个输入图片是否为人脸，即解决是和否的问题。人脸二分类器的原理如下图所示：

![img](https://mmbiz.qpic.cn/mmbiz_jpg/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SZo18EUwht5MEhW0lbl8Vs6icLPExAJTdhuQT98NUKxEg01CyfIFKLFw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

由于人脸可能出现在图像的任何位置，在检测时用固定大小的窗口对图像从上到下、从左到右扫描，判断窗口里的子图像是否为人脸，这称为滑动窗口技术（sliding window）。为了检测不同大小的人脸，还需要对图像进行放大或者缩小构造图像金字塔，对每张缩放后的图像都用上面的方法进行扫描。由于采用了滑动窗口扫描技术，并且要对图像进行反复缩放然后扫描，因此整个检测过程会非常耗时。



由于一个人脸附件可能会检测出多个候选位置框，还需要将检测结果进行合并去重，这称为非极大值抑制（NMS）。多尺度滑动窗口技术的原理如下图所示：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Skk6qsfbWdDVLYddpj7DMCsqEPVah4J4cWXf7Gc8Xbse9u4kZN141Qg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

以 512x512 大小的图像为例，假设分类器窗口为 24x24，滑动窗口的步长为 1，则总共需要扫描的窗口数为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

即要检测一张图片需要扫描大于 120 万个窗口！！！计算量惊人，因此有必要采取某种措施提高效率，具体解决方案本文会给出。



典型应用







人脸检测是机器视觉领域被深入研究的经典问题，在安防监控、人证比对、人机交互、社交等领域都有重要的应用价值。数码相机、智能手机等端上的设备已经大量使用人脸检测技术实现成像时对人脸的对焦、图集整理分类等功能，各种虚拟美颜相机也需要人脸检测技术定位人脸，然后才能根据人脸对齐的技术确定人脸皮肤、五官的范围然后进行美颜。在[人脸识别的流程中](http://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247483726&idx=1&sn=9fef4cc1766ea4258749f8d40cc71a6e&chksm=fdb69cd9cac115cf4eba16081780c3b64c75e1e55a40bf2782783d5c28f00c6f143426e6f0aa&scene=21#wechat_redirect)，人脸检测是整个人脸识别算法的第一步。



早期算法







我们将整个人脸检测算法分为 3 个阶段，分别是早期算法，AdaBoost框架，以及深度学习时代，在接下来将分这几部分进行介绍。



早期的人脸检测算法使用了模板匹配技术，即用一个人脸模板图像与被检测图像中的各个位置进行匹配，确定这个位置处是否有人脸；此后机器学习算法被用于该问题，包括神经网络，支持向量机等。以上都是针对图像中某个区域进行人脸-非人脸二分类的判别。



早期有代表性的成果是 Rowley 等人提出的方法[1][2]。他们用神经网络进行人脸检测，用 20x20 的人脸和非人脸图像训练了一个多层感知器模型。文献[1]的方法用于解决近似正面的人脸检测问题，原理如下图所示：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

文献[2]的方法解决多角度人脸检测问题，整个系统由两个神经网络构成，第一个网络用于估计人脸的角度，第二个用于判断是否为人脸。角度估计器输出一个旋转角度，然后用整个角度对检测窗进行旋转，然后用第二个网络对旋转后的图像进行判断，确定是否为人脸。系统结构如下图所示：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

Rowley的方法有不错的精度，由于分类器的设计相对复杂而且采用的是密集滑动窗口进行采样分类导致其速度太慢。



AdaBoost框架







接下来介绍 AdaBoost 框架之后的方法，boost算法是基于 PAC 学习理论（probably approximately correct）而建立的一套集成学习算法(ensemble learning)。其根本思想在于通过多个简单的弱分类器，构建出准确率很高的强分类器，PAC学习理论证实了这一方法的可行性，感谢大神 Leslie-Valiant！！我们首先来看 FDDB 上各种检测算法的 ROC 曲线，接下来的介绍将按照这些 ROC 曲线上的算法进行展开。



![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

在 2001 年 Viola 和 Jones 设计了一种人脸检测算法[10]。它使用简单的 Haar-like特征和级联的 AdaBoost 分类器构造检测器，检测速度较之前的方法有 2 个数量级的提高，并且保持了很好的精度，我们称这种方法为 VJ 框架。VJ框架是人脸检测历史上第一个最具有里程碑意义的一个成果，奠定了基于 AdaBoost 目标检测框架的基础，所以作为重点和大家唠唠。



用级联 AdaBoost 分类器进行目标检测的思想是：用多个 AdaBoost 分类器合作完成对候选框的分类，这些分类器组成一个流水线，对滑动窗口中的候选框图像进行判定，确定它是人脸还是非人脸。



在这一系列 AdaBoost 分类器中，前面的强分类器设计很简单，包含的弱分类器很少，可以快速排除掉大量的不是人脸的窗口，但也可能会把一些不是人脸的图像判定为人脸。如果一个候选框通过了第一级分类器的筛选即被判定为人脸，则送入下一级分类器中进行判定，以此类推。如果一个待检测窗口通过了所有的强分类器，则认为是人脸，否则是非人脸。下图是分类器级联进行判断的示意图：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

这种思想的精髓在于用简单的强分类器在初期快速排除掉大量的非人脸窗口，同时保证高的召回率，使得最终能通过所有级强分类器的样本数很少。这样做的依据是在待检测图像中，绝大部分都不是人脸而是背景，即人脸是一个稀疏事件，如果能快速的把非人脸样本排除掉，则能大大提高目标检测的效率。



出于性能考虑，弱分类器使用了简单的 Haar-like特征，这种特征源自于小波分析中的 Haar 小波变换，Haar小波是最简单的小波函数，用于对信号进行均值、细节分解。这里的 Haar-like特征定义为图像中相邻矩形区域像素之和的差值。下图是基本 Haar-like特征的示意图：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

Haar-like特征是白色矩形框内的像素值之和，减去黑色区域内的像素值之和。以图像中第一个特征为例，它的计算方法如下：首先计算左边白色矩形区域里所有像素值的和，接下来计算右边黑色矩形区域内所有像素的和，最后得到的 Haar-like特征值为左边的和减右边的和。



这种特征捕捉图像的边缘、变化等信息，各种特征描述在各个方向上的图像变化信息。人脸的五官有各自的亮度信息，很符合 Haar-like特征的特点。



为了实现快速计算，使用了一种称为积分图（Integral Image）的机制。通过积分图可以快速计算出图像中任何一个矩形区域的像素之和，从而计算出各种类型的 Haar-like特征。假设有一张图像，其第 i 行第 j 列处的像素值为![x_{ij}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)，积分图定义为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

即原始图像在任何一点处的左上角元素之和。在构造出积分图之后，借助于它可以快速计算出任何一个矩形区域内的像素之和，以下图中的矩形框为例：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

在上图中，要计算黑色矩形框内的像素值之和。假设上面四个矩形的右下角的坐标分别为

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

黑色色矩形框内的像素值之和为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

之所以这样，是因为黑色区域内的像素值之和等于这 4 个矩形框内的像素值之和，减去上面两个矩形框的像素值之和，再减去左边两个矩形框的像素值之和，这样做的话，左上角的矩形框被减了两遍，因此要加一遍回来。在计算出任何一个矩形区域的像素值之和后，可以方便的计算出上面任何一种 Haar-like特征。下图是通过 AdaBoost 算法自动筛选出来的对区分人脸和非人脸有用的 Haar-like特征，基本符合人类的直观感受：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

弱分类器采用最简单的深度很小的决策树，甚至只有一个内部节点。决策树的训练算法此处不做详细的阐述，需要注意的是这里的特征向量是稀疏的，即每一棵决策树只接受少量特征分量的输入，根据它们来做决策。



强分类器和前面讲述的是一样的，不同的是这里的强分类器加上了一个调节阈值：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

其中![\xi](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)为阈值，它通过训练得到。每一级强分类器在训练时使用所有的人脸样本作为正样本，并用上一级强分类器对负样本图像进行扫描，把找到的虚警中被判定为人脸的区域截取出来作为下一级强分类器的负样本。



假设第 i 级强分类器的检测率和误报率分别为![d_{i}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)和![f_{i}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)，由于要通过了所有强分类器才被判定为正样本，因此级联分类器的误报率为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

上式表明增加分类器的级数可以降低误报率，类似的级联分类器的检测率为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

这个式子表明增加分类器的级数会降低检测率。对于前者，可以理解为一个负样本被每一级分类器都判定为正样本的概率；对于后者，可以理解为一个正样本被所有分类器都判定为正样本的概率。



在 VJ 算法问世之后，较好的解决了近似正面人脸的检测问题。此后出现了大量改进方案，在深度学习技术出现之前，一直是人脸检测算法的主流框架。这些方案的改进主要在以下几个方面：



新的特征，包括扩展的 Haar 特征[4]，ACF特征[15]等，它们比标准的 Haar-like特征有更强的描述能力，同时计算成本也很低。



使用其他类型的 AdaBoost 分类器。VJ框架中采用的是离散型的 AdaBoost 算法，除此之外，还有实数型，Logit型，Gentle型等各种方案。实数型、Logit型和 Gentle 型 AdaBoost 算法不仅能输出分类标签值，还能给出置信度，有更高的精度。



分类器级联结构，如 Soft Cascade，将 VJ 方法的多个强分类器改成一个强分类器（该算法后面会有介绍）。另外，检测处于各种角度和姿态的人脸是研究另一个重点，VJ方法的分类器级联只有一条路径，是瀑布模型，改进的方案有树状级联，金字塔级联等，篇幅所限这里不做过多解释，各种级联方案如下图所示：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

在深度学习出现以前工业界的方案都是基于 VJ 算法。但 VJ 算法仍存在一些问题：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

（1) Haar-like特征是一种相对简单的特征，其稳定性较低；



（2)弱分类器采用简单的决策树，容易过拟合。因此，该算法对于解决正面的 人脸效果好，对于人脸的遮挡，姿态，表情等特殊且复杂的情况，处理效果不理想（虽然有了一些改进方案，但还是不够彻底！！）。



（3）基于 VJ-cascade的分类器设计，进入下一个 stage 后，之前的信息都丢弃了，分类器评价一个样本不会基于它在之前 stage 的表现----这样的分类器鲁棒性差。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)



ACF[15]（Aggregate Channel Features for Multi-view Face Detection）是一种为分类提供足够多的特征选择的方法。在对原图进行处理后，得到多通道的图像，这些通道可以是 RGB 的通道，可以是平滑滤波得到的，可以是 x 方向 y 方向的梯度图等等。将这些通道合起来，在此基础上提取特征向量后续采用 Soft-Cascade分类器进行分类。



相较于 VJ-cascade的设计，Soft-Cascade采用几个改进的方案：



![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SjEyYn9FNU9u48WHTfRKiblbgZo6aUb9miawIbdjIVXNNlRUicaQT09VIQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

（1）每个 stage 的决策函数不是二值而是标量值(scalar-valued) ，且与该样本有多"容易"通过这个 stage 以及在这个 stage 的相对重要性成比例。



（2）生成的决策函数是需要通过之前每个阶段的值而不单单是本阶段来判定。



（3）文中把检测器的运行时间-准确率权衡通过一个叫 ROC surface的 3 维曲面清楚的展示出来，方便调节参数，可以明确的知道动了哪个参数会对这个检测器的性能会有些什么影响。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Sj8mCBYZBLgxxE5RFl5Nc2LCOhJebjicnHk5uSr31ic5LibsNCSiaJ8RQmA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SGtm7hMq0eibQa4icicibfSg9LAwBdoNK5VEfkOg2fKibpOrU36MppFzpMhg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



DMP模型







DPM（Deformable Part Model），正如其名称所述，可变形的组件模型，是一种基于组件的检测算法，其所见即其意。该模型由 Felzenszwalb 在 2008 年提出，并发表了一系列的 CVPR，NIPS会议。并且还拿下了 2010 年，PASCAL VOC的“终身成就奖”。



由于 DPM 算法[16]本身是一种基于组件的检测算法，所以对扭曲，性别，多姿态，多角度等的人脸都具有非常好的检测效果（人脸通常不会有大的形变，可以近似为刚体，基于 DMP 的方法可以很好地处理人脸检测问题）。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

DPM的方法采用的是 FHOG 进行特征的提取，作者对 HOG 进行了很大的改动，没有直接采用 4*9=36维向量，而是对每个 8x8 的 cell 提取 18+9+4=31维特征向量。作者还讨论了依据 PCA（Principle Component Analysis）可视化的结果选 9+4维特征，能达到 HOG 4*9维特征的效果。基于 DPM 的方法在户外人脸集上都取得了比 Viola-Jones更好的效果，但是由于该模型过于复杂，判断时计算复杂，很难满足实时性的要求。后续有了一些列改进的流程，比如加入级联分类器，针对特征计算采用了积分图的方法等，但都还没有达到 VJ 方法的效率。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

DPM模型一个大的问题是速度太慢，因此在工程中很少使用，一般采用的是 AdaBoost 框架的算法。



基于经典的人工设计特征本身稳定性并不稳定，容易受外界环境的影响（光照、角度、遮挡等），所以在复杂场景下的人脸检测性能很难的到保证，只能应用到受限的场景中。深度学习出现以后，DCNN（深度卷积神经网络）能很好的学习到图像中目标物各个层级的特征，对外界的抗干扰能力更强，后序的人脸检测方法基本都基于 DCNN 的特征来优化了。



基于深度学习的方法在 FDDB 上基本饱和了，是时候抛出一个新的 benchmark 了！！！WIDERFace测试集上各种算法的性能：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)



深度学习框架







卷积神经网络在图像分类问题上取得成功之后很快被用于人脸检测问题，在精度上大幅度超越之前的 AdaBoost 框架，当前已经有一些高精度、高效的算法。直接用滑动窗口加卷积网络对窗口图像进行分类的方案计算量太大很难达到实时，使用卷积网络进行人脸检测的方法采用各种手段解决或者避免这个问题。



Cascade CNN

Cascade CNN[17]可以认为是传统技术和深度网络相结合的一个代表，和 VJ 人脸检测器一样，其包含了多个分类器，这些分类器采用级联结构进行组织，然而不同的地方在于，Cascade CNN采用卷积网络作为每一级的分类器。



构建多尺度的人脸图像金字塔，12-net将密集的扫描这整幅图像（不同的尺寸），快速的剔除掉超过 90%的检测窗口，剩下来的检测窗口送入 12-calibration-net调整它的尺寸和位置，让它更接近潜在的人脸图像的附近。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)



采用非极大值抑制（NMS）合并高度重叠的检测窗口，保留下来的候选检测窗口将会被归一化到 24x24 作为 24-net的输入，这将进一步剔除掉剩下来的将近 90%的检测窗口。和之前的过程一样，通过 24-calibration-net矫正检测窗口，并应用 NMS 进一步合并减少检测窗口的数量。



将通过之前所有层级的检测窗口对应的图像区域归一化到 48x48 送入 48-net进行分类得到进一步过滤的人脸候选窗口。然后利用 NMS 进行窗口合并，送入 48-calibration-net矫正检测窗口作为最后的输出。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

12x12，24x24，48x48尺寸作为输入的分类 CNN 网络结构，其中输出为 2 类-人脸和非人脸。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SdwRgO1GwRvn3JUib76urKzk4FgAstEl99D6PAZIGAf3JO0AdfSzOXrA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

12x12，24x24，48x48尺寸作为输入的矫正（calibration）CNN网络结构。其中输出为 45 中种矫正模式的类别。



文中影响区域位置和大小的因素有三种：尺度、X方向偏移、Y方向偏移。总共构成了 5x3x3=45种模式。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SsI5QiaNpribXC856DMtwAibybmeancJJu4Dod9ibrdIesjPlJpk7vwM57w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上一级检测网络输出的人脸位置（x,y,w,h）通过以下公式进行校正：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SJAlDkqsbwqIx93rOgfxWx6aLFOp7HMTGGLjzDic0Roj1mBX1KGKial2Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

校正网络的结构如下图所示：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SnQoicNjP8XV9rZsh9dLhbBTcpbNXvsny7uXnca1ia8zzxpbpicPKBPlNg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Cascade CNN一定程度上解决了传统方法在开放场景中对光照、角度等敏感的问题，但是该框架的第一级还是基于密集滑动窗口的方式进行窗口过滤，在高分辨率存在大量小人脸（tiny face）的图片上限制了算法的性能上限。



DenseBox

文献[18]提出了一种称为 DenseBox 的目标检测算法，适合人脸这类小目标的检测。这种方法使用全卷积网络，在同一个网络中直接预测目标矩形框和目标类别置信度。通过在检测的同时进行关键点定位，进一步提高了检测精度。



检测时的流程如下：

1.对待检测图像进行缩放，将各种尺度的图像送入卷积网络中处理，以检测不同大小的目标。

2.经过多次卷积和池化操作之后，对特征图像进行上采样然后再进行卷积，得到最终的输出图像，这张图像包含了每个位置出现目标的概率，以及目标的位置、大小信息。

3.由输出图像得到目标矩形框。

4.非最大抑制，得到最终的检测结果。

在检测时卷积网络接受![m \times n](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S9T5tau0qyfiaHhFGHf2vYrT7zsBLbu5VJUa67OVc9mgZBDXbDw7fY3w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)的输入图像，产生 5 个通道的![m / 4 \times n / 4](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SQ9X8v1dbMHmToJVGymyExWxCicYvEoZricr1TBGpObLSdVrWPLjgfaeg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)输出图像。假设目标矩形左上角![p_{t}](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S2YP9mpV4HQzrFYo0HiaibQxMzrVwvo7n2sXH8g70DDEyh1tBmGNE4MwQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)的坐标为![(x_{t}, y_{t})](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SWTLuLaqiaoYD0BzgDxWSNxRYicRNXFeDM3iav2RZIBQ6Ciah8IedF2DiciaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)，右下角![p_{b}](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SGlMUToEiaBIZeopBM2KspUeYaLibePicE4XPPewiafQRmhIZWXQ0ROXdnw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)的坐标为![(x_{b}, y_{b})](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SGHtuicNfKnXkFiaJjfK3nKnqn83tFbSh7tD7WGSNib1G8eFOtmh3VESdQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)。输出图像中位于点![(x_{i}, y_{i})](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SA9V8MicWVAefaRFgK0ao2xJnWaAvT3smaL9wAIWEiabjeoKWEWn073Ng/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)处的像素用 5 维向量描述了一个目标的矩形框和置信度信息：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5St94b2erQlK1zy1kuZOVTNDdbkCmzNh3DDsDpzUTMafyOa3Nic82fSVA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

第一个分量是候选框是一个目标的置信度，后面 4 项分别为本像素的位置与矩形框左上角、右下角的距离。每个像素都转化成一个矩形框和置信度值，然后对置信度值大于指定阈值的矩形框进行非最大抑制，得到最终检测结果。



backbone从 VGG 19网络改进得到，包含 16 个卷积层。前 12 个卷积层用 VGG 19的模型进行初始化。卷积层 conv4_4的的输出被送入 4 个 的卷积层中。第一组的两个卷积层产生 1 通道的输出图像作为置信度得分；第二组的两个卷积层产生 4 通道的输出图像作为矩形框的 4 个坐标。网络的输出有两个并列的分支，分别表示置信度和矩形框位置预测值。整个网络的结构如下图所示：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

DenseBox的网络结构



为了提高检测精度，采用了多尺度融合的策略。将 conv3_4和 conv_4_4的卷积结果拼接起来送入后面处理。由于两个层的输出图像大小不同，在这里用了上采样和线性插值对小的图像进行放大，将两种图像尺寸变为相等。



由于输出层有两个并列分支，损失函数由两部分组成。第一部分输出值为分类置信度即本位置是一个目标的概率，用![\hat{y}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)表示。真实的类别标签值为![y^{*}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)，取值为 0 或者 1，分别表示是背景和目标。分类损失函数定义为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

损失函数的第二部分是矩形框预测误差，假设预测值为![\hat{d}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)，真实值为![d^{*}](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)，它们的 4 个分量均为当前像素与矩形框左上角和右下角的距离。定位损失函数定义为：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)



总损失函数为这两部分加权求和。训练时样本标注方案如下：对于任何一个位置，如果它和真实目标矩形框的重叠比大于指定阈值，则标注为 1，否则标注为 0；对位置的标注根据每个像素与目标矩形框 4 条边的距离计算。



Faceness-Net

Faceness-Net[19]是一个典型的由粗到精的工作流，借助了多个基于 DCNN 网络的 facial parts分类器对人脸进行打分，然后根据每个部件的得分进行规则分析得到 Proposal 的人脸区域，最后通过一个 Refine 的网络得到最终的人脸检测结果。整体流程如图 Faceness（b）。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

Faceness（a）

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

Faceness（b&c）



系统主要包含了 2 个阶段:





第 1 阶段：生成 partness map，由局部推理出人脸候选区域。



根据 attribute-aware深度网络生成人脸部件 map 图(partness map)，如上图 Faceness(a)中的颜色图，文章共使用了 5 个部件:hair,eye,nose,mouth,beard. 通过 part 的结合计算人脸的 score。部件与部件之间是有相对位置关系的，比如头发在眼睛上方，嘴巴在鼻子下方，因此利用部件的 spatial arrangement可以计算 face likeliness. 通过这个打分对原始的人脸 proposal 进行重排序. 如图 Faceness(b)。



第 2 阶段：Refining the face hypotheses

上一阶段 proposal 生成的候选框已经有较高的召回率，通过训练一个人脸分类和边界回归的 CNN 可以进一步提升其效果。



Faceness的整体性能在当时看来非常令人兴奋。此前学术界在 FDDB 上取得的最好检测精度是在 100 个误检时达到 84%的检测率，Faceness在 100 个误检时，检测率接近 88%，提升了几乎 4 个百分点；除了算法本身的精度有很大提升，作者还做了很多工程上的优化比如：通过多个网络共享参数，降低网络参数量 83%；采用多任务的训练方式同一网络实现不同任务等。



MTCNN

MTCNN[20]顾名思义是多任务的一个方法，它将人脸区域检测和人脸关键点检测放在了一起，同 Cascade CNN一样也是基于 cascade 的框架，但是整体思路更加巧妙合理，MTCNN总体来说分为三个部分：PNet、RNet和 ONet，如下图所示：

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

Cascade CNN第一级的 12-net需要在整张图片上做密集窗口采样进行分类，缺陷非常明显；MTCNN在测试第一阶段的 PNet 是全卷积网络（FCN），全卷积网络的优点在于可以输入任意尺寸的图像，同时使用卷积运算代替了滑动窗口运算，大幅提高了效率。下图为不同尺度图像经过 PNet 的密集分类响应图，亮度越高代表该区域是人脸的概率越大（dense prediction response map）。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/75DkJnThACmZQF9ljErGeL7Sb3ncBb5ScF6u5M2pF4Sj2f08QvIYC6Sib4icyAWOFqIMUlyz7XfMlVslG8OTKwVg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

除了增加人脸 5 个关键点的回归任务，另外在 calibration 阶段采用了直接回归真实位置坐标的偏移量的思路替代了 Cascade CNN中的固定模式分类方式，整个思路更为合理。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Shv9qktvdxgQsdQ50OYucAzhC7QBLcEVRknZ8qZcqeP8aVtKZBSk8KA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

MTCNN的整体设计思路很好，将人脸检测和人脸对齐集成到了一个框架中实现，另外整体的复杂度得到了很好的控制，可以在中端手机上跑 20~30FPS。该方法目前在很多工业级场景中得到了应用。



先抛出一张据说是目前世界上人数最多的合照吓吓大家。一眼望过去能估计下有多少人吗？因为本文对小目标人脸检测有很多独到的理解，我们下面会多花点笔墨去分析！

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Sb4y9zwBa7pfvSn8wllc7X63u1ck3yfM58ia432smDSAT9EnTWjsf2icA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



  HR

之前我们讲过的一些方法都没有针对小目标去分析，小目标检测依然是检测领域的一个难题，[21]本文作者提出的检测器通过利用尺度，分辨率和上下文多种信息融合来检测小目标，在上图的总共 1000 个人脸中成功检测到约 800 个，检测器的置信度由右侧的色标表示。



针对小目标人脸检测，作者主要从三个方面做了研究：尺度不变，图像分辨率和上下文，作者的算法在 FDDB 和 WIDERFace 取得了当时最好的效果。



作者分析了小目标人脸检测的三个问题：



Multi-task modeling of scales



一方面，我们想要一个可以检测小人脸的小模板；另一方面，我们想要一个可以利用详细特征（即面部）的大模板来提高准确性。取代“一刀切”的方法，作者针对不同的尺度（和纵横比）分别训练了检测器。虽然这样的策略提升了大目标检测的准确率，但是检测小目标仍然具有挑战性。



How to generalize pre-trained networks?



关于小目标检测的问题，作者提出了两个见解。



如何从预训练的深度网络中最佳地提取尺度不变的特征。



虽然许多应用于“多分辨率”的识别系统都是处理一个图像金字塔，但我们发现在插值金字塔的最底层对于检测小目标尤为重要。



因此，作者的最终方法是：通过尺度不变方式，来处理图像金字塔以捕获大规模变化，并采用特定尺度混合检测器，如下图：

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Sh5RNPRN5LHysSbFibXN5spMluDLecUc02Vy8mnyYJEeHehibzVrZamJQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



（a）单一尺度模板和图像金字塔

（b）不同尺度模板和单一图像

（c）粗略尺度模板和粗略图像金字塔，（a）和（b）的结合

（d）含有上下文信息的固定大小多尺度模板和粗略图像金字塔

（e）定义了从深度模型的多个层中提取的特征模板，也就是 foveal descriptors

How best to encode context?



作者证明从多个层中提取的卷积深度特征（也称为 “hypercolumn” features）是有效的“ foveal”描述符，其能捕获大感受野上的高分辨率细节和粗略的低分辨率线索。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SsgiaHGgziaGR6RdO0PDpmnh5ADlVaN6JHaBSQtYHIEVtibS2zf8apvqfg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

从输入图像开始，首先创建一个图像金字塔（2x插值）。然后我们将缩放的输入图像输入到 CNN 中，获得不同分辨率下人脸预测响应图（后续用于检测和回归）。最后将在不同尺度上得到的候选区域映射回原始分辨率图像上，应用非极大值抑制（NMS）来获得最终检测结果。



Face R-CNN

[22]该方法基于 Faster R-CNN框架做人脸检测，针对人脸检测的特殊性做了优化。



对于最后的二分类，在 softmax 的基础上增加了 center loss。通过加入 center loss使得类内的特征差异更小（起到聚类的作用），提高正负样本在特征空间的差异性从而提升分类器的性能。



加入在线困难样本挖掘（OHEM），每次从正负样本中各选出 loss 最大的 N 个样本加入下次训练，提高对困难样本的的分类能力。

多尺度训练，为了适应不同尺度影响(或者更好地检测小目标)，训练阶段图片会经过不同尺度缩放。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S0t3jXRHIC1kE5c6f7j58hpnbHkibMO7EibIxKoHqqxykgPMF4C0agFjw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



  SSH

[23] SSH最大的特色就是尺度不相关性（scale-invariant），比如 MTCNN 这样的方法在预测的时候，是对不同尺度的图片分别进行预测，而 SSH 只需要处以一个尺度的图片就可以搞定。实现方式就是对 VGG 网络不同 level 的卷积层输出做了 3 个分支（M1,M2,M3），每个分支都使用类似的流程进行检测和分类，通过针对不同尺度特征图进行分析，变相的实现了多尺度的人脸检测。

![img](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

M1和 M2,M3区别有点大，首先，M1的通道数为 128，M2,M3的通道数为 512，这里，作者使用了 1*1卷积核进行了降维操作。其次，将 conv4_3卷积层输出和 conv5_3卷积层输出的特征进行了融合（elementwise sum），由于 conv5_3卷积层输出的大小和 conv4_3卷积层输出的大小不一样，作者对 conv5_3卷积层的输出做了双线性插值进行上采样。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5Sa0gXrYkEPJUvGePXIvIzianMGeIgFDxU7JC6PXrTOuMZOhBtMMFmdyA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

其中，M模块如上图所示，包含了分类和回归 2 个任务，其中 Context Module的为了获得更多的上下文信息，更大的感受野，对该模块使用了等价的 5*5和 7*7的卷积分别进行操作，然后进行特征的 concat 最终形成了上图的 Context Module。（由于大的卷积核效率问题，根据 INCEPTION 的思想，使用 2 个 3*3的卷积核替代一个 5*5的卷积核，使用 3 个 3*3的卷积核替换 1 个 7*7的卷积核）。



PyramidBox

这张图又出现了！！！这一次是百度的“PyramidBox”[24]跑出来的结果。880个人脸！！！

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S3pQTJSAf26LJF4LJy0XudoK2SCiagrQdxtCBTVgOVDrO3WJhYID97wQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

PyramidBox从论文看主要是已有技术的组合应用，但是作者对不同技术有自己很好的理解，所以能组合的很有效，把性能刷的非常高。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S8LnQFnwULc4aXvDN0x1HybibTTibbSS7NYHjglJIAxX9sNK5FSQdCYZA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Architecture of PyramidBox

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5S5KibgJSzAKBK7ia61endAuYhpBw2OmicobnfVoC8uNqRBIIvqJco7Tryw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

针对之前方法对上下文信息的利用不够充分的问题，作者提出了自己的优化方案：



\1. 提出了一种基于 anchor 的上下文信息辅助方法 PyramidAnchors，从而可以引入监督信息来学习较小的、模糊的和部分遮挡的人脸的上下文特征（下图中紫色的人脸框为例可以看到 P3，P4，P5的层中框选的区域分别对应 face、head、body）。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5StqzYmkiaCn930vhqibbnEW8mGcYOI0Qtc6ez5KpwEefOt3a1NJicBMgLg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

\2. 设计了低层特征金字塔网络 ( Low-level Feature Pyramid Networks ) 来更好地融合上下文特征和面部特征，该方法在一次前向过程中（in a single shot）可以很好地处理不同尺度的人脸。

\3.  文中提出了一种上下文敏感的预测模块，该模块由一个混合网络结构和 max-in-out层组成，该模块可以从融合特征中学习到更准确的定位信息和分类信息（文中对正样本和负样本都采用了该策略，针对不同层级的预测模块为了提高召回率对正负样本设置了不同的参数）。max-in-out参考的 maxout 激活函数来自 GAN 模型发明人 Ian J,Goodfellow，它对上一层的多个 feature map跨通道取最大值作为输出，在 cifar10 和 cifar100 上相较于 ReLU 取得了更好的效果。

![img](https://mmbiz.qpic.cn/mmbiz_png/75DkJnThACmZQF9ljErGeL7Sb3ncBb5SKaZpYhOMSqGLOsT88WnCJ1KTrOg4UJic15M3lmFlLxfp8QrsakNe6iag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

\4. 文中提出了尺度敏感的 Data-anchor-采样策略，改变训练样本的分布，重点关注了较小的人脸。



结束语


# 相关

- [人脸检测算法综述](https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247483950&idx=1&sn=a3a5b7907b2552c233f654a529931776&chksm=fdb69fb9cac116af5dd237cf987e56d12b0d2e54c5c565aab752f3e366c0c45bfefa76f5ed16&scene=21#wechat_redirect)
