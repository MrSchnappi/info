---
title: 3.11 无监督图像翻译 CycleGAN
toc: true
date: 2019-09-03
---

### 7.3.6 无监督图像翻译：CycleGAN

**模型结构**

​总体思路如下，假设有两个域的数据，记为 A，B。对于上图第一排第一幅图 A 域就是普通的马，B 域就是斑马。由于 A->B 的转换缺乏监督信息，于是，作者提出采用如下方法进行转换：

- A->fake_B->rec_A
- B->fake_A->rec_B

​对于 A 域的所有图像，学习一个网络 G_B，该网络可以生成 B。对于 B 域的所有图像，也学习一个网络 G_A，该网络可以生成 A。<span style="color:red;">赞！看到这个就知道他是啥思路了，赞。</span>

​训练过程分成两步，首先对于 A 域的某张图像，送入 G_B 生成 fake_B，然后对 fake_B 送入 G_A，得到重构后的 A 图像 rec_A。对于 B 域的某一张图像也是类似。

重构后的图像 rec_A/rec_B 可以和原图 A/B 做均方误差，实现了有监督的训练。此处值得注意的是 A->fake_B(B->fake_A) 和 fake_A->rec_B(fake_B->rec_A) 的网络是一模一样的。<span style="color:red;">是的是的。</span>

下图是形象化的网络结构图：

<center>

![](http://images.iterate.site/blog/image/20190722/Fsr0Nmfzjl1B.png?imageslim){ width=85% }

</center>

> CycleGAN模型示意图

​cycleGAN的生成器采用 U-Net，判别器采用 LS-GAN。<span style="color:red;">嗯。</span>

**Loss设计**

​总的 Loss 就是 X 域和 Y 域的 GAN Loss，以及 Cycle consistency loss：<span style="color:red;">这个式子没看明白。</span>

$$
L(G,F,D_X,D_Y)=L_{GAN}(G,D_Y,X,Y)+L_{GAN}(F,D_X,Y,X)+\lambda L_{cycle}(G,F)
$$

整个过程 End to end 训练，效果非常惊艳，利用这一框架可以完成非常多有趣的任务。<span style="color:red;">是呀，各种赞！</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
