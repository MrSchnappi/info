---
title: 01 风格迁移算法简介
toc: true
date: 2018-08-29
---
##### 第 13 章图像风格迁移

本章简要介绍一种实现图像风格迁移的算法，并介绍 MXNet 中对照片风格化处理的 有趣例子。

13.1风格迁移算法简介

本节简要介绍通过基于卷积神经网络的图像重建，实现风格迁移的方法。

13.1.1通过梯度下降法进行图像重建

前面已经讲过，神经网络可以看作是一种变换，输入在每一层变接后都可以看作是一 个向量，这个向量经过下一层继续变换成为新的向量。因为是变换，很自然会想到是否可 以做逆变换，也就是根据提取的特征进行图像重建的问题。对于一般的卷积神经网络，严 格的逆变换常常是不行的，不过这个问题有不少人研究过，其中一种比较有代表性的方法 是 VGG 组在 2015 年 CVPR 上发表的《Understanding Deep Image Representations by Inverting Them》。方法的基本思路是原始图片经过变换后会得到一个向量作为特征，这时候保持提 取特征的网络的参数不变，用任意输入（比如白噪声）经过网络变换可以得到一个特征， 然后定义一种损失函数来计算这个特征和原图得到特征的差异，并利用梯度下降法进行优 化，同时加入规范化的项对要重建的图像进行约束。这就转换成了一个优化问题：

(公式 13-1)

argmm(G(x)-G(ximg))2+2/?(x)

其中，ximg是目标图像，是迭代过程中的图像，所以维度是图像的宽（W）乘以高（//） 再乘以通道数（C）。优化的目标函数是要让目标图像经过一个卷积神经网络 G 得到的特 征，和要重建的图像经过 G 得到的特征尽量一致。采用欧式距离作为损失函数，另外，因 为通常是个不可逆问题，所以需加上规范化的项。规范项有很多选项，原文中采用的是图 像的梯度，外加考虑了图像分辨率大小的取值幅度。

求解这个问题就可以得到重建的图像，如图 13-la所示。至于变换 G，可以是不同的 网络，也可以是同一个网络中任何层得到的特征。第 4 章中已经讨论过，对于一般的分类/ 检测网络等，越靠近输入的特征越底层，比如纹理，或是简单形状等；越靠近输出的特征 则包含越多的语义信息，比如不同种类的物体或是某类物体的明显特点。在图像重建中， 特征所处的位置则反映在重建的完整性上。对于底层的卷积核，如果数量足够，是能够很 好保存原始图像中的信息的。另一方面因为低层的特征响应图的维度通常远高于输入的图 像，这时候只要特征足够多样化，几乎是可以完美重建输入图像。随着特征的不断传播， 丢失的信息越来越多，尤其是到了很高的层之后，特征的维度也降下来，这时候通过梯度 下降重建输入图像成了典型的病态问题，重建的效果就不会很好，最后的结果受到规范化 项的影响也比较大。体现在视觉上就是低层特征重建的图像和原图更像包括线条等细节， 都能够得到很好的还原，而高层特征重建的图像则丢失较多内容，尤其是细节部分。比如

用 MXNet 的 neural-style 自带的 VGG-19 模型为例，https://github.com/dmlc/mxnet/blob/ master/example/neural-style/model_vggl9.py，分另 lj 基于 relul_l、relu2_l、relu3_l、relu4_l 和 relu5_l的特征进行图像重建，就会发现随着特征层数的不断变高，丢失的信息从细节 边缘到颜色，再到整个画面，如图 13-lb所示。



基于不同层特征重建的图像



relull relu2_l relu3_l relu4_l    relu5_l

图 13-1通过梯度下降的方法重建图像示意图

13.1.2图像风格重建和 Gram 矩阵

提到图像风格，其实是个很主观的概念，每个人都有不同的理解，比如绘画的表现形 式有写实、印象、浪漫等。稍微具体一些的比如以画的类型区分，有油画、水彩、国画或 素描，到这个层级就已经偏向客观一些了，从纹理上就能很明显地区分。更细致具体的就 是绘画的笔触了，比如素描中不同的笔触会留下不同的线条和变化。计算机视觉中，谈到 图像风格一般指的都是偏于客观的成分，也就是纹理、线条等特点。图像风格学习基于的 早期研究都属于计算机视觉中纹理合成(Texture Synthesis)的范畴，这在第 1 章中也介绍 过。所以在本章中说到图像风格的学习，其实具体一些可以理解为基于卷积神经网络的纹 理合成。

通过 13.1.1节我们知道了如何通过图像特征重建图像内容的一种方法，本节介绍基于 同样套路来重建图像纹理风格的方法。既然是纹理，其中的一个特点就是和图像中的具体 位置无关（比如第 1 章图 l-12a），基于此常见的思路有两大类：一类是参数化方法，把 图像中的某种统计信息拿出来作为一种代表纹理的特征；另一类是非参数化方法，大体思 路是随机采样图像中的区域，然后通过某种自然的方式合成新的纹理。本节介绍的方法属 于第一类，利用卷积神经网络不同层响应图的 Gram 矩阵代表纹理的信息：

（公式 13-2）

k

其中 Gz 代表第/层响应图对应的 Gram 矩阵，F/代表该层第 f 个卷积核对应的响应图。通 常一个响应图是二维的，这里把响应图展开为一个一维向量，其中 Fz/代表该层第/个响应 图的第*个元素。所以 Gram 矩阵中每个元素就是该层响应图对应的两个通道的点积，代 表了这两个通道的特征之间的相关性。接下来就和 13.1.1节一样了，把每层 Gram 矩阵作 为特征，让重建图像的 Gram 矩阵尽量接近原图的 Gram 矩阵，也是个优化问题：

x = arg min V WjE,    （公式 13-3）

xeR.xC 勺-

其中松是每一层的 loss,    是该层 loss 的权重。松的形式是考虑到每层响应图大小后

的 Gram 矩阵差异。

（公式叫）

其中是输入图像每层的 Gram 矩阵。从第 4 章中知道，不同层响应图的像素对 应着原画面上不同大小的感受野，同时越高层相应包含的信息越抽象，*这种特性一定程度 上也体现在重建的纹理中。下面以梵高的《星夜》作为输入，来看看分别以 relul_l> relu2_l> relu3_l、relu4_l和 relu5_l，还有把这些层综合考虑一起的 Gmm 矩阵作为优化目标得到的 纹理。采用的模型同样是 mxnet/example/neural-style自带的 VGG-19，结果如图 13-2所 75。



relul 一 1    relu2_l    relu3_l



“The Starry Night” by Vincent van Gogh

图 13-2不同层 Gram 矩阵重建纹理的结果

通过图 13-2可以观察出不同层的 Gram 矩阵对重建图像的贡献，比如 relul_l只能得 到很高频的纹理特征，差不多是画面中最基本的色块，无序程度也最高。而随着层数的增 加，得到的重建纹理中渐渐出现了类似于线条走向的信息，甚至能勉强看出一点梵高特有 的漩涡状线条。然后把所有 5 个层对应的 loss 平均加在一起，就综合考虑了各种不同尺度 和层次的纹理。得到的重建如图 13-2中的 all 图所示，感觉夜空、小镇、星月和松树像是 都溶进了一幅随手涂的油画里。

13.1.3图像风格迁移

图像内容和图像风格(纹理)的重建方法都有了，那么图像风格迁移的思路就很自然 了，就是把两种 loss 考虑在一起，重建的图像会融合一张图像的内容和另一张图像的风格， 所以仍然是个优化问题。

x = argmin aLcontent (x,xcontent) + ^styIe (x,xstyle) + 2/? (x) (公式 13-5)

xeK//xrxc

其中々。。⑽和 LeQntent 分别是内容图像和对应的 loss,    £style分别是风格图像和对

应的 loss, 7?(x)是规范项。a, 和 A 分别是权重系数，用来决定重建的图像更偏重内容还 是风格。这个方法算是基于卷积神经网络进行风格迁移的开山之作，最早由德国 Tubingen 大学的 Leon A. Gatys 发表在 arxiv 上的预印版论文《A Neural Algorithm of Artistic Style》 中，后来完善版的论文《Image Style Transfer Using Convolutional Neural Networks》发表在 2016年的 CVPR 上。

这种直接基于优化的方法优点是简单清晰，发表之后就陆续出现改进风格 loss 的各种 办法。比如德国 Mainz 大学一个研究组，用基于图像 patch 的马尔科夫随机场 loss 替换 Gram 矩阵的《Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis))，对于很多图片的效果要自然很多。

从图像直接优化的过程其缺点在于很慢，所以另一个方向是针对慢的问题进行研究。 比如 Stanford 的 Li Fei-Fei 组发表在 2016 年 ECCV 上的论文 «Perceptual Losses for Real-Time Style Transfer and Super-Resolution》，把内容图像经过一个变换网络，再送入计 算内容加风格 loss 的网络，这样再生成新图片的时候就不需要经过漫长的优化过程了，达 到了实时。在 MXNet 中的官方例子里，有个 end_to_end的文件夹，其中的方法就和这个 思路类似但又不完全一样，有兴趣的读者可以参考<http://dmlc.ml/mxnet/2016/06/20/> end-to-end-neural-style.html。

2017 年 1 月，在 arXiv 上出现了一篇叫《Bringing Impressionism to Life with Neural Style Transfer in Come Swim》的论文，这篇论文用风格迁移的方法对影片《Come Swin》的画面 进行了风格转换和调参，提出了风格迁移和艺术结合的研究方向。

13.2 MXNet中的图像风格迁移例子

本节一起来了解 MXNet 下实现图像风格迁移的官方例子，并试试效果。

13.2.1 MXNet的风格迁移实现

MXNet中风格迁移的实现在 mxnet/example/neural-style下，实现的是最原始的 Gatys 版的算法，文件列表如图 13-3所示。

| g README.md                  | New callback interface for training visualization. (#3849) | 2 months ago  |
| ---------------------------- | ---------------------------------------------------------- | ------------- |
| \|S) checkpoint-viewer.ipynb | New callback interface for training visualization. (#3849) | 2 months ago  |
| g) download.sh               | I exam pie] init commit of neural-style                    | a year ago    |
| 區]f»nd.mxnet.py             | lexamplel commit of neural-style                           | a year ago    |
| g] modeLvggl9.py             | (STYLE] make pure symbolic impl, add tv loss               | 10 months ago |
| @ neuralartipynb             | New callback interface for training visualization. (#3849) | 2 months ago  |
| g) nstyle.py                 | New callback interface for training visualization. (#3849) | 2 months ago  |

图 13-3 MXNet中 neural-style例子的主要文件

其中 download.sh用于下载 VGG-19模型的参数；model_vggl9.py为模型结构的定义； 其他大部分实现都在 nstyle.py S； find mxnet.py是用来自动导入 MXNet 的脚本；两个 ipynb 是 ipython notebook文件，主要演示如何运行和查看优化过程中的结果，在控制台执行：

» jupyter notebook

然后在浏览器中找到这两个 ipynb 文件就可以打开。因为方法本舞非常简单，所以主 要关注的几乎都在 nstyle.py中，下面通过注释的方式结合代码一起来看看这个文件的具体 实现。

import find_mxnet import mxnet as mx import numpy as np import importlib import logging

logging.basicConfig(level=logging.DEBUG) import argparse

from collections import namedtuple from skimage import io, transform

from skimage.restoration import denoise_tv_chambolle

CallbackData = namedtuple(* CallbackData', field_names=[* eps', 'epoch *,

\* img *,* filename1])

def get_args(arglist=None):

ft vv vv

各种输入参数的定义

i"i n

parser = argparse.ArgumentParser(description=1 neural style1)

\#指定模型，默认使用 vggl9，如果要使用自己定义的模型，需要按照 # model_vggl 9. py的格式定义好 style 和 content 对应的特征层 #并命名为 model_[模型名字].py的形式

parser.add_argument(1——model *, type=str, default='vggl9 *, choices =    ['vgg1],

help =    * the pretrained model

to use1)

\#指定内容图片

parser.add_argument('--content-image', type=str, default=1 input/ IMG_4343.jpg’，

help= * the content image *)

\#指定风格图片，默认是梵高的《星夜》

parser.add_argument('--style-image *,    type=str,    default='input/

starry_night.jpg',

help='the style image')

\#当重建图像的相对变换小于 stop-eps时停止迭代

parser.add_argument(*--stop-eps'z type=float, default=.005z

help=1 stop if the relative

chanage is less than eps *)

\#内容 loss 的权重，会认 10

parser.add_argument(*——content-weight *, type=float, default=10, help='the weight for the

content image1)

\#风格 loss 的权重，默认 1

parser.add_argument(*——style-weight *, type=floatz default=l,

help='the weight for the style

image1)

\#规范项之 totol-variation的权重

parser.add_argument(1--tv-weight *, type=float, default=le-2,

help= * the magtitute on TV loss')

\#最大迭代次数

parser.add_argument(*--max-num-epochs *, type=int, default=1000, help= * the maximal number of

training epochs *)

\#限制输入图像的最长边

parser.add_argument(* ——max-long-edge•, type=int, help=* resize the

default=600, content image *)

001,

learning rate1)

\#基础学习率

parser.add_argument('——lr', type=float, default= help='the initial

\#指定要用来进行优化的 GPU

parser.add_argument('--gpu', type=int, default=0,

help='which gpu card to use,

-1 means using cpu *)

\#指定^出文件，包含优化过程中的文件和最后文件的输出位置

parser.add_argument('——output_dir *, type=str, default= * output/*, help=1 the output image *)

\#每隔多少次进行一次重建图像的保存

parser.add_argument(1--save-epochs *, type=int, default=50,

help= * save the output every n

epochs’)

\#移除噪音的幅度

parser,add_argument('--remove-noise*, type=float, default=.O2,

help='the magtitute to remove

noise')

\#学习率变化的策略，默认 75 次迭代学习率下降为之前 0.9倍

parser.add_argument('--lr-sched-delay1, type=int, default=75,

help='how many epochs between

decreasing learning rate *)

parser.add_argument('——lr-sched-factor' , type=int, default=0.9, help='factor to    decrease

learning rate on schedule *) if arglist is None:

return parser.parse_args()

else:

return parser.parse_args(arglist)

def PreprocessContentlmage(path, long_edge):

If If If

预处理内容输入图片

内容在此省略

def PreprocessStylelmage(path, shape):

预处理风格输入图片

VI IV VT

..。内容在此省略...

def Postprocesslmage(img):

VI IV IV

将重建得到的向量变换回图像

| img =     | np.resize(img,   | (3,  | img.shape[2], img.shape[3])) |
| --------- | ---------------- | ---- | ---------------------------- |
| img[0,    | :]+= 123.68      |      |                              |
| img[1,    | :]+=    116.779  |      |                              |
| img[2,    | :]+= 103.939     |      |                              |
| img =     | np.swapaxes(img, | 1,   | 2)                           |
| img =     | np.swapaxes(img, | 0,   | 2)                           |
| #防止溢出 |                  |      |                              |
| img =     | np.clip(img, 0,  | 255) |                              |

return img.astype('uint8 *) def SaveImage(img, filename, remove_noise=0.):

If If If

保存图片

vv vv n

..。内容在此省略...

def style_gram_symbol(input_size, style):

VV VV If

for i in range(len(style.list_outputs())): shape = output_shapes[i]

x = mx.sym.Reshape(style[i],    target_shape=(int(shape[1]),

int(np.prod(shape[2:]))))

\#利用全连接层快速计算点积：(x, x-T)

gram = mx.sym.FullyConnected(x, x, no_bias=True, num_ hidden=shape[1])

gram一 list.append(gram)

grad_scale.append(np.prod(shape[1:])    ★ shape[1]〉

return mx.sym.Group(gram_list), grad_scale

def get_loss(gram, content):

ft VV II

利用 Gram 矩阵计算风格的 loss

gram_loss =    []

\# ^＞文中不同的是这里并没有设置权重，而是直接相加

for i in range(len(gram.list_outputs())):

gvar = mx. sym. Variable (ntarget_gram_%d,' % i)

gram_loss.append(mx.sym.sum(mx.sym.square(gvar - gram[i])))

cvar = mx. sym.Variable (ntarget_content**)

content_loss = mx.sym.sum(mx.sym.square(cvar - content)) return mx.sym.Group(gram_loss), content_loss

def get_tv_grad_executor(img, ctx, tv_weight):

VV VI IV

计算图像梯度作为 Total Variation的定义 思路是用 3x3 的 Laplace 和对图像做卷积

if tv_weight <=    0.0:

return None

nchannel = img.shape[1]

simg = mx.sym.Variable("img")

skernel = mx.sym.Variable("kernel")

channels = mx.sym.SliceChannel(simg, num_outputs=nchannel) out = mx.sym.Concat(*[

mx.sym.Convolution(data=channels [i], weight=skernel, num_filter=l,

kernel=(3f    3), pad=(l,l),

no_bias=True,

stride=(1,1))

for i in range(nchannel)])

out = out * tv_weight

return out.bind(ctx, args={"img": img,

"kernel": kernel})

def train_nstyle(args, callback=None):

IV VV ft

训练过程的定义

IV VI If

\#输入：内容图像和风格图像

dev = mx. gpu (args. gpu) if args.gpu >=    0 else mx. cpu ()

content_np = PreprocessContentlmage(args.content_imagez    args.

max_long_edge)

style_np = PreprocessStylelmage(args.style_imagez shape=content_ np.shape)

size = content_np.shape[2:]

\#模型和相应的 executor

Executor = namedtuple(1 Executor',    [* executor1,    'data',    *data_grad'])

model_module = importlib.import_module(*model_' + args.model) style, content = model_module.get_symbol()

gram, gscale = style_gram_symbol(size, style)

model_executor = model—module.get_executor(gram, content, size,

dev)

model_executor.data[: ]    = style_np

model_executor.executor.forward() style—array =    []

for i in range(len(model_executor.style)):

style_array.append(model_executor.style[i].copyto(mx.cpu())) model_executor.data[:]    = content_np

model_executor.executor.forward()

content_array = model_executor.content.copyto(mx.cpu())

\#图像内_容和风格特征已经获'取，删除当前 executor #接下来用新的 executor 用于重建图像的梯度下降 del model_executor

style_loss, content_loss = get_loss(gram, content) model_executor = model_module•get一 executor(

style_loss, content_loss, size, dev) grad_array =    []

for i in range(len(style_array)):

style_array[i].copyto(model_executor.arg_dict[ntarget_gram_%dn % i])

grad_array.append(mx.nd.ones((1z), dev) ★ (float(args.

style_weight) / gscale[i]))

grad_array.append(mx.nd.ones((1, ) , dev) * (float(args.content— weight)))

print([x.asscalar() for x in grad_array])

content_array.copyto(model_executor.arg一 diet["target_contentu])

\#要重達的图像，用随机噪声初始不七

img = mx.nd.zeros(content_np.shape, ctx=dev) img[:]    = mx.rnd.uniform(-0.1,    0.1, img.shape)

\#学习率策略

lr = mx.lr_scheduler.FactorScheduler(step=args.lr_sched_delay, factor=args.lr_sched_factor)

\#用 NAG 进行梯度下降

optimizer = mx.optimizer.NAG(

learning_rate = args.lr, wd =    0.0001,

momentum=0.95, lr_scheduler = lr)

optim_state = optimizer.create_state(0, img) logging.info(* start training arguments %s ' , args) old_img = img.copyto(dev)

clip_norm =    1    * np.prod(img.shape)

tv_grad_executor = get_tv_grad_executor(img, dev, args.tv_weight)

\# _执行<度下降

for e in range(args,max_num_epochs): img.copyto(model_executor.data) model executor.executor.forward()

——    i

model_executor.executor.backward(grad_array)

gnorm = mx.nd.norm(model_executor.data_grad).asscalar()

| #    | 梯度截断防止过大梯度出现                                     |                |        |
| ---- | ------------------------------------------------------------ | -------------- | ------ |
| if   | gnorm > clip norm:model executor.data_grad[:]                | ★= clip norm / | 'gnorm |
| if   | tv grad executor is not None: tv grad executor.forward() optimizer.update(0, img, |                |        |

model_executor.data_grad

\+ tv_grad_executor.outputs [ 0],

optim—state)

else:

optimizer.update(0, img, model_executor.data_grad,

optim_state)

new_img = img

\# ；算相对变化，用于判断是否停止迭代

eps = (mx.nd.norm(old_img - new_img) / mx.nd.norm (new_img)).asscalar()

old_img = new_img.copyto(dev)

logging.info('epoch %d, relative change %f', e, eps) if eps < args. stop_eps:

logging.info(* eps < args.stop_eps, training finished*) break

if callback:

outfn = args.output_dir +    *e_*+str(e+1) + *.jpg*

npimg = new_img.asnumpy()

Savelmage(npimg, outfn, args.remove_noise) if callback:

cbdata[* filename * ]    = outfn

cbdata[* img1]

npimg

if callback:

callback(cbdata)

final_fn = args.output_dir +    */final.jpg *

SaveImage(new_img.asnumpy(), final_fn)

if _name_ ==    •’_main_":

args = get_args() train_nstyle(args)

model_vggl9.py文件这里也简单看一下，主要值得关注的是 get_symbol()函数的最后 几行：

\#定义用来提取风格和内容特征的层

style = mx.sym.Group([relul_l, relu2_l, relu3_l, relu4_l, relu5_l])

content = mx.sym.Group([relu4_2]) return style, content

可以看到风格训练有用到从高层到低层的特征，而训练图像内容只使用了 relu4_2这 一比较高层的特征，这样可以让纹理更充分地替代图像内容中的细节。

13.2.2对图片进行风格迁移

首先来试试自带的例子，第一步下载预训练好的 VGG-19模型参数和示例图片。

\>> sh download, sh

之后会在 input 文件夹下得到两幅演示的图像，model文件夹下得到 VGG-19的模型参 数 vggl9.params。然后直接运行：

» python nstyle.py

X

即能得到把《星夜》风格迁移到建筑物上的图片了，输出在 output 文件夹下。作为演示， 用下面命令运行脚本，每隔 30 次迭代获取一幅重建中的图像。

» python nstyle.py ——save-epochs 30 训练中重建图像的变化过程如图 13-4所示。

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-315.jpg)



迭代 30 次    迭代 90 次    迭代 150 次



图 13-4重建图片随训练进行的变化过程

可以看到随着迭代次数的增加，图片渐渐从一团乱糟变成了带有《星夜》味道的图像。 下面再来试试其他的照片和风格，通过--content-image和--style-image参数可以分别指定内 容和风格图像，通过-content-weight和--style-weight可以调整相应 loss 的比重。下面用海 边拍摄的照片分别加上莫奈的《帆船，夜晚印象》，以及 19 世纪德国浪漫主义画家 Caspar David Friedrich的《云端的旅行者》，并把风格的权重系数增加到 2 来测试，结果如图 13-5 所示。

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-318.jpg)

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-319.jpg)

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-320.jpg)



图 13-5图像风格迁移的例子

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-322.jpg)

从图 13-5中看效果还不错，从《帆船，夜晚印象》的例子来看，得到的照片甚至暗部 细节也提升了，相当于实现了 HDR (High Dynamic Range)效果，也就是说连图像的动态 范围也作为风格学习到了。通过调整风格比重，甚至改变用来提取特征的层，还可以获得 更多不同的变化，这些变化就留给读者自己探索了。




# 相关

- 《深度学习与计算机视觉》
