# 大纲


## 2. 知识表示、推理和回答

<span style="color:red;">没看懂。再看下。</span>


因为使用符号(Rumelhart et al.,1986a)和词嵌入(Deerwester et al.,1990;Bengio et al.,2001b)，深度学习方法在语言模型、机器翻译和自然语言处理方面非常成功。这些嵌入表示关于单个词或概念的语义知识。研究前沿是为短语或词和事实之间的关系开发嵌入。搜索引擎已经使用机器学习来实现这一目的，但是要改进这些更高级的表示还有许多工作要做。

### 2.1 知识、联系和回答


一个有趣的研究方向是确定如何训练分布式表示才能捕获两个实体之间的关系(relation)。

数学中，二元关系是一组有序的对象对。集合中的对具有这种关系，而那些不在集合中的对则没有。例如，我们可以在实体集 $\{1,2,3\}$ 上定义关系“小于”来定义有序对的集合 $\mathbb{S}=\{(1,2),(1,3),(2,3)\}$。一旦这个关系被定义，我们可以像动词一样使用它。因为 $(1,2) \in \mathbb{S}$，我们说 1 小于 2。因为 $(2,1) \notin \mathrm{S}$ ，我们不能说 2 小于 1。当然，彼此相关的实体不必是数字。我们可以定义关系 `is_a_type_of` 包含如 $(狗，哺乳动物)$ 的元组。

在 AI 的背景下，我们将关系看作句法上简单且高度结构化的语言。关系起到动词的作用，而关系的两个参数发挥着主体和客体的作用。这些句子是一个三元组标记的形式：

$$
(subject, verb, object)
$$

其值是

$$
(entity _{i},relation _{j}, entity _{k} )
$$

我们还可以定义属性(attribute)，类似于关系的概念，但只需要一个参数：

$$
(entity_i, attribute _{j} )
$$


例如，我们可以定义 `has_fur` 属性，并将其应用于像狗这样的实体。

许多应用中需要表示关系和推理。我们如何在神经网络中做到这一点？

机器学习模型当然需要训练数据。我们可以推断非结构化自然语言组成的训练数据集中实体之间的关系，也可以使用明确定义关系的结构化数据库。这些数据库的共同结构是关系型数据库，它存储这种相同类型的信息，虽然没有格式化为三元标记的句子。当数据库旨在将日常生活中常识或关于应用领域的专业知识传达给人工智能系统时，我们将这种数据库称为知识库。知识库包括一般的，像 Freebase、Open Cyc、Word Net、Wikibase 等；还包括专业的知识库，如 Gene Ontology。实体和关系的表示可以将知识库中的每个三元组作为训练样本来学习，并且以最大化捕获它们的联合分布为训练目标(Bordes et al.,2013a)。<span style="color:red;">厉害厉害，想知道这个后续是什么样了。</span>

除了训练数据，我们还需定义训练的模型族。一种常见的方法是将神经语言模型扩展到模型实体和关系。神经语言模型学习提供每个词分布式表示的向量。他们还通过学习这些向量的函数来学习词之间的相互作用，例如哪些词可能出现在词序列之后。我们可以学习每个关系的嵌入向量将这种方法扩展到实体和关系。事实上，建模语言和通过关系编码建模知识的联系非常接近，研究人员可以同时使用知识库和自然语言句子训练这样的实体表示(Bordes et al.,2011,2012;Wang et al.,2014a)，或组合来自多个关系型数据库的数据(Bordes et al.,2013b)。可能与这种模型相关联的特定参数化有许多种。早期关于学习实体间关系的工作(Paccanaro and Hinton,2000)假定高度受限的参数形式(“线性关系嵌入”)，通常对关系使用与实体形式不同的表示。例如，Paccanaro and Hinton(2000)和 Bordes et al.(2011)用向量表示实体而矩阵表示关系，其思想是关系在实体上相当于运算符。或者，关系可以被认为是任何其他实体(Bordes et al.,2012)，允许我们关于关系作声明，但是更灵活的是将它们结合在一起并建模联合分布的机制。

这种模型的实际短期应用是链接预测(link prediction)：预测知识图谱中缺失的弧。这是基于旧事实推广新事实的一种形式。目前存在的大多数知识库都是通过人力劳动构建的，这往往使知识库缺失许多并且可能是大多数真正的关系。请查看 Wang et al.(2014b)、Lin et al.(2015)和 Garcia-Duran et al.(2015)中这样应用的例子。

我们很难评估链接预测任务上模型的性能，因为我们的数据集只有正样本(已知是真实的事实)。如果模型提出了不在数据集中的事实，我们不确定模型是犯了错误还是发现了一个新的以前未知的事实。度量基于测试模型如何将已知真实事实的留存集合与不太可能为真的其他事实相比较，因此有些不精确。构造感兴趣的负样本(可能为假的事实)的常见方式是从真实事实开始，并创建该事实的损坏版本，<span style="color:red;">哦，原来这就是损坏样本。嗯。</span>例如用随机选择的不同实体替换关系中的一个实体。通用的测试精度(10%度量)计算模型在该事实的所有损坏版本的前 10%中选择“正确”事实的次数。

知识库和分布式表示的另一个应用是词义消歧(word-sense disambiguation)(Navigli and Velardi,2005;Bordes et al.,2012)，这个任务决定在某些语境中哪个词的意义是恰当的。

最后，知识的关系结合一个推理过程和对自然语言的理解可以让我们建立一个一般的问答系统。一般的问答系统必须能处理输入信息并记住重要的事实，并以之后能检索和推理的方式组织。这仍然是一个困难的开放性问题，只能在受限的“玩具”环境下解决。目前，记住和检索特定声明性事实的最佳方法是使用显式记忆机制，如第 10.12节所述。记忆网络最开始是被用来解决一个玩具问答任务(Weston et al.,2014)。Kumar et al.(2015b)提出了一种扩展，使用 GRU 循环网络将输入读入存储器并且在给定存储器的内容后产生回答。

深度学习已经应用于其他许多应用(除了这里描述的应用以外)，并且肯定会在此之后应用于更多的场景。我们不可能全面描述与此主题相关的所有应用。本项调查尽可能地提供了在本文写作之时的代表性样本。

本书第 2 部分介绍了涉及深度学习的现代实践，囊括了所有非常成功的方法。一般而言，这些方法使用代价函数的梯度寻找模型(近似于某些所期望的函数)的参数。当具有足够的训练数据时，这种方法是非常强大的。我们现在转到第 3 部分，开始进入研究领域，旨在使用较少的训练数据或执行更多样的任务。而且相比目前为止所描述的情况，其中的挑战更困难并且远远没有解决。

