---
title: 华尔街发现AI应用尚有局限
toc: true
date: 2019-11-17
---
2018年8月22日，高盛董事总经理兼机器学习全球负责人Charles Elkan在开源AI软件公司H2O.ai主办的会议上发言。 图片来源：SARA CASTELLANOS / THE WALL STREET JOURNAL

高盛集团(Goldman Sachs Group Inc., GS)和摩根士丹利(Morgan Stanley, MS)对人工智能进行多方位试验的专家称，人工智能可能有助发现欺诈行为，减少算法交易中的错误，但眼下这种技术仍存在很多局限。

摩根士丹利机器学习和人工智能执行董事Ambika Sukla周二在一个人工智能大会上表示，运用人工智能领域取得的进步为金融领域创造利益需要做很多工作。Sukla表示，在研究开发一些新模型的过程中，有必要谨慎推进且有人类的参与。

在开源人工智能软件公司H2O.ai举办的一个大会上，Sukla等人谈到人工智能对金融行业的潜在影响。此次大会的召开适逢自动化、软件和电脑驱动的量化基金在金融业兴起之时。正如《华尔街日报》(The Wall Street Journal)此前报道的，目前代码取代交易员完成很多工作。

Sukla说，在摩根士丹利，人工智能通过对人类无法消化的数百份文件和数据来源做更多研究和分析，可以为客户提供更好的交易和投资理念。人工智能还可以用来识别信用卡交易异常、电汇诈骗，以及减少算法交易的错误。他说，人工智能也是虚拟助手的基础技术，虚拟助手可以处理简单任务，回答员工和客户的简单提问。

但是，当回答那些需要背景理解和财务敏锐度的问题时，人工智能算法很容易被愚弄，所以在这方面指望不上这项技术。在提到那些接受模式识别训练的演算法时，Sukla说，尚不清楚这些模型是在不断学习还是仅仅是简单记忆数据。

Sukla等人在会议上说，通用人工智能(general purpose artificial intelligence)能够理解知识、通过观察来学习，能够解决问题并产生想法，我们离这个目标还很远。

高盛董事总经理兼机器学习全球负责人Charles Elkan称，在他看来，根本性问题是他所谓的深刻理解与肤浅理解的比较。他说，肤浅理解是只能回答那些彼此相似的有限问题，而深刻理解意味着了解整体背景且拥有广博的知识，包括知道谁在提问，而这是人工智能算法所不能企及的。他举例说，使用聊天机器人对求职者进行初步筛选是不可能的，因为这项工作需要深刻理解。

Elkan说，目前对于人工智能系统能否像人类一样聪明或比人类更加聪明的猜测甚嚣尘上。他说，答案就是，没有自然法则说超级智能是不可能的，但目前已知的所有人工智能算法都不会达到人类智力水平，更不要说超级智能。

高级人工智能系统的另一个局限是，这种系统无法解释它们是如何做决定的。

一些公司、私人机构和研究人员对于借助人工智能的透明性在人类和机器之间建立起更高程度的信任很感兴趣。

例如，Capital One Financial (COF)正研究机器学习算法可以用什么办法解释其答案背后的理由，这可能会在防范潜在道德和监管问题方面产生深远影响，因为该公司正在银行业务中使用更多的人工智能技术。

机器学习使计算机得以借助最低限度的编程工作从数据中进行学习，是人工智能很大的一个组成部分。人工智能包含了多种技术，这些技术被用于教计算机如何像人类一样学习、推理、感知、推断、交流和做决定。



富国银行(Wells Fargo & Co., WFC)企业模型风险部负责人Agus Sudjianto说，他的团队已经研究出让机器学习模型像统计模型一样透明的方法。

他表示：“将机器学习或人工智能付诸应用的一大障碍是可解释性。”

# 相关

- [华尔街发现AI应用尚有局限](https://mp.weixin.qq.com/s?__biz=MjM5NjgyMDg4OQ==&mid=2721256864&idx=1&sn=e76c985ca23c7e5ac887ce15954ef88c&chksm=8124d756b6535e40991bffd6ce68fcdca7acd3c0b298ac28f8b1d0d858a90a21c1bf3a678d8a&mpshare=1&scene=1&srcid=0825cc3GhUHMgPsUgoc2TDZG#rd)
