---
title: 21 不同算法的相同之处
toc: true
date: 2019-06-05
---

# 不同算法的相同之处

几乎所有的深度学习算法都可以被描述为一个相当简单的配方：

- 特定的数据集
- 代价函数
- 优化过程
- 模型。

所以在整个 machine learning framework整个过程分成了三个：

1. 第一个步骤就是找一个 function，定出一个 function set
2. 第二个步骤让 machine 可以衡量一个 function 是好还是不好
3. 第三个步骤是让 machine 有一个自动的方法，有一个好演算法可以挑出最好的 function。

## 代价函数


例如，线性回归算法由以下部分组成：$\boldsymbol{X}$ 和 $\boldsymbol{y}$ 构成的数据集，代价函数

$$
J(\boldsymbol{w}, b)=-\mathbb{E}_{\mathbf{x}, \mathbf{y} \sim \hat{p}_{\text { data }}} \log p_{\text { model }}(y | \boldsymbol{x})
$$

<span style="color:red;">$\mathbf{x}, \mathbf{y} \sim \hat{p}$ 是什么意思？</span>

模型是 $p_{\text { model }}(y | \boldsymbol{x})=\mathcal{N}\left(y ; \boldsymbol{x}^{\top} \boldsymbol{w}+b, 1\right)$ ，在大多数情况下，优化算法可以定义为求解代价函数梯度为零的正规方程。<span style="color:red;">$\mathcal{N}$ 是什么？</span>

意识到我们可以替换独立于其他组件的大多数组件，因此我们能得到很多不同的算法。<span style="color:red;">是呀，厉害。</span>


通常代价函数至少含有一项使学习过程进行统计估计的成分。最常见的代价函数是负对数似然，最小化代价函数导致的最大似然估计。<span style="color:red;">为什么负对数似然是最常见的代价函数？最小化代价函数导致的最大似然估计。这句是什么意思？</span>

代价函数也可能含有附加项，如正则化项。例如，我们可以将权重衰减加到线性回归的代价函数中：


$$
J(\boldsymbol{w}, b)=\lambda\|\boldsymbol{w}\|_{2}^{2}-\mathbb{E}_{\mathbf{x}, \mathbf{y} \sim \hat{p}_{\text { data }}} \log p_{\text { model }}(y | \boldsymbol{x})
$$

该优化仍然有闭解。<span style="color:red;">什么是闭解？</span>



组合模型、代价和优化算法来构建学习算法的配方同时适用于监督学习和无监督学习。线性回归示例说明了如何适用于监督学习的。

无监督学习时，我们需要定义一个只包含 $\boldsymbol{X}$ 的数据集、一个合适的无监督代价和一个模型。例如，通过指定如下损失函数可以得到 PCA 的第一个主向量


$$
J(\boldsymbol{w})=\mathbb{E}_{\mathbf{x} \sim \hat{p}_{\text { data }}}\|\boldsymbol{x}-r(\boldsymbol{x} ; \boldsymbol{w})\|_{2}^{2}
$$

<span style="color:red;">这个地方没懂。涉及到 PCA</span>

模型定义为重构函数 $r(\boldsymbol{x})=\boldsymbol{w}^{\top} \boldsymbol{x} \boldsymbol{w}$，并且 $\boldsymbol{w}$ 有范数为 $1$ 的限制。

## 数值优化过程

如果我们将该模型变成非线性的，那么大多数代价函数不再能通过闭解优化。这就要求我们选择一个迭代数值优化过程，如梯度下降等。


在某些情况下，由于计算原因，我们不能实际计算代价函数。在这种情况下，只要我们有近似其梯度的方法，那么我们仍然可以使用迭代数值优化近似最小化目标。

## 一些看起来比较特殊的

尽管有时候不显然，但大多数学习算法都用到了上述配方。如果一个机器学习算法看上去特别独特或是手动设计的，那么通常需要使用特殊的优化方法进行求解。

有些模型，如决策树或 $k$-means，需要特殊的优化，因为它们的代价函数有平坦的区域，使其不适合通过基于梯度的优化去最小化。<span style="color:red;">决策树和 k-means 有什么特殊的优化吗？</span>

## 总结

在我们认识到大部分机器学习算法可以使用上述配方描述之后，我们可以将不同算法视为出于相同原因解决相关问题的一类方法，而不是一长串各个不同的算法。<span style="color:red;">是的，厉害</span>


# 相关

- 《深度学习》花书
