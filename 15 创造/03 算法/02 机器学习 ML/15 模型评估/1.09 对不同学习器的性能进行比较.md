---
title: 1.09 对不同学习器的性能进行比较
toc: true
date: 2018-07-30 16:05:55
---

# 可以补充进来的

- <span style="color:red;">为什么这几种假设检验方法之前从来没听说过？</span>

# 对不同学习器的性能进行比较

## 交叉验证 t 检验


对两个学习器 A 和 B ，若我们使用 k 折交叉验证法得到的测试错误率分 别为 $\epsilon_{1}^{A}, \epsilon_{2}^{A}, \ldots, \epsilon_{k}^{A}$ 和 $\epsilon_{1}^{B}, \epsilon_{2}^{B}, \ldots, \epsilon_{k}^{B}$ ，其中 $\epsilon_{i}^{A}$ 和 $\epsilon_{i}^{B}$ 是在相同的第 $i$ 折训练/测 试集上得到的结果，则可用 $k$ 折交叉验证“成对 t 检验” (paired t-teste)来进行 比较检验。这里的基本思想是若两个学习器的性能相同，则它们使用相同的训 练/测试集得到的测试错误率应相同，即 $\epsilon_{i}^{A}=\epsilon_{i}^{B}$ .

具体来说，对 $k$ 折交叉验证产生的 $k$ 对测试错误率：先对每对结果求差 $\Delta_{i}=\epsilon_{i}^{A}-\epsilon_{i}^{B}$ ， 若两个学习器性能相同，则差值均值应为零。因此，可根据差值 $\Delta_{1}, \Delta_{2}, \dots, \Delta_{k}$ , 来对“学习器 A 与 B 性能相同”这个假设做 t 检验，计算出差值的均值 $\mu$ 和方差 $\sigma^{2}$ ，在显著度 $\alpha$ 下，若变量

$$
\tau_{t}=\left|\frac{\sqrt{k} \mu}{\sigma}\right|
$$

小于临界值 $t_{\alpha / 2, k-1}$，则假设不能被拒绝，即认为两个学习器的性能没有显著差 别；否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习 器性能较优。这里 $t_{\alpha / 2, k-1}$ 是自由度为 $k-1$ 的 $t$ 分布上尾部累积分布为 $\alpha / 2$ 的临界值.<span style="color:red;">最后这句没明白。</span>

欲进行有效的假设检验，一个重要前提是测试错误率均为泛化错误率的独 立采样。然而，通常情况下由于样本有限，在使用交叉验证等实验估计方法时， 不同轮次的训练集会有一定程度的重叠，这就使禧测试错误率实际上并不独立， 会导致过高估计假设成立的概率。为缓解这一问题，可采用“ $5 \times 2$ 交叉验证”法[Dietterich，1998].

5x2交叉验证是做 5 次 2 折交叉验证，在每次 2 折交叉验证之前随机将数 据打乱，使得 5 次交叉验证中的数据划分不重复。对两个学习器 A 和 B，第 i 次 2折交叉验证将产生两对测试错误率，我们对它们分别求差，得到第 1 折上的差 值 $\Delta_{i}^{1}$ 和第 2 折上的差值 $\Delta_{i}^{2}$ 。为缓解测试错误率的非独立性，我们仅计算第 1 次 2 折交叉验证的两个结果的平均值 $\mu=0.5\left(\Delta_{1}^{1}+\Delta_{1}^{2}\right)$ ，但对每次 2 折实验的 结果都计算出其方差 $\sigma_{i}^{2}=\left(\Delta_{i}^{1}-\frac{\Delta_{i}^{1}+\Delta_{i}^{2}}{2}\right)^{2}+\left(\Delta_{i}^{2}-\frac{\Delta_{i}^{1}+\Delta_{i}^{2}}{2}\right)^{2}$ 。 变量

$$
\tau_{t}=\frac{\mu}{\sqrt{0.2 \sum_{i=1}^{5} \sigma_{i}^{2}}}\tag{2.32}
$$

服从自由度为 5 的 t 分布，其双边检验的临界值 $t_{\alpha / 2,5}$ 当 $\alpha=0.05$ 时为 2.5706, $\alpha=0.1$ 时为 2.0150.

## McNemar 检验

对二分类问题，使用留出法不仅可估计出学习器 A 和 B 的测试错误率，还可获得两学习器分类结果的差别，即两者都正确、都错误、一个正确另一个错 误的样本数，如“列联表” (contingency table) 2.4所示.

<center>

![](http://images.iterate.site/blog/image/20190705/SrR0yztU5B8u.png?imageslim){ width=55% }

</center>


若我们做的假设是两学习器性能相同，则应有 $e_{01}=e_{10}$ ，那么变量 $\left|e_{01}-e_{10}\right|$ 应当服从正态分布，且均值为 1，方差为 $e_{01}+e_{10}$ 。因此变量

$$
\tau_{\chi^{2}}=\frac{\left(\left|e_{01}-e_{10}\right|-1\right)^{2}}{e_{01}+e_{10}}\tag{2.33}
$$

> 中文称为卡方分布.
> 临界值 $\chi_{\alpha}^{2}$ 在 R 语 言中可通过 `qchisq(l — a, fc—1)` 计算，在 Matlab 中 是 `icdf ('Chisquare',1 — a,k — 1)`。这里的 k = 2 是进行比较的算法个数.

服从自由度为 $1$ 的 $\chi^{2}$ 分布，即标准正态分布变量的平方。给定显著度 $\alpha$，当以 上变量值小于临界值 $\chi_{\alpha}^{2}$ 时，不能拒绝假设，即认为两学习器的性能没有显著差 别；否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习 器性能较优。自由度为 1 的 $\chi^{2}$ 检验的临界值当 $\alpha=0.05$ 时为 3.8415, $\alpha=0.1$ 时为 2.7055.

## Friedman 检验 与 Nemenyi 后续检验

交叉验证 t 检验和 McNemar 检验都是在一个数据集上比较两个算法的 性能，而在很多时候，我们会在一组数据集上对多个算法进行比较。当有多个 算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，而在 两两比较时可使用前述方法；另一种方法更为直接，即使用基于算法排序的 Friedman 检验.

假定我们用 $D_{1}, D_{2}, D_{3},D_{4}$ 四个数据集对算法 A、B、C 进行比较. 首先，使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏排序，并赋予序值 $1,2, \dots$ ，若算法的 测试性能相同，则平分序值。例如，在 $D_{1}$ 和 $D_{3}$ 上，A最好、B其次、C最差， 而在 $D_{2}$ 上，A最好、B与 C 性能相同，……，则可列出表 2.5，其中最后一行通过对每一列的序值求平均，得到平均序值.

<center>

![](http://images.iterate.site/blog/image/20190705/1SRymxfb6uky.png?imageslim){ width=55% }

</center>


然后，使用 Friedman 检验来判断这些算法是否性能都相同。若相同，则它 们的平均序值应当相同。假定我们在 $N$ 个数据集上比较 $k$ 个算法，令 $r_{i}$ 表示第 $i$ 个算法的平均序值，为简化讨论，暂不考虑平分序值的情况，则 $\boldsymbol{r}_{i}$ 服从正态分 布，其均值和方差分别为 $(k+1) / 2$ 和 $\left(k^{2}-1\right) / 12$.<span style="color:red;">为什么是服从这个正态分布？</span>

变量

$$
\begin{aligned}
\tau_{\chi^{2}}&=\frac{k-1}{k} \cdot \frac{12 N}{k^{2}-1} \sum_{i=1}^{k}\left(r_{i}-\frac{k+1}{2}\right)^{2}\\&=\frac{12 N}{k(k+1)}\left(\sum_{i=1}^{k} r_{i}^{2}-\frac{k(k+1)^{2}}{4}\right)
\end{aligned}\tag{2.34}
$$


在 $k$ 和 $N$ 都较大时，服从自由度为 $k-1$ 的 $\chi^{2}$ 分布.

然而，上述这样的“原始 Friedman 检验”过于保守，现在通常使用变量

$$
\tau_{F}=\frac{(N-1) \tau_{\chi^{2}}}{N(k-1)-\tau_{\chi^{2}}}\tag{2.35}
$$

其中 $\tau_{\chi^{2}}$ 由式(2.34)得到. $\tau_{F}$ 服从自由度为 $k-1$ 和 $(k-1)(N-1)$ 的 $F$ 分布。表 2.6给出了一些常用临界值.

<center>

![](http://images.iterate.site/blog/image/20190705/GrIAvLp1RUAe.png?imageslim){ width=55% }

</center>


若 “所有算法的性能相同” 这个假设被拒绝，则说明算法的性能显著不 同。这时需进行“后续检验”(post-hoc test)来进一步区分各算法。常用的有 Nemenyi后续检验.

Nemenyi检验计算出平均序值差别的临界值域

$$
C D=q_{\alpha} \sqrt{\frac{k(k+1)}{6 N}}\tag{2.36}
$$

> $q_{\alpha}$ 是 Tukey 分布的临 界值。

表 2.7给出了 $\alpha=0.05$ 和 0.1时常用的 $q_{\alpha}$ 值。若两个算法的平均序值之差超出了临界值域 CD，则以相应的置信度拒绝“两个算法性能相同”这一假设.

<center>

![](http://images.iterate.site/blog/image/20190705/EwNU8ac9sgbM.png?imageslim){ width=55% }

</center>


以表 2.5中的数据为例，先根据式(2.34)和(2.35)计算出 $\tau_{F}=24.429$ ，由表 2.6可知，它大于 $\alpha=0.05$ 时的 $F$ 检验临界值 5.143，因此拒绝“所有算法性 能相同”这个假设.

然后使用 Nemenyi 后续检验，在表 2.7中找到 $k=3$ 时 $q_{0.05}=2.344$ ，根据式(2.36)计算出临界值域 $C D=1.657$ ，由表 2.5中的平均序值可知，算法 A 与 B 的差距，以及算法 B 与 C 的差距均未超过临界值域，而算 法 A 与 C 的差距超过临界值域，因此检验结果认为算法 A 与 C 的性能显著不同，而算法 A 与 B、以及算法 B 与 C 的性能没有显著差别.

上述检验比较可以直观地用 Friedman 检验图显示。例如根据表 2.5的序 值结果可绘制出图 2.8，图中纵轴显示各个算法，横轴是平均序值。对每个算法， 用一个圆点显示其平均序值，以圆点为中心的横线段表示临界值域的大小。然 后就可从图中观察，若两个算法的横线段有交叠，则说明这两个算法没有显著 差别，否则即说明有显著差别。从图 2.8中可容易地看出，算法 A 与 B 没有显著 差别，因为它们的横线段有交叠区域，而算法 A 显著优于算法 C，因为它们的 横线段没有交叠区域.

<center>

![](http://images.iterate.site/blog/image/20190705/XtR00i9MWcsu.png?imageslim){ width=55% }

</center>







# 相关

- 《机器学习》周志华
