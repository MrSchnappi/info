---
title: 2.17 ROC 与 AUC
toc: true
date: 2019-03-27
---


# ROC 与 AUC

<span style="color:red;">还是没明白，结合别的资料仔细看下，要弄明白</span>

很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值 (threshold) 进行比较，如果大于阈值则分为正类，否则为反类。

例如：神经网络在一般情形下是对每个测试样本预测出一个 `[0.0,1.0]` 之间的实值， 然后将这个值与 `0.5` 进行比较，大于 `0.5` 则判为正例，否则为反例。这个实值或概率预测结果的好坏，直接决定了学习器的泛化能力。

实际上，根据这个实值或概率预测结果，我们可以将测试样本进行排序，“最可能” 是正例的排在最前面， “最不可能” 是正例的排在最后面。这样，分类过程就相当于在这个排序中以某个 “截断点” (cut point) 将样本分为两部分，前一部分判作正例，后一部分则判作反例。<span style="color:red;">是的。</span> 在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若我们更重视 “查准率”，则可选择排序中靠前的位置进行截断；若更重视 “查全率”，则可选择靠后的位置进行截断。<span style="color:red;">有些厉害。没明白，这个截断点不是应该我们自己固定的吗？</span>

因此，排序本身的质量好坏，体现了综合考虑学习器在不同任务下的 “期望泛化性能” 的好坏，或者说，“一般情况下” 泛化性能的好坏。<span style="color:red;">嗯，但是这个排序本身的质量好坏只与模型本身有关吧？</span>

`ROC` 曲线则是从这个角度出发来研究学习器泛化性能 的有力工具。 ROC 全称是 “受试者工作特征” (Receiver Operating Characteristic) 曲线，它源于二战中用于敌机检测的雷达信号分析技术，二十世纪六七十年代开始被用于一些心理学、医学检测应用中，此后被引入机器学习领域。

`P-R` 曲线相似，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、级坐标作图，就得到了 “ROC曲线”。<span style="color:red;">什么叫逐个把样本作为正例进行预测？两个重要量的值是什么？</span>

与`P-R`曲线使用查准率、查全率为纵、横轴不同，ROC 曲线的纵轴是 “真正例率” (True Positive Rate，简称 TPR)，横轴是 “假正例率” (False Positive Rate，简称 FPR)，两者定义如下：
$$
\mathrm{TPR}=\frac{T P}{T P+F N}
$$
$$
\mathrm{FPR}=\frac{F P}{T N+F P}
$$

`ROC` 曲线的图称为 “ROC图” ，下图为 `ROC` 曲线与 `AUC` 示意图：


<center>

![](http://images.iterate.site/blog/image/180713/bej8fCgEHf.png?imageslim){ width=55% }

</center>

显然， 对角线对应于 “随机猜测” 模型，而点 `(0, 1)` 则对应于将所有正例排在所有反例之前的 “理想模型”。<span style="color:red;">没看懂。而且，一直没明白，为什么这个 ROC 是一个曲线？这个曲线怎么得到的？</span>

现实任务中通常是利用有限个测试样例来绘制 ROC 图，此时仅能获得有限个(真正例率，假正例率)坐标对，无法产生上图 (a) 中的光滑 ROC 曲线，只能 绘制出如上图 (b) 中所示的近似 ROC 曲线。绘图过程很简单：给定 $m^+$ 个正例和 $m^-$ 个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大， 即把所有样例均预测为反例，此时真正例率和假正例率均为 `0`，在坐标 `(0,0)` 处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为 $(x,y)$，当前若为真正例，则对应标记点的坐标为 $(x,y+\frac{1}{m^+})$ ，当前若为假正例，则对应标记点的坐标为 $(x+\frac{1}{m^-},y)$  ，然后用线段连接相邻点即得。

进行学习器的比较时，与 P-R 图相似，：

* 若一个学习器的 ROC 曲线被另一 个学习器的曲线完全 “包住”，则可断言后者的性能优于前者；
* 若两个学习器 的 ROC 曲线发生交叉，则难以一般性地断言两者孰优孰劣，此时如果一定要进行比较，则较为合理的判据是比较 ROC 曲线下的面积，即 AUC (Area Under ROC Curve)。


从定义可知，AUC可通过对 ROC 曲线下各部分的面积求和而得。假定 ROC 曲线是由坐标为 $\{(x_1,y_1),(x_2,y_2),\cdots ,(x_m,y_m)\}$ 的点按序连接而形成 $(x_1=0,x_m=1)$ ，则 AUC 可估算为

$$
AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot (y_i+y_{i+1})
$$


> [解析]：由于图 2.4(b)中给出的 ROC 曲线为横平竖直的标准折线，所以乍一看这个式子的时候很不理解其中的 $ \cfrac{1}{2} $ 和 $ (y_i + y_{i+1}) $ 代表着什么，因为对于横平竖直的标准折线用 $ AUC=\sum_{i=1}^{m-1}(x_{i+1} - x_i) \cdot y_i $ 就可以求出 AUC 了，但是图 2.4(b)中的 ROC 曲线只是个特例罢了，因为此图是所有样例的预测值均不相同时的情形，也就是说每次分类阈值变化的时候只会划分新增**1个**样例为正例，所以下一个点的坐标为 $ (x+\cfrac{1}{m^-},y) $ 或 $ (x,y+\cfrac{1}{m^+}) $，然而当模型对某个正样例和某个反样例给出的预测值相同时，便会划分新增**两个**样例为正例，于是其中一个分类正确一个分类错误，那么下一个点的坐标为 $ (x+\cfrac{1}{m^-},y+\cfrac{1}{m^+}) $（当没有预测值相同的样例时，若采取按固定梯度改变分类阈值，也会出现一下划分新增两个甚至多个正例的情形，但是此种阈值选取方案画出的 ROC 曲线 AUC 值更小，不建议使用），此时 ROC 曲线中便会出现斜线，而不再是只有横平竖直的折线，所以用**梯形面积公式**就能完美兼容这两种分类阈值选取方案，也即 **(上底+下底)\*高\*$ \cfrac{1}{2} $**


形式化地看，AUC 考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定 $m^+$ 个正例和 $m^-$ 个反例，令 $D^+$ 和 $D^-$ 分别表示正、反例集合，则排序 “损失” (loss) 定义为：

$$
\ell_{r a n k}=\frac{1}{m^{+} m^{-}} \sum_{\boldsymbol{x}^{+} \in D^{+}} \sum_{\boldsymbol{x}^{-} \in D^{-}}\left(\mathbb{I}\left(f\left(\boldsymbol{x}^{+}\right)<f\left(\boldsymbol{x}^{-}\right)\right)+\frac{1}{2} \mathbb{I}\left(f\left(\boldsymbol{x}^{+}\right)=f\left(\boldsymbol{x}^{-}\right)\right)\right)
$$


> **解析**：
>
> 此公式正如书上所说，$ l_{rank} $ 为 ROC 曲线**之上**的面积，假设某 ROC 曲线如下图所示：
>
> ![](http://images.iterate.site/blog/image/20190709/x7akiJoQwoQf.png?imageslim){ width=55% }
>
> 观察 ROC 曲线易知：
>
> - 每增加一条绿色线段对应着有**1个**正样例（$ x^+_i $）被模型正确判别为正例，且该线段在 Y 轴的投影长度恒为 $ \cfrac{1}{m^+} $；
> - 每增加一条红色线段对应着有**1个**反样例（$ x^-_i $）被模型错误判别为正例，且该线段在 X 轴的投影长度恒为 $ \cfrac{1}{m^-} $；
> - 每增加一条蓝色线段对应着有 a 个正样例和 b 个反样例**同时**被判别为正例，且该线段在 X 轴上的投影长度=$ b * \cfrac{1}{m^-} $，在 Y 轴上的投影长度=$ a * \cfrac{1}{m^+} $；
> - 任何一条线段所对应的样例的预测值一定**小于**其左边和下边的线段所对应的样例的预测值，其中蓝色线段所对应的 a+b个样例的预测值相等。
>
> 公式里的 $ \sum_{x^+ \in D^+} $ 可以看成一个遍历 $ x^+_i $ 的循环：
>
> for $ x^+_i $ in $ D^+ $:
>
> 　　　　$ \cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}(\mathbb{I}(f(x^+_i)<f(x^-))+\cfrac{1}{2}\mathbb{I}(f(x^+_i)=f(x^-)))$ #记为式 S
>
> 由于每个 $ x^+_i $ 都对应着一条绿色或蓝色线段，所以遍历 $ x^+_i $ 可以看成是在遍历每条绿色和蓝色线段，并用式 S 来求出每条绿色线段与 Y 轴构成的面积（例如上图中的 m1)或者蓝色线段与 Y 轴构成的面积（例如上图中的 m2+m3）。
>
> **对于每条绿色线段：** 将其式 S 展开可得：
> $$ \cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\mathbb{I}(f(x^+_i)<f(x^-))+\cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\cfrac{1}{2}\mathbb{I}(f(x^+_i)=f(x^-)) $$ 其中 $ x^+_i $ 此时恒为该线段所对应的正样例，是一个定值。$ \sum_{x^- \in D^-}\cfrac{1}{2}\mathbb{I}(f(x^+_i)=f(x^-) $ 是在通过遍历所有反样例来统计和 $ x^+_i $ 的预测值相等的反样例个数，由于没有反样例的预测值和 $ x^+_i $ 的预测值相等，所以 $ \sum_{x^- \in D^-}\cfrac{1}{2}\mathbb{I}(f(x^+_i)=f(x^-)) $ 此时恒为 0，于是其式 S 可以化简为：$$ \cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\mathbb{I}(f(x^+_i)<f(x^-)) $$ 其中 $ \cfrac{1}{m^+} $ 为该线段在 Y 轴上的投影长度，$ \sum_{x^- \in D^-}\mathbb{I}(f(x^+_i)<f(x^-)) $ 同理是在通过遍历所有反样例来统计预测值大于 $ x^+_i $ 的预测值的反样例个数，也即该线段左边和下边的红色线段个数+蓝色线段对应的反样例个数，所以 $ \cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}(\mathbb{I}(f(x^+)<f(x^-))) $ 便是该线段左边和下边的红色线段在 X 轴的投影长度+蓝色线段在 X 轴的投影长度，也就是该绿色线段在 X 轴的投影长度，观察 ROC 图像易知绿色线段与 Y 轴围成的面积=该线段在 Y 轴的投影长度 * 该线段在 X 轴的投影长度。
>
> **对于每条蓝色线段：** 将其式 S 展开可得：
> $$ \cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\mathbb{I}(f(x^+_i)<f(x^-))+\cfrac{1}{m^+}\cdot\cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\cfrac{1}{2}\mathbb{I}(f(x^+_i)=f(x^-)) $$
> 其中前半部分表示的是蓝色线段和 Y 轴围成的图形里面矩形部分的面积，后半部分表示的便是剩下的三角形的面积，矩形部分的面积公式同绿色线段的面积公式一样很好理解，而三角形部分的面积公式里面的 $ \cfrac{1}{m^+} $ 为底边长，$ \cfrac{1}{m^-}\cdot\sum_{x^- \in D^-}\mathbb{I}(f(x^+_i)=f(x^-)) $ 为高。
>
> 综上分析可知，式 S 既可以用来求绿色线段与 Y 轴构成的面积也能求蓝色线段与 Y 轴构成的面积，所以遍历完所有绿色和蓝色线段并将其与 Y 轴构成的面积累加起来即得 $ l_{rank} $。


即考虑每一对正、反例，若正例的预测值小于反例，则记一个 “罚分” ，若相 等，则记 `0.5` 个 “罚分”。容易看出，$\mathcal{l}_{rank}$ 对应的是 ROC 曲线之上的面积：若 一个正例在 ROC 曲线上对应标记点的坐标为 $(x,y)$ ，则 x 恰是排序在其之前的反例所占的比例，即假正例率。因此有：

$$
\mathrm{AUC}=1-\ell_{\text {rank}}
$$







# ROC 曲线

二值分类器（Binary Classifier）是机器学习领域中最常见也是应用最广泛的分类器。评价二值分类器的指标很多，比如 precision、recall、F1 score、P-R 曲线等。这些指标或多或少只能反映模型在某一方面的性能。

相比而言，ROC 曲线则有很多优点，经常作为评估二值分类器最重要的指标之一。下面我们来详细了解一下 ROC 曲线的绘制方法和特点。<span style="color:red;">是二值分类器最重要的指标之一吗？</span>


## 什么是 ROC 曲线？

ROC曲线是 Receiver Operating Characteristic Curve 的简称，中文名为“受试者工作特征曲线”。

ROC曲线的：

- 横坐标为假阳性率（False Positive Rate，FPR）；
- 纵坐标为真阳性率（True Positive Rate，TPR）。

FPR 和 TPR 的计算方法分别为：

$$FPR=\frac{FP}{N}$$
$$TPR=\frac{TP}{P}$$

上式中，P是真实的正样本的数量，N是真实的负样本的数量，TP是 P 个正样本中被分类器预测为正样本的个数，FP是 N 个负样本中被分类器预测为正样本的个数。


只看定义确实有点绕，为了更直观地说明这个问题，我们举一个医院诊断病人的例子。假设有 10 位疑似癌症患者，其中有 3 位很不幸确实患了癌症（P=3），另外 7 位不是癌症患者（N=7）。医院对这 10 位疑似患者做了诊断，诊断出 3 位癌症患者，其中有 2 位确实是真正的患者（TP=2）。那么真阳性率 TPR=TP/P=2/3。对于 7 位非癌症患者来说，有一位很不幸被误诊为癌症患者（FP=1），那么假阳性率 FPR=FP/N=1/7。

对于“该医院”这个分类器来说，这组分类结果就对应 ROC 曲线上的一个点（1/7，2/3）。<span style="color:red;">嗯。</span>


## 如何绘制 ROC 曲线？


事实上，ROC曲线是通过不断移动分类器的“截断点”来生成曲线上的一组关键点的，通过下面的例子进一步来解释“截断点”的概念。

在二值分类问题中，模型的输出一般都是预测样本为正例的概率。假设测试集中有 20 个样本，表 2.1是模型的输出结果。样本按照预测概率从高到低排序。在输出最终的正例、负例之前，我们需要指定一个阈值，预测概率大于该阈值的样本会被判为正例，小于该阈值的样本则会被判为负例。比如，指定阈值为 0.9，那么只有第一个样本会被预测为正例，其他全部都是负例。

上面所说的“截断点”指的就是区分正负预测结果的阈值。<span style="color:red;">是的。</span>

![mark](http://images.iterate.site/blog/image/20190826/spMbqbWxiUhK.png?imageslim)

通过动态地调整截断点，从最高的得分开始（实际上是从正无穷开始，对应着 ROC 曲线的零点），逐渐调整到最低得分，每一个截断点都会对应一个 FPR 和 TPR，在 ROC 图上绘制出每个截断点对应的位置，再连接所有点就得到最终的 ROC 曲线。<span style="color:red;">是的。但是这个地方有个疑问，这个阈值通常来说不是固定的吗？为什么要弄一个动态的过程？</span>


就本例来说，当截断点选择为正无穷时，模型把全部样本预测为负例，那么 FP 和 TP 必然都为 0，FPR和 TPR 也都为 0，因此曲线的第一个点的坐标就是（0，0）。当把截断点调整为 0.9时，模型预测 1 号样本为正样本，并且该样本确实是正样本，因此，TP=1，20个样本中，所有正例数量为 P=10，故 TPR=TP/P=1/10；这里没有预测错的正样本，即 FP=0，负样本总数 N=10，故 FPR=FP/N=0/10=0，对应 ROC 曲线上的点（0，0.1）。依次调整截断点，直到画出全部的关键点，再连接关键点即得到最终的 ROC 曲线。<span style="color:red;">是的。</span>

ROC 曲线如图所示：

![](http://images.iterate.site/blog/image/20190327/MfiXoxufEfof.png?imageslim){ width=55% }

其实，还有一种更直观地绘制 ROC 曲线的方法。首先，根据样本标签统计出正负样本的数量，假设正样本数量为 P，负样本数量为 N；接下来，把横轴的刻度间隔设置为 1/N，纵轴的刻度间隔设置为 1/P；再根据模型输出的预测概率对样本进行排序（从高到低）；依次遍历样本，同时从零点开始绘制 ROC 曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在（1，1）这个点，整个 ROC 曲线绘制完成。<span style="color:red;">是的，这个也挺好。</span>


## 如何计算 AUC？

顾名思义，AUC指的是 ROC 曲线下的面积大小，该值能够量化地反映基于 ROC 曲线衡量出的模型性能。计算 AUC 值只需要沿着 ROC 横轴做积分就可以了。由于 ROC 曲线一般都处于 y=x这条直线的上方（如果不是的话，只要把模型预测的概率反转成 1−p就可以得到一个更好的分类器 <span style="color:red;">什么是模型预测的概率反转？</span>），所以 AUC 的取值一般在 0.5～1之间。AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。<span style="color:red;">嗯，之前关于这个地方一直有点疑问，为什么这个动态的阈值画出来的线的面积可以说明分类性能的好坏呢？嗯，现在看来的确，因为这个面积越大，说明真正的正样本是排在最前面的，也就是说对于样本的预测概率的排序越贴近真实的样本标签。厉害了。</span>


## 为什么使用 ROC 和 AUC 评价分类器

模型有很多评估方法，为什么还要使用 ROC 和 AUC 呢？

因为 ROC 曲线有个很好的特性：

- 当测试集中的正负样本的分布变换的时候，ROC 曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。<span style="color:red;">是的，正负样本均衡性发生变化的时候，ROC 曲线保持不变。嗯，之前看的百面机器学习书中有随着分布发生变化的指标。</span>

## ROC曲线的由来

ROC 曲线最早是运用在军事上的，后来逐渐运用到医学领域，并于 20 世纪 80 年代后期被引入机器学习领域。

相传在第二次世界大战期间，雷达兵的任务之一就是死死地盯住雷达显示器，观察是否有敌机来袭。理论上讲，只要有敌机来袭，雷达屏幕上就会出现相应的信号。但是实际上，如果飞鸟出现在雷达扫描区域时，雷达屏幕上有时也会出现信号。

这种情况令雷达兵烦恼不已，如果过于谨慎，凡是有信号就确定为敌机来袭，显然会增加误报风险；如果过于大胆，凡是信号都认为是飞鸟，又会增加漏报的风险。每个雷达兵都竭尽所能地研究飞鸟信号和飞机信号之间的区别，以便增加预报的准确性。但问题在于，每个雷达兵都有自己的判别标准，有的雷达兵比较谨慎，容易出现误报；有的雷达兵则比较胆大，容易出现漏报。

为了研究每个雷达兵预报的准确性，雷达兵的管理者汇总了所有雷达兵的预报特点，特别是他们漏报和误报的概率，并将这些概率画到一个二维坐标系里。这个二维坐标的纵坐标为敏感性（真阳性率），即在所有敌机来袭的事件中，每个雷达兵准确预报的概率。而横坐标则为 1-特异性（假阳性率），表示在所有非敌机来袭信号中，雷达兵预报错误的概率。由于每个雷达兵的预报标准不同，且得到的敏感性和特异性的组合也不同。将这些雷达兵的预报性能进行汇总后，雷达兵管理员发现他们刚好在一条曲线上，这条曲线就是后来被广泛应用在医疗和机器学习领域的 ROC 曲线。<span style="color:red;">有些厉害。</span>




# 相关

- 《百面机器学习》
