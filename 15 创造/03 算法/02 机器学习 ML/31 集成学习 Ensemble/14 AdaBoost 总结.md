---
title: 14 AdaBoost 总结
toc: true
date: 2019-08-27
---

# AdaBoost 开发过程中要注意的


AdaBoost 算法中的弱分类器要很弱效果才好，比如单层的决策树，单层的决策树可以处理任何数据类型。 当然也可以使用任意分类器作为弱分类器，比如 KNN、Decision Tree、Naive Bayes、SVM、LogisticRegression 等。** 都要尝试一下。**

AdaBoost 的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。

同 SVM 一样，AdaBoost 预测两个类别中的一个。如果想把它应用到多个类别的场景，那么就要像多类 SVM 中的做法一样对 AdaBoost 进行修改。**嗯，到底要怎么修改？**


# AdaBoost 算法特点


优点：

- 泛化（由具体的、个别的扩大为一般的）错误率低，
- 易编码  **什么是易编码？**
- 可以应用在大部分分类器上，
- 无参数调节。**没有参数调节吗？**


缺点：

- 对离群点敏感。**为什么对离群点敏感？**

适用数据类型：

- 数值型和标称型数据。



AdaBoost确实采用的是指数损失，基分类器最常见的是决策树（在很多情况下是决策树桩，深度为 1 的决策树）。在每一轮提升相应错分类点的权重可以被理解为调整错分类点的 observation probability。**没明白？**





# 相关

- 七月在线 机器学习
- [机器学习算法中 GBDT 与 Adaboost 的区别与联系是什么？](https://www.zhihu.com/question/54626685)
