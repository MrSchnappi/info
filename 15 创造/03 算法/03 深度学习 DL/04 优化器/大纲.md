---
title: 大纲
toc: true
date: 2019-04-07
---
# 优化算法

自适应学习率的方法仔细总结下。

优化是机器学习的核心组成部分。

实际上，机器学习算法 = 模型表征 + 模型评估 + 优化算法。

其中，优化算法所做的事情就是在模型表征空间中找到模型评估指标最好的模型。

不同的优化算法对应的模型表征和评估指标不尽相同，比如经典的支持向量机对应的模型表征和评估指标分别为线性分类模型和最大间隔，逻辑回归对应的模型表征和评估指标则分别为线性分类模型和交叉熵。

随着大数据和深度学习的迅猛发展，在实际应用中面临的大多是大规模、高度非凸的优化问题，这给传统的基于全量数据、凸优化的优化理论带来了巨大的挑战。

如何设计适用于新场景的、高效的、准确的优化算法成为近年来的研究热点。优化虽然是一门古老的学科，但是大部分能够用于训练深度神经网络的优化算法都是近几年才被提出，如 Adam 算法等。<span style="color:red;">嗯嗯，想看下这些是怎么做到找到最优的结果的。</span>

虽然，目前大部分机器学习的工具已经内置了常用的优化算法，实际应用时只需要一行代码即可完成调用。但是，鉴于优化算法在机器学习中的重要作用，了解优化算法的原理也很有必要。


## 主要内容

- 损失函数
- 解法-凸优化
- 无约束问题的优化方法
- 梯度下降法

## 需要消化的


- [学界 | 清华大学NIPS 2017 Spotlight论文：通过在单纯形上软门限投影的加速随机贪心坐标下降](http://www.sohu.com/a/192570193_465975)



- [深度学习优化器总结]

## 可以补充进来的


- BFGS
