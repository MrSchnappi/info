---
title: 31 行列式
toc: true
date: 2019-05-07
---
# 可以补充进来的

- 感觉没有很懂，补充下。
- 补充的时候注意，这个不是 alpha 版本的 pdf 的，是发行后的，公式编号要对应。

# 行列式

行列式，记作 $\operatorname{det}(\boldsymbol{A})$，是一个将方阵 $\boldsymbol{A}$ 映射到实数的函数。<span style="color:red;">什么叫把矩阵映射到实数？嗯，还别说，好像是这样的。</span>


行列式等于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果行列式是 $0$ ，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积；如果行列式是 $1$，那么这个转换保持空间体积不变。<span style="color:red;">这一段没有怎么理解。</span>


## 实例：主成分分析

主成分分析 (principal components analysis,PCA) 是一个简单的机器学习算法，可以通过基础的线性代数知识推导。

假设在 $\mathbb{R}^{n}$ 空间中有 $m$ 个点 $\left\{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)}\right\}$ ，我们希望对这些点进行有损压缩。有损压缩表示我们使用更少的内存，但损失一些精度去存储这些点。我们希望损失的精度尽可能少。<span style="color:red;">嗯。</span>

编码这些点的一种方式是用低维表示。对于每个点 $\boldsymbol{x}^{(i)} \in \mathbb{R}^{n}$ ，会有一个对应的编码向量 $\boldsymbol{c}^{(i)} \in \mathbb{R}^{l}$ 。如果 $l$ 比 $n$ 小，那么我们便使用了更少的内存来存储原来的数据。<span style="color:red;">是的。</span>我们希望找到一个编码函数，根据输入返回编码，$f(\boldsymbol{x})=\boldsymbol{c}$ ；我们也希望找到一个解码函数，给定编码重构输入，$\boldsymbol{x} \approx g(f(\boldsymbol{x}))$。<span style="color:red;">是的，说的很清晰，赞！</span>

PCA 由我们选择的解码函数而定。具体来讲，为了简化解码器，我们使用矩阵乘法将编码映射回 $\mathbb{R}^{n}$，即 $g(\boldsymbol{c})=\boldsymbol{D} \boldsymbol{c}$，其中 $\boldsymbol{D} \in \mathbb{R}^{n \times l}$ 是定义解码的矩阵。<span style="color:red;">嗯，挺有意思的。</span>


到目前为止，所描述的问题可能会有多个解。因为如果我们按比例地缩小所有点对应的编码向量 $c_{i}$，那么只需按比例放大 $\boldsymbol{D}_{ :, i}$，即可保持结果不变。为了使问题有唯一解，我们限制 $\boldsymbol{D}$ 中所有列向量都有单位范数。<span style="color:red;">嗯，所有列向量都有单位范数，嗯。</span>

计算这个解码器的最优编码可能是一个困难的问题。为了使编码问题简单一些，PCA 限制 $\boldsymbol{D}$ 的列向量彼此正交(注意，除非 $l=n$ ，否则严格意义上 $\boldsymbol{D}$ 不是一个正交矩阵)。<span style="color:red;">嗯。</span>

为了将这个基本想法变为我们能够实现的算法，首先我们需要明确如何根据每一个输入 $\boldsymbol{x}$ 得到一个最优编码 $\boldsymbol{c}*$ 。一种方法是最小化原始输入向量 $\boldsymbol{x}$ 和重构向量 $g(\boldsymbol{c}*)$ 之间的距离。我们使用范数来衡量它们之间的距离。在 PCA 算法中，我们使用 $L^{2}$ 范数：<span style="color:red;">嗯，为什么是用的 $L^{2}$ 范数？有用别的范数的吗？</span>

$$
\boldsymbol{c}^{*}=\underset{c}{\arg \min }\|\boldsymbol{x}-g(\boldsymbol{c})\|_{2}\tag{2.54}
$$

我们可以用平方 $L^{2}$ 范数替代 $L^{2}$ 范数，因为两者在相同的值 $\boldsymbol{c}$ 上取得最小值。这是因为 $L^{2}$ 范数是非负的，并且平方运算在非负值上是单调递增的。<span style="color:red;">没想到在这个地方用到了平方 $L^{2}$ 范数。嗯。</span>

$$
\boldsymbol{c}^{*}=\arg \min _{\boldsymbol{c}}\|\boldsymbol{x}-g(\boldsymbol{c})\|_{2}^{2}\tag{2.55}
$$


该最小化函数可以简化成：

$$
(\boldsymbol{x}-g(\boldsymbol{c}))^{\top}(\boldsymbol{x}-g(\boldsymbol{c}))\tag{2.56}
$$


(式(2.30)中 $L^{2}$ 范数的定义)

$$
=\boldsymbol{x}^{\top} \boldsymbol{x}-\boldsymbol{x}^{\top} g(\boldsymbol{c})-g(\boldsymbol{c})^{\top} \boldsymbol{x}+g(\boldsymbol{c})^{\top} g(\boldsymbol{c})\tag{2.57}
$$


(分配律)

$$
=\boldsymbol{x}^{\top} \boldsymbol{x}-2 \boldsymbol{x}^{\top} g(\boldsymbol{c})+g(\boldsymbol{c})^{\top} g(\boldsymbol{c})\tag{2.58}
$$


(因为标量 $g(\boldsymbol{c})^{\top} \boldsymbol{x}$ 的转置等于自己)。

因为第一项 $\boldsymbol{x}^{\top} \boldsymbol{x}$ 不依赖于 $\boldsymbol{c}$，所以我们可以忽略它，得到如下的优化目标：

$$
\boldsymbol{c}^{*}=\underset{c}{\arg \min }-2 \boldsymbol{x}^{\top} g(\boldsymbol{c})+g(\boldsymbol{c})^{\top} g(\boldsymbol{c})\tag{2.59}
$$

更进一步，代入 $g(\boldsymbol{c})$ 的定义：

$$
\boldsymbol{c}^{*}=\underset{c}{\arg \min }-2 \boldsymbol{x}^{\top} \boldsymbol{D} \boldsymbol{c}+\boldsymbol{c}^{\top} \boldsymbol{D}^{\top} \boldsymbol{D} \boldsymbol{c}\tag{2.60}
$$

$$
=\underset{c}{\arg \min }-2 \boldsymbol{x}^{\top} \boldsymbol{D} \boldsymbol{c}+\boldsymbol{c}^{\top} \boldsymbol{I}_{l} \boldsymbol{c}\tag{2.61}
$$

(矩阵 $\boldsymbol{D}$ 的正交性和单位范数约束)

$$
=\underset{c}{\arg \min }-2 \boldsymbol{x}^{\top} \boldsymbol{D} \boldsymbol{c}+\boldsymbol{c}^{\top} \boldsymbol{c}\tag{2.62}
$$

我们可以通过向量微积分来求解这个最优化问题(如果你不清楚怎么做，请参考第 4.3节)。

$$
\nabla_{c}\left(-2 \boldsymbol{x}^{\top} \boldsymbol{D} \boldsymbol{c}+\boldsymbol{c}^{\top} \boldsymbol{c}\right)=0\tag{2.63}
$$

$$
-2 \boldsymbol{D}^{\top} \boldsymbol{x}+2 \boldsymbol{c}=0\tag{2.64}
$$

$$
\boldsymbol{c}=\boldsymbol{D}^{\top} \boldsymbol{x}\tag{2.65}
$$


这使得算法很高效：最优编码 $\boldsymbol{x}$ 只需要一个矩阵-向量乘法操作。为了编码向量，我们使用编码函数：

$$
f(\boldsymbol{x})=\boldsymbol{D}^{\top} \boldsymbol{x}
$$

进一步使用矩阵乘法，我们也可以定义 PCA 重构操作：

$$
r(\boldsymbol{x})=g(f(\boldsymbol{x}))=\boldsymbol{D} \boldsymbol{D}^{\top} \boldsymbol{x}
$$


接下来，我们需要挑选编码矩阵 $\boldsymbol{D}$ 。要做到这一点，先来回顾最小化输入和重构之间 $L^2$ 距离的这个想法。因为用相同的矩阵 $\boldsymbol{D}$ 对所有点进行解码，我们不能再孤立地看待每个点。反之，我们必须最小化所有维数和所有点上的误差矩阵的 Frobenius 范数：<span style="color:red;">最小化所有维数和所有点上的误差矩阵的 Frobenius 范数。</span>

$$
\boldsymbol{D}^{*}=\underset{D}{\arg \min } \sqrt{\sum_{i, j}\left(\boldsymbol{x}_{j}^{(i)}-r\left(\boldsymbol{x}^{(i)}\right)_{j}\right)^{2}} \text { subject to } \boldsymbol{D}^{\top} \boldsymbol{D}=\boldsymbol{I}_{l}\tag{2.68}
$$



为了推导用于寻求 $\boldsymbol{D}^{*}$ 的算法，我们首先考虑 $l=1$ 的情况。在这种情况下，$\boldsymbol{D}$ 是一个单一向量 $\boldsymbol{d}$ 。将式(2.67)代入式(2.68)，简化 $\boldsymbol{D}$ 为 $\boldsymbol{d}$ ，问题简化为：


$$
\boldsymbol{d}^{*}=\underset{d}{\arg \min } \sum_{i}\left\|\boldsymbol{x}^{(i)}-\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{x}^{(i)}\right\|_{2}^{2} \text { subject to }\|\boldsymbol{d}\|_{2}=1\tag{2.69}
$$

上述公式是直接代入得到的，但不是表述上最美观的方式。在上述公式中，我们将标量 $\boldsymbol{d}^{\top} \boldsymbol{x}^{(i)}$ 放在向量 $\boldsymbol{d}$ 的右边。将该标量放在左边的写法更为传统。于是我们通常写作：

$$
\boldsymbol{d}^{*}=\underset{d}{\arg \min } \sum_{i}\left\|\boldsymbol{x}^{(i)}-\boldsymbol{d}^{\top} \boldsymbol{x}^{(i)} \boldsymbol{d}\right\|_{2}^{2} \text { subject to }\|\boldsymbol{d}\|_{2}=1\tag{2.70}
$$

或者，考虑到标量的转置和自身相等，我们也可以写作：

$$
\boldsymbol{d}^{*}=\underset{d}{\arg \min } \sum_{i}\left\|\boldsymbol{x}^{(i)}-\boldsymbol{x}^{(i) \top} \boldsymbol{d} \boldsymbol{d}\right\|_{2}^{2} \text { subject to }\|\boldsymbol{d}\|_{2}=1\tag{2.71}
$$

读者应该对这些重排写法慢慢熟悉起来。

此时，使用单一矩阵来重述问题，比将问题写成求和形式更有帮助。这有助于我们使用更紧凑的符号。将表示各点的向量堆叠成一个矩阵，记为 $\boldsymbol{X} \in \mathbb{R}^{m \times n}$ ，其中 $\boldsymbol{X}_{i, :}=\boldsymbol{x}^{(i)^{\top}}$。原问题可以重新表述为：



$$
d^{*}=\underset{d}{\arg \min }\left\|\boldsymbol{X}-\boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right\|_{F}^{2}  \text { subject to } \boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.72}
$$

暂时不考虑约束，我们可以将 Frobenius 范数简化成下面的形式：

$$
\underset{d}{\arg \min }\left\|\boldsymbol{X}-\boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right\|_{F}^{2}\tag{2.73}
$$

$$
=\underset{d}{\arg \min } \operatorname{Tr}\left(\left(X-X d d^{\top}\right)^{\top}\left(X-X d d^{\top}\right)\right)\tag{2.74}
$$




(式(2.49) $\|A\|_{F}=\sqrt{\operatorname{Tr}\left(\boldsymbol{A} \boldsymbol{A}^{\top}\right)}$)

$$
=\underset{d}{\arg \min } \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X}-\boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top}-\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X}+\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\tag{2.75}
$$


$$
=\underset{d}{\arg \min } \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X}\right)-\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)-\operatorname{Tr}\left(\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X}\right)+\operatorname{Tr}\left(\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\tag{2.76}
$$


$$
=\underset{d}{\arg \min }-\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top}\right)-\operatorname{Tr}\left(\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X}\right)+\operatorname{Tr}\left(d \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} d d^{\top}\right)\tag{2.77}
$$

(因为与 $\boldsymbol{d}$ 无关的项不影响 $\arg \min$ )

$$
=\underset{d}{\arg \min }-2 \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)+\operatorname{Tr}\left(\boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top}\right)\tag{2.78}
$$

(因为循环改变迹运算中相乘矩阵的顺序不影响结果，如式(2.52) $\operatorname{Tr}\left(\prod_{i=1}^{n} F^{(i)}\right)=\operatorname{Tr}\left(\boldsymbol{F}^{(n)} \prod_{i=1}^{n-1} \boldsymbol{F}^{(i)}\right)$ 所示)

$$
=\underset{d}{\arg \min }-2 \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)+\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\tag{2.79}
$$

(再次使用上述性质)。

此时，我们再来考虑约束条件

$$
=\underset{d}{\arg \min }-2 \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)+\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\text { subject to }\boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.80}
$$

$$
=\underset{d}{\arg \min }-2 \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top}\right)+\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} d \boldsymbol{d}^{\top}\right)\text { subject to }\boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.81}
$$

（因为约束条件）：

$$
=\underset{d}{\arg \min }-\operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\text { subject to }\boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.82}
$$

$$
=\arg \max _{d} \operatorname{Tr}\left(\boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d} \boldsymbol{d}^{\top}\right)\text { subject to }\boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.83}
$$

$$
=\underset{d}{\arg \max } \operatorname{Tr}\left(\boldsymbol{d}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{d}\right)\text { subject to }\boldsymbol{d}^{\top} \boldsymbol{d}=1\tag{2.84}
$$

这个优化问题可以通过特征分解来求解。具体来讲，最优的 $\boldsymbol{d}$ 是 $\boldsymbol{X}^{\top} \boldsymbol{X}$ 最大特征值对应的特征向量。

以上推导特定于 $l=1$ 的情况，仅得到了第一个主成分。

更一般地，当我们希望得到主成分的基时，矩阵 $\boldsymbol{D}$ 由前 $l$ 个最大的特征值对应的特征向量组成。这个结论可以通过归纳法证明，我们建议将此证明作为练习。



# 相关

- 《深度学习》花书
