---
title: 向量求导
toc: true
date: 2018-08-21 18:16:22
---
# 可以补充进来的

- <span style="color:red;">再补充下。</span>


# 向量求导

在线性回归的时候用到了


## 向量的导数

- $\frac{\partial A \overrightarrow{x} }{\partial \overrightarrow{x} }=A^T$
- $\frac{\partial A^T \overrightarrow{x} }{\partial \overrightarrow{x} }=A$
- $\frac{\partial A \overrightarrow{x} }{\partial \overrightarrow{x}^T}=A$




## 标量对向量的导数


$A$ 为 $n\times n$ 的矩阵，$x$ 为 $n\times 1$ 的列向量，记  $y=\overrightarrow{x}^T\cdot A\cdot \overrightarrow{x}$

这个时候 y 是一个数。这时可得：

$$
\frac{\partial y}{\partial \vec{x}}=\frac{\partial\left(\vec{x}^{T} \cdot A \cdot \vec{x}\right)}{\partial \vec{x}}=\left(A^{T}+A\right) \cdot \vec{x}
$$

如果 A 为对称阵，则有：

$$
\frac{\partial y}{\partial \vec{x}}=\frac{\partial\left(\vec{x}^{T} \cdot A \cdot \vec{x}\right)}{\partial \vec{x}}=2 A \cdot \vec{x}
$$



# 相关

1. 七月在线 机器学习
2. [矩阵论：向量求导/微分和矩阵微分](https://blog.csdn.net/pipisorry/article/details/68961388)
