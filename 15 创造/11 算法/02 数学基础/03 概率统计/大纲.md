---
title: 大纲
toc: true
date: 2018-08-20 14:28:04
---
# 大纲

统计学

概率论是用于表示不确定性声明的数学框架。它不仅提供了量化不确定性的方法，也提供了用于导出新的不确定性声明(statement)的公理。<span style="color:red;">嗯。</span>

在人工智能领域，概率论主要有两种用途：

- 首先，概率法则告诉我们 AI 系统如何推理，据此我们设计一些算法来计算或者估算由概率论导出的表达式；
- 其次，可以用概率和统计从理论上分析我们提出的 AI 系统的行为。

对于概率论和信息论：

- 概率论使我们能够提出不确定的声明以及在不确定性存在的情况下进行推理。
- 而信息论使我们能够量化概率分布中的不确定性总量。

<span style="color:red;">是的，概率论和信息论，有些厉害。感觉上面这两句话有些厉害。</span>


1．离散和连续的随机变量（Discrete and continuous random variables）
2．重要的分布（伯努利，分类，二项式，正态，指数，泊松，贝塔，伽马）
3．贝叶斯统计（Bayes statistics）
4．相关和协方差（correlation and covariance）



## 主要内容


概率论基础：

- 随机事件与概率
- 条件概率与贝叶斯公式 重点

概率论主体：

- 随机变量
- 数学期望与方差
- 常用概率分布
- 随机向量 推广到向量情况
- 协方差与协方差矩阵
- 最大似然估计 用于确定概率密度函数里面的参数的方法



1）微积分与逼近论
2）极限、微分、积分基本概念
3）利用逼近的思想理解微分，利用积分的方式理解概率
4）概率论基础
5）古典模型
6）常见概率分布
7）大数定理和中心极限定理
8）协方差(矩阵)和相关系数
9）最大似然估计和最大后验估计





然后是概率论的内容
2.25 为什么需要概率论
2.26 随机事件与概率 2.27 条件概率与贝叶斯公式
2.28 随机事件的独立性
2.29 随机变量
2.30 数学期望与方差
2.31 常用的概率分布
2.32 随机向量
2.33 随机变量的独立性
2.34 协方差
2.35 常用的多维概率分布
2.36 最大似然估计
2.37 本集总结




概率论




如果把机器学习所处理的样本数据看作随机变量/向量，我们就可以用概率论的观点对问题进行建模，这代表了机器学习中很大一类方法。在机器学习里用到的概率论知识点有:

- 随机事件的概念，概率的定义与计算方法
- 随机变量与概率分布，尤其是连续型随机变量的概率密度函数和分布函数
- 条件概率与贝叶斯公式
- 常用的概率分布，包括正态分布，伯努利二项分布，均匀分布
- 随机变量的均值与方差，协方差
- 随机变量的独立性
- 最大似然估计


## 需要消化的

- 《概率论与数理统计》 浙大版 也是本科教材

## 可以补充进来的



- 信息论的东西看来放在数学基础里面有点不合适。可以放在机器学习基础知识里面。

概率统计与信息论

1. 为什么要使用概率？
2. 随机变量
3. 概率分布
   1. 离散型变量和概率质量函数
      1. 连续型变量和概率密度函数
4. 边缘概率
5. 条件概率
6. 条件概率的链式法则
7. 独立性和条件独立性
8. 期望、方差和协方差
9. 常用概率分布
10. 常用函数的有用性质
11. 贝叶斯规则
12. 连续型变量的技术细节
13. 信息论
14. 结构化概率模型
15.
16. 概率与积分
17. 条件概率与贝叶斯公式
18. 分布 add 周志华
19. 共轭分布 NULL
20. 期望 方差 协方差
21. 大数定理与中心极限定理
22. 矩估计与极大似然估计
23. 熵  add 周志华
24. 信息熵




## 可以补充进来的

- 共轭分布
