---
title: 2.01 监督学习
toc: true
date: 2019-05-24
---
# 可以补充进来的

- 感觉讲的还是挺好的，虽然只是简单的提了下。


# 监督学习算法

粗略地说，监督学习算法是给定一组输入 $\boldsymbol{x}$ 和输出 $\boldsymbol{y}$ 的训练集，学习如何关联输入和输出。在许多情况下，输出 $\boldsymbol{y}$ 很难自动收集，必须由人来提供“监督”，不过该术语仍然适用于训练集目标可以被自动收集的情况。<span style="color:red;">嗯。</span>


对于分类问题的处理，最简单的就是感知器模型，从感知器算法按照最大化分类间隔思想就是 SVM。另外一个分支是 Logistic 回归，把线性预测器改装了以下，用 logistic 函数影射了以下，得到一个 0~1 之间的概率值。我们可以吧 Logistic 推广到多分类问题的场景，就是著名的 Softmax 回归，这个在深度学习里面是经常用到的，很多时候，我们的深度神经网络最后一层接的就是 Softmax 。

从感知器诞生的另外一类分支就是人工神经网络。在这次我们只重点讲全连接神经网络 MLP，多层感知器模型，实际上从它里面诞生的很多算法都会在深度学习里面进行讲解。

KNN 是一个大家族，里面要用到距离。引出了距离度量学习算法。


下面的是贝叶斯家族，第一种是朴素贝叶斯，第二是正态贝叶斯。

然后是一种线性投影技术 LDA 是一种有监督学习的投影，他的思想很简单，就是最大化类间差异，最小化类差异，向这个方向做投影，得到一个投影方向。它有非线性版本，加上核函数之后得到一个 KLDA 这个不做重点介绍。






# 相关

- 《深度学习》花书
- SIGAI
