---
title: 3.04 参数模型与非参数模型
toc: true
date: 2019-08-28
---
# 参数模型与非参数模型


## 参数模型

如果我们对所要学习的问题有足够的认识，具备一定的先验知识，此时我们一般会假定要学习的目标函数 $f(x)$ 或分布 $P(y|x)$ 的具体形式。

然后，通过训练数据集，基于 ERM、SRM、MLE、MAP等学习策略，可以估计出 $f(x)$ 或 $P(y|x)$ 中含有的未知参数。

一旦未知参数估计完毕，训练数据一般来说，就失去其作用了，因为这些估计出来的参数就是训练数据的浓缩。

通过这种方式建立起来的模型就是参数模型。

参数模型的一个很重要的特点是，如果对于模型的假设正确，那么只需要很少的训练数据就可以从假设空间中学出一个很好的模型。但是，如果模型的假设错误，那么无论训练的数据量有多大，甚至趋于无穷大，学出的模型都会与实际模型出现不可磨灭的偏差。

参数模型有如下：

- 感知机
- 逻辑斯特回归
- 高斯判别分析
- 朴素贝叶斯
- 线性支持向量机


## 非参数模型

当我们对所要学习的问题知之甚少，此时我们一般不会对潜在的模型做过多的假设。在面对预测任务的时候，我们通常会用上所有的训练数据。

例如简单的核密度估计(KDE)的表达式中，就带有所有训练数据的信息。通过这种方式建立的模型就是非参数模型。

非参数模型的一个很重要的特点就是：let the data speak for itself.

正因为如此，非参数模型的存储开销、计算开销都会比参数模型大的多。

但是，由于不存在模型的错误假定问题，可以证明，当训练数据量趋于无穷大的时候，非参数模型可以逼近任意复杂的真实模型。这正是非参数模型诱人的一点。

另外需要说明的一点是，非参数模型之所以叫做非参数，并不是因为模型中没有参数。实际上，非参数模型中一般会含有一个或多个超参数，外加无穷多个普通的参数。


非参数模型如下：

- K近邻就是典型的非参数模型。


## 半参数模型


对于神经网络来说，当固定了隐层的数目以及每一层神经元的个数，它也属于参数模型。但由于隐层数目与每一层神经元个数的不确定性，很多时候，神经网络都被归类为半参数模型。

通过加大网络的深度(加大隐层数目)以及宽度(增加每一层神经元的个数)，使假设空间的复杂度得到极大的提高。复杂的假设空间有极强的表达能力，当训练数据量很大的时候，不会陷入过拟合。所以，深度学习的成功，从理论上讲，一方面来源于海量的训练数据，另一方面来源于其复杂的网络结构。






# 相关

- [监督学习的分类：判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型](https://zhuanlan.zhihu.com/p/26012348)
