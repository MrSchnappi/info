---
title: 2.13 自助法
toc: true
date: 2019-09-20
---

# 自助法 bootstrapping

不管是 Holdout 检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。

然而，当样本规模比较小时，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。

有没有能维持训练集样本规模的验证方法呢？自助法可以比较好地解决这个问题。<span style="color:red;">即使我之前看到过，再次看到还是感觉有些惊奇。而且，还是想知道，这样不会有分布上的问题吗？分布不会发生变化吗？</span>


自助法是基于自助采样法 bootstrap sampling 的检验方法。对于总数为 $n$ 的样本集合，进行 $n$ 次有放回的随机抽样，得到大小为 $n$ 的训练集。$n$ 次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集，进行模型验证，这就是自助法的验证过程。<span style="color:red;">嗯，这个自助法，这个名字感觉与这个定义不是特别搭，为什么起这么个名字呢？是自助餐的意思吗？</span>


## 在自助法的采样过程中，对 $n$ 个样本进行 $n$ 次自助抽样，当 $n$ 趋于无穷大时，最终有多少数据从未被选择过？


一个样本在一次抽样过程中未被抽中的概率为 $(1-\frac{1}{n})$，$n$ 次抽样均未抽中的概率为 $(1-\frac{1}{n})^n$ 。当 $n$ 趋于无穷大时，概率为 $\lim_{n\rightarrow \infty} (1-\frac{1}{n})^n$。

根据重要极限 $\lim_{n\rightarrow \infty} (1-\frac{1}{n})^n=e$，所以有：

$$
\begin{aligned}
\lim_{n\rightarrow \infty}(1-\frac{1}{n})^n &= \lim_{n\rightarrow\infty}\frac{1}{(1+\frac{1}{n-1})^n}\\
&= \frac{1}{lim_{n\rightarrow \infty}(1+\frac{1}{n-1})^{n-1}}\cdot \frac{1}{lim_{n\rightarrow \infty}(1+\frac{1}{n-1})}\\
&=\frac{1}{e}\approx 0.368
\end{aligned}
$$

因此，当样本数很大时，大约有 $36.8\%$ 的样本从未被选择过，可作为验证集。<span style="color:red;">嗯，还是很好的。</span>

也即是：实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，仍有数据总量约 $1/3$ 的、没在训练集中出现的样本可以用于测试。

## 自助法的使用场景

那么这么好的方法，我们在什么情况下使用呢？

自助法在数据集较小、难以有效划分训练集/测试集的时候还是很有用的。<span style="color:red;">那么大的数据集的时候不推荐使用吗？而且小的数据集的时候这种自助法不是会产生一些重复的数据吗？不会对模型有影响吗？</span>而且，**自助法由于能够从初始数据集中产生多个不同的训练集，这就对集成学习等方法有很大的好处。**<span style="color:red;">感觉很厉害的，不过还是要确认下 ensemble 与这种自助法的详细关系。</span>

然而，**自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差，因此，在初始数据量足够多的时候，还是留出法和交叉验证法更常用一些。**<span style="color:red;">估计偏差要怎么消除？难道小数据量的时候就可以不考虑估计偏差吗？</span>

<span style="color:red;">嗯，这些方法的选取在实践中再确认下，然后将经验补充到这里。</span>



# 相关

- 《百面机器学习》
- 《机器学习》
