---
title: 1.13 异常值处理
toc: true
date: 2019-09-20
---
# 异常值处理

异常值分析是检验数据是否有录入错误以及含有不合常理的数据。忽视异常值的存在是十分危险的，不加剔除地把异常值包括进数据的计算分析过程中，对结果会产生不良影响。

异常值是指样本中的个别值，其数值明显偏离其余的观测值。异常值也称为离群点，异常值分析也称为离群点分析。

## 如何发现离群点

对于数据量较少，可以使用画图，但是画图其实并不常用，因为数据量多时不好画图，而且慢。


我们还有很多其他方法:

### 1. 简单的统计分析

拿到数据后可以对数据进行一个简单的描述性统计分析，譬如最大最小值可以用来判断这个变量的取值是否超过了合理的范围，如客户的年龄为-20岁或 200 岁，显然是不合常理的，为异常值。在 python 中可以直接用 pandas 的 describe()。

或者简单使用散点图也能观察到异常值的存在，如下图所示：

<center>

![mark](http://images.iterate.site/blog/image/20190918/OOPxmtM7Avoo.png?imageslim)

</center>

### 2. $3\sigma$ 原则

如果数据服从正态分布，在 $3\sigma$ 原则下，异常值为一组测定值中与平均值的偏差超过 3 倍标准差的值。因为距离平均值 $3\sigma$ 之外的值出现的概率为 P(|x-u| > $3\sigma$) <= 0.003，属于极个别的小概率事件。

如果数据不服从正态分布，也可以用远离平均值的多少倍标准差来描述。

<center>

![mark](http://images.iterate.site/blog/image/20190918/amfVdYnwkf5d.png?imageslim)

</center>

### 3. 箱型图分析

这种方法是利用箱型图的四分位距（IQR）对异常值进行检测，也叫 Tukey‘s test。箱型图的定义如下：

<center>

![mark](http://images.iterate.site/blog/image/20190918/zfIiSmGYYliK.png?imageslim)

</center>

QL为下四分位数，表示全部观察值中有四分之一的数据取值比它小；QU为上四分位数，表示全部观察值中有四分之一的数据取值比它大；IQR为四分位数间距，是上四分位数 QU 与下四分位数 QL 的差值，包含了全部观察值的一半。

而我们通过 IQR 的 1.5倍为标准，规定：超过**上四分位+1.5倍 IQR 距离，或者下四分位-1.5倍 IQR 距离**的点为异常值。下面是 Python 中的代码实现，主要使用了`numpy`的`percentile`方法。

箱型图判断异常值的方法以四分位数和四分位距为基础，四分位数具有鲁棒性：25%的数据可以变得任意远并且不会干扰四分位数，所以异常值不能对这个标准施加影响。

因此箱型图识别异常值比较客观，在识别异常值时有一定的优越性。


上面三种方法是比较简单的异常值检测方法，接下来是一些较复杂的异常值检测方法，因此这里简单介绍下这些方法的基本概念。


4. 基于模型检测

顾名思义，该方法会构建一个概率分布模型，并计算对象符合该模型的概率，将低概率的对象视为异常点。

如果模型是簇的组合，则异常点是不在任何簇的对象；如果模型是回归，异常点是远离预测值的对象(就是第一个方法的图示例子)。


优缺点：

1. 有坚实的统计学理论基础，当存在充分的数据和所用的检验类型的知识时，这些检验可能非常有效；
2. 对于多元数据，可用的选择少一些，并且对于高维数据，这些检测可能性很差。



### 5. 基于距离

**一个对象的离群点得分由到它的 k-最近邻（KNN）的距离给定**。

> 这里需要注意 **k** 值的取值会影响离群点得分，如果 k 太小，则少量的邻近离群点可能会导致较低的离群点得分；如果 k 太大，则点数少于 k 的簇中所有的对象可能都成了离群点。为了增强鲁棒性，可以采用 k 个最近邻的平均距离。

**优缺点**：

- 简单;
- 基于邻近度的方法需要 $O\left(m^{2}\right)$ 时间，大数据集不适用；
- k 值的取值导致该方法对参数的选择也是敏感的；
- 不能处理具有**不同密度区域**的数据集，因为它使用全局阈值，不能考虑这种密度的变化。



### 6. 基于密度

**一种常用的定义密度的方法是，定义密度为到 k 个最近邻的平均距离的倒数。如果该距离小，则密度高，反之亦然。**

**另一种密度定义是使用 DBSCAN 聚类算法使用的密度定义，即一个对象周围的密度等于该对象指定距离 d 内对象的个数。**

**优缺点：**

- 给出了对象是离群点的定量度量，并且即使数据具有不同的区域也能够很好的处理；
- 与基于距离的方法一样，这些方法必然具有 $O\left(m^{2}\right)$ 的时间复杂度。对于低维数据使用特定的数据结构可以达到 $O(\text { mlogm })$ ；
- 参数选择是困难的。虽然 `LOF` 算法通过观察不同的 k 值，然后取得最大离群点得分来处理该问题，但是，仍然需要选择这些值的上下界。



### 7. 基于聚类

**一个对象是基于聚类的离群点，如果该对象不强属于任何簇，那么该对象属于离群点。**

离群点对初始聚类的影响：如果通过聚类检测离群点，则由于离群点影响聚类，存在一个问题：**结构是否有效**。这也是 `k-means` 算法的缺点，**对离群点敏感**。

为了处理该问题，可以使用如下方法：对象聚类，删除离群点，对象再次聚类（这个不能保证产生最优结果）。

**优缺点：**

- 基于线性和接近线性复杂度（k 均值）的聚类技术来发现离群点可能是高度有效的；
- 簇的定义通常是离群点的补集，因此可能同时发现簇和离群点；
- 产生的离群点集和它们的得分可能非常依赖所用的簇的个数和数据中离群点的存在性；
- 聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大。


### 8. 专门的离群点检测

除了以上提及的方法，还有两个专门用于检测异常点的方法比较常用：`One Class SVM`和`Isolation Forest`，




## **异常值处理**

- **删除含有异常值的记录**：直接将含有异常值的记录删除；
- **视为缺失值**：将异常值视为缺失值，利用缺失值处理的方法进行处理；
- **平均值修正**：可用前后两个观测值的平均值修正该异常值；
- **不处理**：直接在具有异常值的数据集上进行数据挖掘；

将含有异常值的记录直接删除的方法简单易行，但缺点也很明显，在观测值很少的情况下，**这种删除会造成样本量不足，可能会改变变量的原有分布，从而造成分析结果的不准确**。视为缺失值处理的好处是 **可以利用现有变量的信息，对异常值（缺失值）进行填补。**

在很多情况下，要先分析异常值出现的可能原因，在判断异常值是否应该舍弃，如果是正确的数据，可以直接在具有异常值的数据集上进行挖掘建模。



# 相关

- [特征工程之数据预处理（下）](https://zhuanlan.zhihu.com/p/56557301)
- [机器学习基础与实践（一）----数据清洗](https://www.cnblogs.com/charlotte77/p/5606926.html)
