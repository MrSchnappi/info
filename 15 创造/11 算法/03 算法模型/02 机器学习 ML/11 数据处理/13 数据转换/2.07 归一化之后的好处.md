---
title: 2.07 归一化之后的好处
toc: true
date: 2019-09-20
---

# 归一化后有三个好处

1. 提升模型的收敛速度

我们不妨借助随机梯度下降的实例来说明归一化的重要性。假设有两种数值型特征，x1的取值范围为 `[0，10]`，x2的取值范围为`[0，3]`，于是可以构造一个目标函数符合下图中的等值图。

![](http://images.iterate.site/blog/image/20190322/y5vblKb9PTve.png?imageslim){ width=55% }


在学习速率相同的情况下，x1的更新速度会大于 x2，需要较多的迭代才能找到最优解。如果将 x1 和 x2 归一化到相同的数值区间后，优化目标的等值图会变成图 1.1（b）中的圆形，x1和 x2 的更新速度变得更为一致，容易更快地通过梯度下降找到最优解。<span style="color:red;">嗯 容易更快地通过梯度下降找到最优解</span>


2. 提升模型的精度

归一化的另一好处是提高精度，这在涉及到一些距离计算的算法时效果显著，比如算法要计算欧氏距离，上图中 x2 的取值范围比较小，涉及到距离计算时其对结果的影响远比 x1 带来的小，所以这就会造成精度的损失。所以归一化很有必要，他可以让各个特征对结果做出的贡献相同。

从经验上说，归一化是让不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。

3. 深度学习中数据归一化可以防止模型梯度爆炸。



# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
- [数据标准化/归一化 normalization](https://blog.csdn.net/pipisorry/article/details/52247379)
- 《百面机器学习》
