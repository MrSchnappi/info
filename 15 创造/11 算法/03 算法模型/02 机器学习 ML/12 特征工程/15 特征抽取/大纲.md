---
title: 大纲
toc: true
date: 2018-09-02
---

# 大纲

特征抽取 Feature Extraction


1. 对于Numerical Variable，可以通过线性组合、多项式组合来发现新的Feature。
2. 对于文本数据，有一些常规的Feature。比如，文本长度，Embeddings，TF-IDF，LDA，LSI等，你甚至可以用深度学习提取文本特征（隐藏层）。
3. 如果你想对数据有更深入的了解，可以通过思考数据集的构造过程来发现一些magic feature，这些特征有可能会大大提升效果。在Quora这次比赛中，就有人公布了一些magic feature。
4. 通过错误分析也可以发现新的特征（见1.5.2小节）。




## 主要内容

- 特征选择
- 特征重要性评估
- 特征抽象
- 特征组合


## 需要消化的


深度学习之前，在特征工程作为算法工程师主要工作内容的时候，构造新特征的尝试往往很大部分都不能在实际工作中work。据我了解，国内几家大公司在特征构造方面的成功率在后期一般不会超过20%。也就是80%的新构造特征往往并没什么正向提升效果。如果给这种方式起一个名字的话，大概是简单模型+复杂特征；简单模型说的是算法比如LR、SVM本身并不服务，参数和表达能力基本呈现一种线性关系，易于理解。复杂特征则是指特征工程方面不断尝试使用各种奇技淫巧构造的可能有用、可能没用的特征，这部分特征的构造方式可能会有各种trick，比如窗口滑动、离散化、归一化、开方、平方、笛卡尔积、多重笛卡尔积等等；顺便提一句，因为特征工程本身并没有特别系统的理论和总结，所以初入行的同学想要构造特征就需要多读paper，特别是和自己业务场景一样或类似的场景的paper，从里面学习作者分析、理解数据的方法以及对应的构造特征的技法；久而久之，有望形成自己的知识体系。


深度学习概念提出以后，人们发现通过深度神经网络可以进行一定程度的表示学习（representation learning），例如在图像领域，通过CNN提取图像feature并在此基础上进行分类的方法，一举打破了之前算法的天花板，而且是以极大的差距打破。这给所有算法工程师带来了新的思路，既然深度学习本身有提取特征的能力，干嘛还要苦哈哈的自己去做人工特征设计呢？


深度学习虽然一定程度上缓解了特征工程的压力，但这里要强调两点：1.缓解并不等于彻底解决，除了图像这种特定领域，在个性化推荐等领域，深度学习目前还没有完全取得绝对的优势；究其原因，可能还是数据自身内在结构的问题，使得在其他领域目前还没有发现类似图像+CNN这样的完美CP。2.深度学习在缓解特征工程的同时，也带来了模型复杂、不可解释的问题。算法工程师在网络结构设计方面一样要花很多心思来提升效果。概括起来，深度学习代表的简单特征+复杂模型是解决实际问题的另一种方式。

## 可以补充进来的

- 关于特征工程要系统的补充下。
