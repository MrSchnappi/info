---
title: 01.01 特征选择介绍
toc: true
date: 2019-08-27
---
# 特征选择

## 相关特征与无关特征

一个西瓜有很多属性，例如色泽、根蒂、敲声、纹理、触感 等，但判断一个瓜是否成熟只需看看根蒂、听听敲声。

也就是说，对一个学习任务来说，给定属性集，有些属性是很关键的，另一些属性则可能没什么用处。

因此，我们把：

- 对当前学习任务有用的属性称为“相关特征”(relevant feature)
- 没什么用的属性称为“无关特征” (irrelevant feature)

## 特征选择定义

我们把：

**从给定的特征集合中选择出相关特征子集的过程，称为“特征选择” (feature selection)。**

> 注意：相关特征子集并不一定是与 label 线性相关的。



## 以后要消化的


特征选择是机器学习中研究最早的分支领域之一，早期研究主要是按特 征子集“生成与搜索-评价”过程进行。在子集生成与搜索方面引入了很多 人工智能搜索技术，如分支限界法［Narendra and Pukunaga, 1977］ ＞浮动搜索 法［Pudil et al, 1994］等；在子集评价方面则采用了很多源于信息论的准则， 如信息熵、AIC (Akaike Information Criterion) ［Akaike, 1974］等。［Blum and Langley, 1997］对子集评价准则进行了讨论，［Forman, 2003］则进行了很多实验 比较。。

早期特征选择方法主要是过滤式的，包裹式方法出现稍晚［Kohavi and John, 1997］，嵌入式方法事实上更晚［Weston et al., 2003］，但由于决策树算法 在构建树的同时也可看作进行了特征选择，因此嵌入式方法也可追溯到 ID3 ［Quinlan, 1986］。有很多文献对特征选择方法的性能进行了实验比较［Yang and Pederson, 1997; Jain and Zongker, 1997］。更多关于特征选择的内容可参 阅［Guyon and Elisseeff，2003; Liu et al., 2010］，以及专门关于特征选择的书籍


LARS (Least Angle Regression) [Efron et al., 2004]是一种嵌入式特征 选择方法，它基于线性回归平方误差最小化，每次选择一个与残差相关性最 大的特征。LASSO [Tibshirani, 1996]可通过对 LARS 稍加修改而实现。在 LASSO基础上进一步发展出考虑特征分组结构的 Group LASSO [Yuan and Lin, 2006]、考虑特征序结构的 Fused LASSO [Tibshirani et al., 2005]等变体。 由于凸性不严格，LASSO类方法可能产生多个解，该问题通过弹性网(Elastic Net)得以解决[Zou and Hastie，2005]。





# 相关

- 《机器学习》周志华
