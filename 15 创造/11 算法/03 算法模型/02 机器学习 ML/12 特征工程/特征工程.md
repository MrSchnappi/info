---
title: 特征工程
toc: true
date: 2019-10-19
---
# 特征工程

### 1. 数值变量标准化

- 不同数据的Scale不一样，所以需要标准化。比如身高和体重。
- 不做标准化，有些算法会死得很惨，比如SVM、神经网络、K-means之类。标准化的一种方法是均值方差法。
- 不是什么时候都需要标准化，比如物理意义非常明确的经纬度，如果标准化，其本身的意义就会丢失。
- 标准化并不等同归一化，此处可参考其他资料。

### 2. 离散化

- 原文是Binning/Converting Numerical to Categorical Variable，实际就是把连续型的数据利用Binning等方法转为离散的分类变量（Categorical Variable）。

### 3. 减少分类变量取值范围

- 有些分类变量的少部分取值可能占据了90%的case，这种情况下如何处理，可以采用预测模型、领域专家、或者简单的频率分布统计。
- 我爱机器学习([http://52ml.net](https://link.zhihu.com/?target=http%3A//52ml.net))编者认为还是应用为王，具体问题具体分析，高频和低频都是需要特别处理的地方，抛弃效果不好时，可以考虑采样（高频）或上采样（低频），加权等等方法。

### 4. 非正态分布转正太分布

- 下图中的例子，z1本来是x的指数函数，取log后两者就变为线性关系了。

![img](https://pic3.zhimg.com/80/v2-f4e51995b867e5fce1b15d9359091176_hd.png)

- 这个例子太特别，作者也提到，现实中可能需要用其他转换，比如平方根立方根。其实就是数据转换，但是转哪种分布不好说，取决于转换后的特征的表征能力和对模型的贡献。

### 5. Missing Data

- 感觉叫Missing Value更合适，这个在很多实际问题中确实挺重要，比如一个性别特征，三分之一为男，三分之一为女，还有一类没填，missing value不容忽视。

### 6. 哑变量

- 哑变量又称为虚拟变量。分类变量（尤其是枚举型变量）有时候多个数值之间的差值没有物理意义，比如操作系统类别，iOS、Android、Windows分别取值0、1、2，它们相互之间的差值并没有任何物理意义。处理方法是直接生成三个哑变量，取值范围都是0或1，第一个哑变量表示是否为iOS，其他类似。
- 加入哑变量后就不会有枚举变量数值无比较意义的问题了。

### 7. 交叉特征

- 有些特征一起考虑才有意义，简单来说if条件需要除了非要加入与/非了，这个重要性无需多言。

### 8. 降维

- 为何要降维？
  - 性能
  - 避免过拟合
- 方法
  - 人肉：SIFT, VLAD, HOG, GIST, LBP
  - 模型：Sparse Coding, Auto Encoders, Restricted Boltzmann Machines, PCA, ICA, K-means

### 9. 直觉和额外的特征

- 针对原始数据，可以利用自己的特长手动或自动生成直觉和额外的特征。比如文本问题，可以写个自动算法生成单词长度、元音个数、n-gram等等。
- 数据分析师可能会发现噪声中的信号。




# 相关

- [怎样提升机器学习：特征工程的奇淫巧技](https://zhuanlan.zhihu.com/p/23356953)
