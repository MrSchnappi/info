---
title: 3.13 合页损失 Hinge Loss
toc: true
date: 2019-09-03
---
# Hinge Loss

Hinge Loss，又称合页损失/多分类 SVM 损失

Hinge 损失函数的标准形式如下：

$$
L(y) = \max{(0, 1-ty)}
$$

统一的形式：

$$
L(Y, f(x)) = \max{(0, Yf(x))}
$$

其中 $y$ 是预测值，范围为(-1,1)，$t$ 为目标值，其为 $-1$ 或 $1$。

图示：

![mark](http://images.iterate.site/blog/image/20190902/AFDbAjeFbVQS.png?imageslim)



Hinge Loss 的形状就像一本要合上的书，故称为合页损失。显然，只有当 $ys < 1$ 时，Loss 才大于零；对于 $ys > 1$ 的情况，Loss 始终为零。




在线性支持向量机中，最优化问题可等价于

$$
\underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2
$$

上式相似于下式

$$
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2
$$

其中 $l(wx_i+by_i)$ 是 Hinge 损失函数，$\Vert w\Vert ^2$ 可看做为正则化项。

## Hinge Loss 优缺点

Hinge Loss 一般多用于支持向量机（SVM）中，体现了 SVM 距离最大化的思想。而且，当 Loss 大于零时，是线性函数，便于梯度下降算法求导。

Hinge Loss 的另一个优点是使得 $ys > 0$ 的样本损失皆为 0，由此带来了稀疏解，使得 SVM 仅通过少量的支持向量就能确定最终超平面。


# 相关

- [确定不收藏？机器学习必备的分类损失函数速查手册](https://redstonewill.com/1584/)
