---
title: 2.15 F1
toc: true
date: 2019-08-27
---

### $F_1$

但是 BEP 还是过于简单了些，我们更常用的是 F1 度量。F1 是基于查准率与查全率的调和平均。<span style="color:red;">为什么使用调和平均？书上说，调和平均与算数平均 $\frac{P+R}{2}$ 和集合平均 $\sqrt{P\times R}$ 相比，更重视较小值，为什么要重视较小值？</span>

<span style="color:red;">有个问题之前就想知道：F1 与 BEP 或者 P-R 的面积会有冲突吗？冲突的时候以哪个为准？</span>


$$
\frac{1}{F 1}=\frac{1}{2} \cdot\left(\frac{1}{P}+\frac{1}{R}\right)
$$
$$
F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{样例总数+T P-T N}
$$

### $F_\beta$

在一些应用中，对查准率和查全率的重视程度是有所不同的，比如：

* 在商品推荐系统中，为了尽可能的少打扰用户，我们更希望推荐内容是用户感兴趣的，这个时候查准率就更重要。

* 而在逃犯信息检索系统中，我们更希望尽可能的少漏掉逃犯，因此这个时候查全率更加重要。


F1 度量的一般形式 $F_\beta$ ，能够让我们表达出对查准率/查全率的不同偏好，它是基于查准率与查全率的加权调和平均：<span style="color:red;">之前从来不知道还有  $F_\beta$ ，有可能看到过，但是忘记了。</span>

$$
\frac{1}{F_{\beta}}=\frac{1}{1+\beta^{2}} \cdot\left(\frac{1}{P}+\frac{\beta^{2}}{R}\right)
$$

$$
F_{\beta}=\frac{\left(1+\beta^{2}\right) \times P \times R}{\left(\beta^{2} \times P\right)+R}
$$

其中 $\beta >0$ 度量了查全率对查准率的相对重要性：

- $\beta =1$ 时退化为标准的 F1
- $\beta >1$ 时查全率有更大影响
- $\beta <1$ 时查准率有更大影响

<span style="color:red;">kaggle 比赛中有使用这个作为衡量指标的吗？一般什么时候用？sklearn 里面怎么使用？</span>




# 相关

- 《机器学习》周志华
