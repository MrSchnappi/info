---
title: 5.06 LR 与线性回归的关系
toc: true
date: 2019-09-03
---

# LR 与线性回归的关系

LR在线性回归的实数范围输出值上施加 sigmoid 函数将值收敛到 $0~1$ 范围， 其目标函数也因此从差平方和函数变为对数损失函数， 以提供最优化所需导数（sigmoid函数是 softmax 函数的二元特例， 其导数均为函数值的 $f*(1-f)$ 形式）。

请注意， LR 往往是解决二元 0/1 分类问题的， 只是它和线性回归耦合太紧， 不自觉也冠了个回归的名字(马甲无处不在). 若要求多元分类，就要把 sigmoid 换成 softmax了。


其次经典线性模型的优化目标函数是最小二乘，而逻辑回归则是似然函数，
