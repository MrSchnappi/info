---
title: 05 K 近邻算法的优缺点
toc: true
date: 2019-08-28
---

# OK，那么 KNN 算法有那些特点呢？


优点：

* 精度高、
* 对异常值不敏感、
* 无数据输入假定

缺点：

* 计算复杂度高、
* 空间复杂度高


适用数据范围：

* 数值型和标称型 **什么是标称型？**


k-最近邻的高容量使其在训练样本数目大时能够获取较高的精度。然而，它的计算成本很高，另外在训练集较小时泛化能力很差。 k-最近邻的一个弱点是它不能学习出哪一个特征比其他更具识别力。例如，假设我们要处理一个回归任务，其中 $\boldsymbol{x} \in \mathbb{R}^{100}$ 是从各向同性的高斯分布中抽取的，但是只有一个变量 $x_{1}$ 和结果相关。进一步假设该特征直接决定了输出，即在所有情况中 $y=x_{1}$ 。最近邻回归不能检测到这个简单模式。<span style="color:red;">是的是的。</span>大多数点 $\boldsymbol{x}$ 的最近邻将取决于 $x_{2}$ 到 $x_{100}$ 的大多数特征，而不是单独取决于特征 $x_{1}$。因此，小训练集上的输出将会非常随机。<span style="color:red;">是的，小训练集上的输出将会非常的随机。虽然其实是这种简单的模式。</span>



# 相关

- [第 2 章 k-近邻算法](http://ml.apachecn.org/mlia/knn/)
