---
title: 15 几种划分标准的区别和联系
toc: true
date: 2019-08-27
---


## 除了构建准则之外，它们之间的区别与联系是什么？

通过对比三种决策树的构造准则，以及在同一例子上的不同表现，我们不难总结三者之间的差异：

- 首先，ID3是采用信息增益作为评价标准，除了“会写代码”这一逆天特征外，会倾向于取值较多的特征。因为，信息增益反映的是给定条件以后不确定性减少的程度，特征取值越多就意味着确定性更高，也就是条件熵越小，信息增益越大。这在实际应用中是一个缺陷。比如，我们引入特征“DNA”，每个人的 DNA 都不同，如果 ID3 按照“DNA”特征进行划分一定是最优的（条件熵为 0），但这种分类的泛化能力是非常弱的。<span style="color:red;">嗯，是的。</span>
- 因此，C4.5实际上是对 ID3 进行优化，通过引入信息增益比，一定程度上对取值比较多的特征进行惩罚，避免 ID3 出现过拟合的特性，提升决策树的泛化能力。

其次，从样本类型的角度：

- ID3只能处理离散型变量，
- 而 C4.5和 CART 都可以处理连续型变量。C4.5处理连续型变量时，通过对数据排序之后找到类别不同的分割线作为切分点，根据切分点把连续属性转换为布尔型，从而将连续型变量转换多个取值区间的离散型变量。<span style="color:red;">嗯，再了解下。</span>
- 而对于 CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适用于连续性变量。


从应用角度，

- ID3 和 C4.5 只能用于分类任务。<span style="color:red;">上面不是说 C4.5 可以用于连续型变量吗？连续型变量有分类任务的吗？嗯，好像也是可以的，确认下。</span>
- 而 CART（Classification and Regression Tree，分类回归树）从名字就可以看出其不仅可以用于分类，也可以应用于回归任务（回归树使用最小平方误差准则）。<span style="color:red;">回归树使用最小平方误差准则。总结下。</span>


此外，从实现细节、优化过程等角度，这三种决策树还有一些不同。比如：

对于样本缺失值来说：

- ID3对样本特征缺失值比较敏感，
- 而 C4.5和 CART 可以对缺失值进行不同方式的处理；<span style="color:red;">怎么进行处理？</span>

对于特征与分支来说：

- ID3和 C4.5可以在每个结点上产生出多叉分支，且每个特征在层级之间不会复用，
- 而 CART 每个结点只会产生两个分支，因此最后会形成一颗二叉树，且每个特征可以被重复使用；

对于为了保持树的准确性和泛化能力来说：

- ID3 和 C4.5 通过剪枝来权衡树的准确性与泛化能力，
- 而 CART 直接利用全部数据发现所有可能的树结构进行对比。<span style="color:red;">什么意思？这个地方？</span>


至此，我们从构造、应用、实现等角度对比了 ID3、C4.5、CART这三种经典的决策树模型。这些区别与联系总结起来容易，但在实际应用中还需要读者慢慢体会，针对不同场景灵活变通。
