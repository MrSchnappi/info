---
title: 23 预剪枝策略
toc: true
date: 2019-08-27
---

## 预剪枝策略

### 预剪枝过程

预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。

<center>

![](http://images.iterate.site/blog/image/180626/43eE2Ig7G0.png?imageslim){ width=55% }

</center>

我们从头开始看，首先，基于信息増益准则，我们会选取属性 “脐部” 来对训练集进行划分。

那么，这个时候，我们就要来判断了，要不要进行这个划分呢？

我们就要看下划分前后的泛化性能怎么样：

* 如果不进行划分，也就是说这个结点将被标记为叶结点，那么这个结点的类别将被标记为训练样本数最多的类别，即 “好瓜” 类， OK，然后，我们用验证集对这个单结点的决策树进行评估，样本 {4,5,8} 分类正确，另外 4 个样本分类错误，那么，这个时候的验证集的精度为 $\frac{3}{7}\times 100\% = 42.9\%$。
* 如果用属性 “脐部” 进行划分，那么划分之后，分成了 ②、③、④ 三类，分别包含编号为 {1,2,3,14}、{6,7,15,17}、{10,16} 的训练样本，每个结点的类别就是这个结点的样本最多的类别，即： “好瓜”、“好瓜”、“坏瓜”。OK，然后，我们用验证集对这个决策树进行评估，验证集中编号为 {4,5,8,11,12} 的样例被分类正确，验证集精度为 $\frac{5}{7}\times  100\% =71.4\%$ 。

$71.4\% > 42.9\%$ ，说明我们可以用 “脐部” 进行划分。

<span style="color:red;">注意上面这个过程与决策树的生成时候的区别。决策树的生成的时候，他实际上是验证的很多的特征，然后看那个特征可以把信息增益做到最大，然后就用哪个特征进行划分。然后才是预剪枝的过程。而且，这个预剪枝并不会干涉到特征的选择，只会来看这个已经确定的特征是不是真的要分。</span>

OK，决策树算法继续对结点 ② 进行划分，基于信息增益准则，我们挑选出属性 “色泽” 。然而，在使用 “色泽” 划分后，计算出的验证集的精度为 57.1% ，相对于 71.4% 下降了，因此这个结点 ② 不能被。<span style="color:red;">解释一下：首先，这个色泽的特征是通过信息增益准则挑选出来的，也就是说，使用这个特征进行划分，对于结点 ② 来说已经是最好的选择了，但是，随后的验证却发现这个特征虽然是最好的，但是它却使整个树的泛化性能变差了，所以直接否掉这个特征。而别的特征因为连信息增益这一关都没有过去，也不会到这里来了。这个节点已经不会往下划分了。</span>

类似的，对于结点 ③ ，最优划分属性为 "根蒂"，划分后验证集精度还是 71.4%。也就是说这个划分不能提升验证集精度，因此，这个结点 ③ 也被禁止划分。<span style="color:red;">不能提升验证集精度的也会被禁止划分。</span>

对于结点 ④，它所含的训练样例已属于同一类，没法找到一个特征进行划分了，因此自然也是不用划分的。

OK，到这里，我们就从表 4.2 的数据中生成了这个已经被剪枝好的树图 4.6 。它的验证集精度为 71.4%。<span style="color:red;">总的来说还是很清晰的。</span>

这是一棵仅有一层划分的决策树，也被称为决策树桩 (decision stump)。<span style="color:red;">注：决策树桩在随机森林中经常会用到。</span>


### 预剪枝策略的优缺点

我们可以对比一下图 4.6 和图 4.5，可以看到，预剪枝使得决策树的很多分支都没有 “展开”。<span style="color:red;">是的，这种没有展开会造成什么后果呢？</span>

我们很容易就能列出这样的剪枝的优点：

* 降低了过拟合的风险。
* 减少了决策树的训练时间开销和测试时间开销。而且是显著的降低。因为很多枝连展开都没有展开，后面的划分计算自然就没有了。

OK，那么这样的预剪枝是十全十美的吗？

实际上，还是有点问题的：


* 有些分支的当前划分虽然这次不能提升泛化性能、甚至可能导致泛化性能的暂时下降，但是在它基础上进行的后续划分却是有可能导致性能显著提高的。而预剪枝策略基于 “贪心” 的本质禁止了这些分支展开，这就给预剪枝决策树带来了欠拟合的风险。<span style="color:red;">是呀，听起来好像是这么回事。不过还是没有很理解？能不能举个例子？而且为什么会出现这种情况？这种方法的本质上有问题了吗？</span>

<span style="color:red;">上面这个缺点现在有什么说法吗？比如有什么降低欠拟合的风险的方法？怎么就提了一下就没有然后了？</span>






# 相关

- 《机器学习》周志华
