---
title: 24 后剪枝策略
toc: true
date: 2019-08-27
---

## 后剪枝策略

### 后剪枝过程

OK，现在我们介绍一下后剪枝。

后剪枝它与预剪枝还是不一样的，它先从训练集生成一棵完整的决策树，如图 4.5。这个时候，这个决策树的验证集精度为 42.9%。

<center>

![](http://images.iterate.site/blog/image/180626/GE4bCh919E.png?imageslim){ width=55% }

</center>

OK，现在开始后剪枝：

我们先考察图 4.5 中的结点 ⑥，如果我们将以它为父节点的分支剪除，也就是说把 ⑥ 替换为一个叶结点，由于替换后的叶结点包含着编号为 {7,15} 的训练样本，于是，这个叶结点的类别被标记为 “好瓜”，OK，这时我们看一下此时的决策树在验证集上的精度，为 57.1%。57.1% > 42.9%，因此我们决定剪枝。


<center>

![](http://images.iterate.site/blog/image/180626/h44A5GEmDg.png?imageslim){ width=55% }

</center>


接着我们考察图 4.5 中的结点 ⑤，如果把以它为父节点的子树替换为一个叶结点，替换后的叶结点包含编号为 {6,7,15} 的训练样例，这个叶结点类别被标记为 “好瓜” ，此时的决策树验证集精度仍为 57.1%。于是，我们可以不进行剪枝。<span style="color:red;">注意：此种情形下检证集精度虽然没有提高，但是根据奥卡姆剃刀准则，剪枝后的模型更好。因此，实际的决策树算法在此种情形下通常要进行剪枝，本书为绘图的方便，采取了不剪枝的保守策略。实际上一般都是要剪的。这里图方便没减而已。好吧。</span>

类似的，我们对应结点 ②、结点 ③、结点 ①。

最终，我们就得到了图 4.7 所示的决策树，其验证集精度为 71.4%。

<span style="color:red;">整体过程还是很清晰的。</span>






# 相关

- 《机器学习》周志华
