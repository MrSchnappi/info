---
title: 02 基于有限的训练样本集尽可能准确地估计出后验概率
toc: true
date: 2018-06-28 08:27:17
---

# 基于有限的训练样本集尽可能准确地估计出后验概率

然而，在现实任务中这通常难以直接获得。

从这个角度来看，机器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率 $P(c | \boldsymbol{x})$ 。大体来说，主要有两种策略：

- 给定 $\boldsymbol{x}$ 可通过直接建模  $P(c | \boldsymbol{x})$ 来 预测 $c$，这样得到的是“判别式模型”(discriminative models);
- 也可先对联合概率分布  $P(\boldsymbol{x}, c)$ 建模，然后再由此获得 $P(c | \boldsymbol{x})$ , 这样得到的是“生成式模型”(generative models)。

显然，前面介绍的决策树、BP神经网络、支持向量机等，都可归入判别式模型的范畴。<span style="color:red;">要补充下。</span>

对生成式模型来说，必然考虑：

$$
P(c | \boldsymbol{x})=\frac{P(\boldsymbol{x}, c)}{P(\boldsymbol{x})}\tag{7.7}
$$

基于贝叶斯定理，$P(c | \boldsymbol{x})$ 可写为

$$
P(c | \boldsymbol{x})=\frac{P(c) P(\boldsymbol{x} | c)}{P(\boldsymbol{x})}\tag{7.8}
$$


> $$P(c|\boldsymbol x)=\cfrac{P(c)P(\boldsymbol x|c)}{P(\boldsymbol x)}$$
> [解析]：最小化误差，也就是最大化 P(c|x)，但由于 P(c|x)属于后验概率无法直接计算，由贝叶斯公式可计算出:
> $$P(c|\boldsymbol x)=\cfrac{P(c)P(\boldsymbol x|c)}{P(\boldsymbol x)}$$
> $P(\boldsymbol x)$ 可以省略，因为我们比较的时候 $P(\boldsymbol x)$ 一定是相同的，所以我们就是用历史数据计算出 $P(c)$ 和 $P(\boldsymbol x|c)$。
> 1. $P(c)$ 根据大数定律，当样本量到了一定程度且服从独立同分布，c的出现的频率就是 c 的概率。
> 2. $P(\boldsymbol x|c)$，因为 $\boldsymbol x$ 在这里不对单一元素是个矩阵，涉及 n 个元素，不太好直接统计分类为 c 时，$\boldsymbol x$ 的概率，所以我们根据假设独立同分布，对每个 $\boldsymbol x$ 的每个特征分别求概率
> $$P(\boldsymbol x|c)=P(x_1|c)*P(x_2|c)*P(x_3|c)...*P(x_n|c)$$
> 这个式子就可以很方便的通过历史数据去统计了，比如特征 n，就是在分类为 c 时特征 n 出现的概率，在数据集中应该是用 1 显示。
> 但是当某一概率为 0 时会导致整个式子概率为 0，所以采用拉普拉斯修正
>
> 当样本属性独依赖时，也就是除了 c 多加一个依赖条件，式子变成了
> $$∏_{i=1}^n P(x_i|c,p_i)$$
> $p_i$ 是 $x_i$ 所依赖的属性
>
> 当样本属性相关性未知时，我们采用贝叶斯网的算法，对相关性进行评估，以找出一个最佳的分类模型。
>
> 当遇到不完整的训练样本时，可通过使用 EM 算法对模型参数进行评估来解决。


其中，$P(c)$ 是类“先验”(prior)概率；$P(x丨 c)$ 是样本 $\boldsymbol{x}$ 相对于类标记 $c$ 的类条件概率(class-conditional probability)，或称为“似然” (likelihood); $P(\boldsymbol{x})$ 是 用于归一化的“证据”(evidence)因子。对给定样本 x 证据因子 $P(\boldsymbol{x})$ 与类标记无关，因此估计 $P(c | \boldsymbol{x})$ 的问题就转化为如何基于训练数据 $D$ 来估计先验 $P(c)$ 和似然  $P(c | \boldsymbol{x})$ 。

类先验概率表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$ 可通过各类样本出现的频率来进行估计.

对类条件概率 $P(\boldsymbol{x} | c)$ 来说，由于它涉及关于 $\boldsymbol{x}$ 所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。例如，假设样本的 $d$ 个属性都是二值的，则样本空间将有 $2^d$ 种可能的取值，在现实应用中，这个值往往远大于训练样本数 $m$ ，也就是说，很多样本取值在训练集中根本没有出现，直接使用频率来估计 $P(\boldsymbol{x} | c)$ 显然不可行，因为 “未被观测到” 与 “出现概率为零” 通常是不同的。<span style="color:red;">是的是的，未被观测到与出现概率为 0 是不同的。</span>







# 相关

- 《机器学习》周志华
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)
