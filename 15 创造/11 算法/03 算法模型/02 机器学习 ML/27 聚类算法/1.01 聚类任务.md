---
title: 1.01 聚类任务
toc: true
date: 2018-06-28 17:10:31
---
# 聚类任务

聚类就是按照某个特定标准把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。


人具有很强的归纳思考能力，善于从一大堆碎片化的事实或者数据中寻找普遍规律，并得到具有逻辑性的结论。以用户观看视频的行为为例，可以存在多种直观的归纳方式，比如从喜欢观看内容的角度，可以分为动画片、偶像剧、科幻片等；从常使用的设备角度，可以分为台式电脑、手机、平板便携式设备、电视等；从使用时间段上看，有傍晚、中午、每天、只在周末观看的用户，等等。对所有用户进行有效的分组对于理解用户并推荐给用户合适的内容是很重要的。<span style="color:red;">是的，没想到单单推荐就有这么多门道。</span>

通常这类问题没有观测数据的标签或者分组信息，需要通过算法模型来寻求数据内在的结构和模式。



在 “无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。此类学习任务中研究最多、应用最广的是 “聚类” (clustering).


聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster)。通过这样的划分，每个簇可能对应于一些潜在的概念(类别)，如“浅色瓜” “深色瓜”，“有籽瓜” “无籽瓜”，甚至“本地瓜” ，“外地瓜”等；需说明的是，这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构，簇所对应的概念语义需由使用者来把握和命名.<span style="color:red;">嗯。</span>

形式化地说，假定样本集 $D=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \ldots, \boldsymbol{x}_{m}\right\}$  包含 $m$ 个无标记样本，每个样本 $\boldsymbol{x}_{i}=\left(x_{i 1} ; x_{i 2} ; \ldots ; x_{i n}\right)$  是一个 $n$ 维特征向量，则聚类算法将样本集 $D$ 划分为 $k$ 个不相交的簇 $\left\{C_{l} | l=1,2 ; \ldots, k\right\}$ ，其中 $C_{l^{\prime}} \cap_{l^{\prime} \neq l} C_{l}=\varnothing$ 且 $D=\bigcup_{l=1}^{k} C_{l}$ 。相应地，我们用 $\lambda_{j} \in\{1,2, \ldots, k\}$ 表示样本 $\boldsymbol{x}_{j}$ 的“簇标记” (cluster label)，即 $\boldsymbol{x}_{j} \in C_{\lambda_{j}}$ 。于是，聚类的结果可用包含 $m$ 个元素的簇标记 $\boldsymbol{\lambda}=\left(\lambda_{1} ; \lambda_{2} ; \ldots ; \lambda_{m}\right)$ 表示。

聚类既能作为一个单独过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程。例如，在一些商业应用中需对新用户的类型进行判别，但定义“用户类型”对商家来说却可能不太容易，此时往往可先对用户数据进行聚类，根据聚类结果将每个簇定义为一个类，然后再基于这些类训练分类模型，用于判别新用户的类型。<span style="color:red;">嗯。</span>

基于不同的学习策略，人们设计出多种类型的聚类算法。本章后半部分将对不同类型的代表性算法进行介绍，


但在此之前，我们先讨论聚类算法涉及的两个基本问题：性能度量和距离计算。



聚类就是按照某个特定标准(如距离准则)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同数据尽量分离。


# 相关

- 《机器学习》周志华
