---
title: 1.02 对于聚类的思考
toc: true
date: 2019-08-27
---

## 2. k-均值聚类

另外一个简单的表示学习算法是 k-均值聚类。


关于聚类的一个问题是，聚类问题本身是病态的。这是说没有单一的标准去度量聚类的数据在真实世界中效果如何。<span style="color:red;">是的。</span>我们可以度量聚类的性质，例如类中元素到类中心点的欧几里得距离的均值。这使我们可以判断从聚类分配中重建训练数据的效果如何。然而我们不知道聚类的性质是否很好地对应到真实世界的性质。<span style="color:red;">是的。</span>此外，可能有许多不同的聚类都能很好地对应到现实世界的某些属性。我们可能希望找到和一个特征相关的聚类，但是得到了一个和任务无关的，同样是合理的不同聚类。例如，假设我们在包含红色卡车图片、红色汽车图片、灰色卡车图片和灰色汽车图片的数据集上运行两个聚类算法。如果每个聚类算法聚两类，那么可能一个算法将汽车和卡车各聚一类，另一个根据红色和灰色各聚一类。假设我们还运行了第 3 个聚类算法，用来决定类别的数目。这有可能聚成了 4 类，红色卡车、红色汽车、灰色卡车和灰色汽车。现在这个新的聚类至少抓住了属性的信息，但是丢失了相似性信息。红色汽车和灰色汽车在不同的类中，正如红色汽车和灰色卡车也在不同的类中。该聚类算法没有告诉我们灰色汽车和红色汽车的相似度比灰色卡车和红色汽车的相似度更高。我们只知道它们是不同的。<span style="color:red;">是呀。</span>

这些问题说明了一些我们可能更偏好于分布式表示(相对于 one-hot表示而言)的原因。分布式表示可以对每个车辆赋予两个属性 - 一个表示它的颜色，一个表示它是汽车还是卡车。目前仍然不清楚什么是最优的分布式表示(学习算法如何知道我们关心的两个属性是颜色和是否汽车或卡车，而不是制造商和车龄？)，但是多个属性减少了算法去猜我们关心哪一个属性的负担，允许我们通过比较很多属性而非测试一个单一属性来细粒度地度量相似性。<span style="color:red;">嗯，那么怎么分布式表示呢？怎么拆分的？</span>



# 相关

- 《深度学习》花书
