---
title: 53 模型融合-投票法
toc: true
date: 2019-08-27
---


## 投票法

对分类任务来说，学习器 $h_i$ 将从类别标记集合 $\left\{c_{1}, c_{2}, \ldots, c_{N}\right\}$ 中预测出一个标记，最常见的结合策略是使用投票法(voting)。为便于讨论，我们将 $h_i$ 在样本 $\boldsymbol{x}$ 上的预测输出表示为一个 N 维向量 $\left(h_{i}^{1}(\boldsymbol{x}) ; h_{i}^{2}(\boldsymbol{x}) ; \ldots ; h_{i}^{N}(\boldsymbol{x})\right)$，其中 $h_{i}^{j}(\boldsymbol{x})$ 是 $h_i$ 在类别标记 $c_j$ 上的输出。

- 绝对多数投票法(majority voting)

$$
H(\boldsymbol{x})=\left\{\begin{array}{cl}{c_{j},} & {\text { if } \sum_{i=1}^{T} h_{i}^{j}(\boldsymbol{x})>0.5 \sum_{k=1}^{N} \sum_{i=1}^{T} h_{i}^{k}(\boldsymbol{x})} \\ {\text { reject, }} & {\text { otherwise. }}\end{array}\right.
$$

即若某标记得票过半数，则预测为该标记；否则拒绝预测。

- 相对多数投票法(plurality voting)

$$
H(\boldsymbol{x})=c_{\underset{j}{\operatorname{argmax}} \sum_{i=1}^{T} h_{i}^{j}(\boldsymbol{x})}
$$

即预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取一个。

- 加权投票法(weighted voting)

$$
H(\boldsymbol{x})=c_{\mathrm{arg} \max } \sum_{i=1}^{T} w_{i} h_{i}^{j}(\boldsymbol{x})
$$

与加权平均法类似，$w_i$ 是 $h_i$ 的权重，通常 $w_i\geq 0$ , $\sum_{i=1}^{T} w_{i}=1$ 。


标准的绝对多数投票法(8.24)提供了 “拒绝预测”选项，这在可靠性要求 较高的学习任务中是一个很好的机制。但若学习任务要求必须提供预测结果， 则绝对多数投票法将退化为相对多数投票法。因此，在不允许拒绝预测的任务 中，绝对多数、相对多数投票法统称为“多数投票法”。

式(8.24)~(8.26)没有限制个体学习器输出值的类型。在现实任务中，不同 类型个体学习器可能产生不同类型的 $h_{i}^{j}(\boldsymbol{x})$ 值，常见的有：

- 类标记: $h_{i}^{j}(\boldsymbol{x}) \in\{0,1\}$ ，若 $h_i$ 将样本 $\boldsymbol{x}$ 预测为类别 $c_j$ 则取值为 $1$，否则为 $0$。使用类标记的投票亦称 “硬投票” (hard voting)。
- 类概率：$h_{i}^{j}(\boldsymbol{x}) \in[0,1]$，相当于对后验概率 $P\left(c_{j} | \boldsymbol{x}\right)$ 的一个估计。使用类概率的投票亦称 “软投票” (soft voting)。

不同类型的 $h_{i}^{j}(\boldsymbol{x})$ 值不能混用。对一些能在预测出类别标记的同时产生分类置信度的学习器，其分类置信度可转化为类概率使用。若此类值未进 行规范化，例如支持向量机的分类间隔值，则必须使用一些技术如 Platt 缩 放(Platt scaling) 、等分回归(isotonic regression) 等进行 “校准” (calibration)后才能作为类概率使用。

有趣的是，虽然分类器估计出的类概率值一般都不太准确，但基于类概率进行结合却往往比直接基于类标记进行结合性能更好。需注意的是，若基学习器的类型不同，则其类概率值不能直接进行比较；在此种情形下，通常可将类概率输出转化为类 标记输出(例如将类概率输出最大的 $h_{i}^{j}(\boldsymbol{x})$ 设为 $1$，其他设为 $0$ )然后再投票。


# 相关

- 《机器学习》周志华
