---
title: 45 近似推断-变分推断
toc: true
date: 2018-08-21 18:16:23
---

# 近似推断-变分推断

变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近 似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布。

在学习变分推断之前，我们先介绍概率图模型一种简洁的表示方法---盘式记法(plate notation) 。图 14.10 给出了一个简单的例子。 图 14.10(a)表示 $N$ 个变量 $\{x_1,x_2,\cdots,x_N\}$ 均依赖于其他变量 $\mathbf{Z}$ 。在图 14.10(b)中，相互独立的、由相同机制生成的多个变量被放在一个方框(盘)内， 并在方框中标出类似变量重复出现的个数 $N$ ；方框可以嵌套。通常用阴影标注出已知的、能观察到的变量，如图 14.10中的变量 x。在很多学习任务中，对属性变量使用盘式记法将使得图表示非常简洁。


<center>

![](http://images.iterate.site/blog/image/180701/40L08aGHiK.png?imageslim){ width=55% }


</center>


在图 14.10(b)中，所有能观察到的变量 $x$ 的联合分布的概率密度函数是

$$
p(\mathbf{x} | \Theta)=\prod_{i=1}^{N} \sum_{\mathbf{z}} p\left(x_{i}, \mathbf{z} | \Theta\right)\tag{14.29}
$$

所对应的对数似然函数为：

$$
\ln p(\mathbf{x} | \Theta)=\sum_{i=1}^{N} \ln \left\{\sum_{\mathbf{z}} p\left(x_{i}, \mathbf{z} | \Theta\right)\right\}\tag{14.30}
$$

其中 $\mathbf{x}=\left\{x_{1}, x_{2}, \dots, x_{N}\right\}$ ，$\Theta$ 是 $\mathbf{x}$ 与 $\mathbf{z}$ 服从的分布参数。

一般来说，图 14.10所对应的推断和学习任务主要是由观察到的变量 $\mathbf{x}$ 来估计隐变量 $\mathbf{z}$ 和分布参数变量 $\Theta$ ，即求解 $p(\mathbf{z} | \mathbf{x}, \Theta)$ 和 $\Theta$ 。


概率模型的参数估计通常以最大化对数似然函数为手段。对式(14.30)可使用 EM 算法：

- 在 E 步，根据 t 时刻的参数 $\Theta^t$ 对 $p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right)$ 进行推断，并计算联合似然函数 $p(\mathbf{x}, \mathbf{z} | \Theta)$ ;
- 在 M 步，基于 E 步的结果进行最大化寻优，即对关于变 量 $\Theta$ 的函数 $\mathcal{Q}\left(\Theta ; \Theta^{t}\right)$ 进行最大化从而求取

$$
\begin{aligned} \Theta^{t+1} &=\underset{\Theta}{\arg \max } \mathcal{Q}\left(\Theta ; \Theta^{t}\right) \\ &=\underset{\Theta}{\arg \max } \sum_{\mathbf{z}} p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right) \ln p(\mathbf{x}, \mathbf{z} | \Theta) \end{aligned}\tag{14.31}
$$

式(14.31)中的 $\mathcal{Q}\left(\Theta ; \Theta^{t}\right)$ 实际上是对数联合似然函数 $\ln p(\mathbf{x}, \mathbf{z} | \Theta)$ 在分布 $p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right)$ 下的期望，当分布  $p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right)$ 与变量 $\mathbf{z}$ 的真实后验分布相等时， $\mathcal{Q}\left(\Theta ; \Theta^{t}\right)$ 近似于对数似然函数。于是，EM 算法最终可获得稳定的参数 $\Theta$ ，而隐变量 $\mathbf{z}$ 的分布也能通过该参数获得。

需注意的是, $p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right)$ 未必是隐变量 $\mathbf{z}$ 服从的真实分布，而只是一个近似分布。若将这个近似分布用 $q(\mathbf{z})$ 表示，则不难验证

$$
\ln p(\mathbf{x})=\mathcal{L}(q)+\mathrm{KL}(q \| p)\tag{14.32}
$$


> $${\rm ln}p(x)=\mathcal{L}(q)+{\rm KL}(q \parallel p)$$
>
> [推导]：根据条件概率公式 $p(x,z)=p(z|x)*p(x)$，可以得到 $p(x)=\frac{p(x,z)}{p(z|x)}$
>
> 然后两边同时作用 ${\rm ln}$ 函数，可得 ${\rm ln}p(x)={\rm ln}\frac{p(x,z)}{p(z|x)}$    (1)
>
> 因为 $q(z)$ 是概率密度函数，所以 $1=\int q(z)dz$
>
> 等式两边同时乘以 ${\rm ln}p(x)$，因为 ${\rm ln}p(x)$ 是不关于变量 $z$ 的函数，所以 ${\rm ln}p(x)$ 可以拿进积分里面，得到 ${\rm ln}p(x)=\int q(z){\rm ln}p(x)dz$
> $$
> \begin{aligned}
> {\rm ln}p(x)&=\int q(z){\rm ln}p(x) \\
>  &=\int q(z){\rm ln}\frac{p(x,z)}{p(z|x)}\qquad(带入公式(1))\\
>  &=\int q(z){\rm ln}\bigg\{\frac{p(x,z)}{q(z)}\cdot\frac{q(z)}{p(z|x)}\bigg\} \\
>  &=\int q(z)\bigg({\rm ln}\frac{p(x,z)}{q(z)}-{\rm ln}\frac{p(z|x)}{q(z)}\bigg) \\
>   &=\int q(z){\rm ln}\bigg\{\frac{p(x,z)}{q(z)}\bigg\}-\int q(z){\rm ln}\frac{p(z|x)}{q(z)} \\
>   &=\mathcal{L}(q)+{\rm KL}(q \parallel p)\qquad(根据\mathcal{L}和{\rm KL}的定义)
> \end{aligned}
> $$


其中

$$
\mathcal{L}(q)=\int q(\mathbf{z}) \ln \left\{\frac{p(\mathbf{x}, \mathbf{z})}{q(\mathbf{z})}\right\} \mathrm{d} \mathbf{z}\tag{14.33}
$$
$$
\mathrm{KL}(q \| p)=-\int q(\mathbf{z}) \ln \frac{p(\mathbf{z} | \mathbf{x})}{q(\mathbf{z})} \mathrm{d} \mathbf{z}\tag{14.34}
$$


然而在现实任务中，E 步对 $p\left(\mathbf{z} | \mathbf{x}, \Theta^{t}\right)$  的推断很可能因 $\mathbf{z}$ 模型复杂而难以进行，此时可借助变分推断。通常假设 $\mathbf{z}$ 服从分布

$$
q(\mathbf{z})=\prod_{i=1}^{M} q_{i}\left(\mathbf{z}_{i}\right)\tag{14.35}
$$


即假设复杂的多变量 $\mathbf{z}$ 可拆解为一系列相互独立的多变量 $\boldsymbol{z}_{i}$ 。更重要的是， 可以令 $q_i$ 分布相对简单或有很好的结构，例如假设 $q_i$ 为指数族(exponential family)分布，此时有

$$
\begin{aligned} \mathcal{L}(q) &=\int \prod_{i} q_{i}\left\{\ln p(\mathbf{x}, \mathbf{z})-\sum_{i} \ln q_{i}\right\} \mathrm{d} \mathbf{z} \\ &=\int q_{j}\left\{\int \ln p(\mathbf{x}, \mathbf{z}) \prod_{i \neq j} q_{i} \mathrm{d} \mathbf{z}_{i}\right\} \mathrm{d} \mathbf{z}_{j}-\int q_{j} \ln q_{j} \mathrm{d} \mathbf{z}_{j}+\text { const } \\ &=\int q_{j} \ln \tilde{p}\left(\mathbf{x}, \mathbf{z}_{j}\right) \mathrm{d} \mathbf{z}_{j}-\int q_{j} \ln q_{j} \mathrm{d} \mathbf{z}_{j}+\text { const } \end{aligned}\tag{14.36}
$$


> $$
> \begin{aligned}
> \mathcal{L}(q)&=\int \prod_{i}q_{i}\bigg\{ {\rm ln}p({\rm \mathbf{x},\mathbf{z}})-\sum_{i}{\rm ln}q_{i}\bigg\}d{\rm\mathbf{z}} \\
> &=\int q_{j}\bigg\{\int p(x,z)\prod_{i\ne j}q_{i}d{\rm\mathbf{z_{i}}}\bigg\}d{\rm\mathbf{z_{j}}}-\int q_{j}{\rm ln}q_{j}d{\rm\mathbf{z_{j}}}+{\rm const} \\
> &=\int q_{j}{\rm ln}\tilde{p}({\rm \mathbf{x},\mathbf{z_{j}}})d{\rm\mathbf{z_{j}}}-\int q_{j}{\rm ln}q_{j}d{\rm\mathbf{z_{j}}}+{\rm const}
> \end{aligned}
> $$
>
> [推导]：
> $$
> \mathcal{L}(q)=\int \prod_{i}q_{i}\bigg\{ {\rm ln}p({\rm \mathbf{x},\mathbf{z}})-\sum_{i}{\rm ln}q_{i}\bigg\}d{\rm\mathbf{z}}=\int\prod_{i}q_{i}{\rm ln}p({\rm \mathbf{x},\mathbf{z}})d{\rm\mathbf{z}}-\int\prod_{i}q_{i}\sum_{i}{\rm ln}q_{i}d{\rm\mathbf{z}}
> $$
> 公式可以看做两个积分相减，我们先来看左边积分 $\int\prod_{i}q_{i}{\rm ln}p({\rm \mathbf{x},\mathbf{z}})d{\rm\mathbf{z}}$ 的推导。
> $$
> \begin{aligned}
> \int\prod_{i}q_{i}{\rm ln}p({\rm \mathbf{x},\mathbf{z}})d{\rm\mathbf{z}} &= \int q_{j}\prod_{i\ne j}q_{i}{\rm ln}p({\rm \mathbf{x},\mathbf{z}})d{\rm\mathbf{z}} \\
> &= \int q_{j}\bigg\{\int{\rm ln}p({\rm \mathbf{x},\mathbf{z}})\prod_{i\ne j}q_{i}d{\rm\mathbf{z_{i}}}\bigg\}d{\rm\mathbf{z_{j}}}\qquad (先对{\rm\mathbf{z_{j}}}求积分，再对{\rm\mathbf{z_{i}}}求积分)
> \end{aligned}
> $$
> 这个就是教材中的 $14.36$ 左边的积分部分。
>
> 我们现在看下右边积分的推导 $\int\prod_{i}q_{i}\sum_{i}{\rm ln}q_{i}d{\rm\mathbf{z}}$ 的推导。
>
> 在此之前我们看下 $\int\prod_{i}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z}}$ 的计算
> $$
> \begin{aligned}
> \int\prod_{i}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z}}&= \int q_{i^{\prime}}\prod_{i\ne i^{\prime}}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z}}\qquad (选取一个变量 q_{i^{\prime}}, i^{\prime}\ne k) \\
> &=\int q_{i^{\prime}}\bigg\{\int\prod_{i\ne i^{\prime}}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z_{i}}}\bigg\}d{\rm\mathbf{z_{i^{\prime}}}}
> \end{aligned}
> $$
> $\bigg\{\int\prod_{i\ne i^{\prime}}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z_{i}}}\bigg\}$ 部分与变量 $q_{i^{\prime}}$ 无关，所以可以拿到积分外面。又因为 $\int q_{i^{\prime}}d{\rm\mathbf{z_{i^{\prime}}}}=1$，所以
> $$
> \begin{aligned}
> \int\prod_{i}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z}}&=\int\prod_{i\ne i^{\prime}}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z_{i}}} \\
> &= \int q_{k}{\rm ln}q_{k}d{\rm\mathbf{z_k}}\qquad (所有 k 以外的变量都可以通过上面的方式消除)
> \end{aligned}
> $$
> 有了这个结论，我们再来看公式
> $$
> \begin{aligned}
> \int\prod_{i}q_{i}\sum_{i}{\rm ln}q_{i}d{\rm\mathbf{z}}&= \int\prod_{i}q_{i}{\rm ln}q_{j}d{\rm\mathbf{z}} + \sum_{k\ne j}\int\prod_{i}q_{i}{\rm ln}q_{k}d{\rm\mathbf{z}} \\
> &= \int q_{j}{\rm ln}q_{j}d{\rm\mathbf{z_j}} + \sum_{z\ne j}\int q_{k}{\rm ln}q_{k}d{\rm\mathbf{z_k}}\qquad (根据上面结论) \\
> &= \int q_{j}{\rm ln}q_{j}d{\rm\mathbf{z_j}} + {\rm const} \qquad (这里我们关心的是 q_{j}，其他变量可以视为{\rm const})
> \end{aligned}
> $$
> 这个就是 $14.36$ 右边的积分部分。


其中

$$
\ln \tilde{p}\left(\mathbf{x}, \mathbf{z}_{j}\right)=\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]+\text { const }\tag{14.37}
$$
$$
\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]=\int \ln p(\mathbf{x}, \mathbf{z}) \prod_{i \neq j} q_{i} \mathrm{d} \mathbf{z}_{i}\tag{14.38}
$$


我们关心的是 $q_j$ ，因此可固定 $q_{i\neq j}$ 再对 $\mathcal{L}(q)$ 进行最大化，可发现 式(14.36)等于 $-\mathrm{KL}\left(q_{j} \| \tilde{p}\left(\mathbf{x}, \mathbf{z}_{j}\right)\right)$ ，即当 $q_{j}=\tilde{p}\left(\mathbf{x}, \mathbf{z}_{j}\right)$ 时 $\mathcal{L}(q)$ 最大。于是可知变量子集 $\mathbf{z}_{j}$ 所服从的最优分布 $q_j^*$ 应满足

$$
\ln q_{j}^{*}\left(\mathbf{z}_{j}\right)=\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]+\text { const }\tag{14.39}
$$

即：

$$
q_{j}^{*}\left(\mathbf{z}_{j}\right)=\frac{\exp \left(\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]\right)}{\int \exp \left(\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]\right) \mathrm{d} \mathbf{z}_{j}}\tag{14.40}
$$

> $$
> \begin{aligned}
> q_j^*(\mathbf{z}_j) = \frac{ \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) }{\int \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) \mathrm{d}\mathbf{z}_j}
> \end{aligned}
> $$
>
> [推导]：由 $14.39$ 去对数并积分
> $$
> \begin{aligned}
>  \int q_j^*(\mathbf{z}_j)\mathrm{d}\mathbf{z}_j &=\int \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right )\cdot\exp(const) \, \mathrm{d}\mathbf{z}_j \\
>  &=\exp(const) \int \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) \, \mathrm{d}\mathbf{z}_j \\
>  &= 1
>  \end{aligned}
>  \tag{7}
> $$
> 所以
> $$
> \exp(const)  = \dfrac{1}{\int \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) \, \mathrm{d}\mathbf{z}_j}  \\
> \tag{8}
> $$
>
> $$
> \begin{aligned}
>   q_j^*(\mathbf{z}_j) &= \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right )\cdot\exp(const) \, \mathrm{d}\mathbf{z}_j \\
>  &= \frac{ \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) }{\int \exp\left ( \mathbb{E}_{i\neq j}[\ln (p(\mathbf{x},\mathbf{z}))] \right ) \mathrm{d}\mathbf{z}_j}
>  \end{aligned}
>  \tag{9}
> $$

换言之，在式(14.35)这个假设下，变量子集 $\mathbf{z}_{j}$ 最接近真实情形的分布由式(14.40)给出。

显然，基于式(14.35)的假设，通过恰当地分割独立变量子集 $\mathbf{z}_{j}$ 并选择 $q_i$ 服从的分布,  $\mathbb{E}_{i \neq j}[\ln p(\mathbf{x}, \mathbf{z})]$ 往往有闭式解，这使得基于式(14.40)能高效地对隐变量 $z$ 进行推断。事实上，由式(14.38)可看出，对变量 $\mathbf{z}_{j}$ 分布 $q_j^*$ 进行估计时融合了 $\mathbf{z}_{j}$ 之外的其他 $\mathbf{z}_{i \neq j}$ 的信息，这是通过联合似然函数 $\ln p(\mathbf{x}, \mathbf{z})$ 在 $\mathbf{z}_{j}$ 之外的隐变量分布上求期望得到的，因此亦称“平均场”(mean field)方法。

在实践中使用变分法时，最重要的是考虑如何对隐变量进行拆解，以及假 设各变量子集服从何种分布，在此基础上套用式(14.40)的结论再结合 EM 算法 即可进行概率图模型的推断和参数估计。

显然，若隐变量的拆解或变量子集的 分布假设不当，将会导致变分法效率低、效果差。







# 相关

- 《机器学习》周志华
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)
