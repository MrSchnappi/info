---
title: 12 压缩感知问题的求解
toc: true
date: 2019-08-27
---


## 压缩感知

假定有长度为 $m$ 的离散信号 $\boldsymbol{x}$，不妨假定我们以远小于奈奎斯特采样定理要求的采样率进行采样，得到长度为 $n$ 的采样后信号 $\boldsymbol{y}$,$n\ll m$ ，即

$$
\boldsymbol{y}=\mathbf{\Phi} \boldsymbol{x}
$$

其中 $\mathbf{\Phi} \in \mathbb{R}^{n \times m}$ 是对信号 $\boldsymbol{x}$ 的测量矩阵，它确定了以什么频率进行采样以及如何将采样样本组成采样后的信号。

在已知离散信号 $\boldsymbol{x}$ 和测量矩阵 $\mathbf{\Phi}$ 时要得到测量值 $\boldsymbol{y}$ 很容易，然而，若将测量值和测量矩阵传输出去，接收方能还原出原始信号 $\boldsymbol{x}$ 吗？

一般来说，答案是 “No”，这是由于 $n\ll m$ ，因此 $\boldsymbol{y}$， $\boldsymbol{x}$，$\mathbf{\Phi}$ 组成的式(11.19)是一个欠定方程，无法轻易求出数值解。


现在不妨假设存在某个线性变换 $\mathbf{\Psi} \in \mathbb{R}^{m \times m}$ 。使得 $\boldsymbol{x}$ 可表示为 $\mathbf{\Psi}_{\boldsymbol{S}}$ 于是 $\boldsymbol{y}$ 可表示为

$$
\boldsymbol{y}=\boldsymbol{\Phi} \boldsymbol{\Psi} \boldsymbol{s}=\mathbf{A} \boldsymbol{s}
$$

其中 $\mathbf{A}=\mathbf{\Phi} \Psi \in \mathbb{R}^{n \times m}$ 。于是，若能根据 $\boldsymbol{y}$ 恢复出 $\boldsymbol{s}$，则可通过 $\boldsymbol{x}=\boldsymbol{\Psi} \boldsymbol{s}$ 来恢复出信号 $\boldsymbol{x}$。

粗看起来式(11.20)没有解决任何问题，因为式(11.20)中恢复信号 $\boldsymbol{s}$ 这个逆问题仍是欠定的。然而有趣的是，若 $\boldsymbol{s}$ 具有稀疏性，则这个问题竟能很好地得以解决！这是因为稀疏性使得未知因素的影响大为减少。此时式(11.20)中的 $\mathbf{\Psi}$  称为稀疏基，而 $\mathbf{A}$ 的作用则类似于字典，能将信号转换为稀疏表示。

事实上，在很多应用中均可获得具有稀疏性的 $\boldsymbol{s}$，例如图像或声音的数字信号通常在时域上不具有稀疏性，但经过傅里叶变换、余弦变换、小波变换等处理后却会转化为频域上的稀疏信号。

显然，与特征选择、稀疏表示不同，压缩感知关注的是如何利用信号本身所具有的稀疏性，从部分观测样本中恢复原信号。

通常认为，压缩感知分为 “感知测量” 和 “重构恢复” 这两个阶段。

- “感知测量” 关注如何对原始信号进行处理以获得稀疏样本表示，这方面的内容涉及傅里叶变换、小波变换以及 11.5 节介绍的字典学习、稀疏编码等，不少技术在压缩感知提出之前就已在信号处理等领域有很多研究；
- “重构恢复” 关注的是如何基于稀疏性从少量观测中恢复原信号，这是压缩感知的精髓，当我们谈到压缩感知时，通常是指该部分。<span style="color:red;">简直厉害。</span>

## 限定等距性

压缩感知的相关理论比较复杂，下面仅简要介绍一下 “限定等距性” (Restricted Isometry Property，简称 RIP)

对大小为 $n \times m(n \ll m)$ 的矩阵 $\mathbf{A}$ ，若存在常数 $\delta_k\in (0,1)$ 使得对于任意向量 $\boldsymbol{s}$ 和 $\mathbf{A}$ 的所有子矩阵 $\mathbf{A}_{k} \in \mathbb{R}^{n \times k}$ 有

$$
\left(1-\delta_{k}\right)\|s\|_{2}^{2} \leqslant\left\|\mathbf{A}_{k} s\right\|_{2}^{2} \leqslant\left(1+\delta_{k}\right)\|\boldsymbol{s}\|_{2}^{2}
$$

则称 $\mathbf{A}$ 满足 $k$ 限定等距性(k-RIP)。此时可通过下面的优化问题近乎完美地从 $\boldsymbol{y}$ 中恢复出稀疏信号 $\boldsymbol{s}$，进而恢复出 $\boldsymbol{x}$:

$$
\begin{aligned} \min _{\boldsymbol{s}} &\|\boldsymbol{s}\|_{0} \\ \text { s.t. } & \boldsymbol{y}=\mathbf{A} \boldsymbol{s} \end{aligned}
$$


然而，式(11.22)涉及 $\mathrm{L}_{0}$ 范数最小化，这是个 NP 难问题。值得庆幸的是， $\mathrm{L}_{1}$  范数最小化在一定条件下与 $\mathrm{L}_{0}$ 范数最小化问题共解，于是实际上只需关注

$$
\begin{array}{l}{\min _{s}\|s\|_{1}} \\ {\text { s.t. } y=\mathbf{A} s}\end{array}
$$

这样，压缩感知问题就可通过 $\mathrm{L}_{1}$ 范数最小化问题求解，例如式(11.23)可转化为 LASSO 的等价形式再通过近端梯度下降法求解，即使用 “基寻踪去噪” (Basis Pursuit De-Noising)。







# 相关

- 《机器学习》周志华
