---
title: 2.03 结合半监督学习
toc: true
date: 2019-06-05
---

# 半监督学习

相当于有更多的信息添加进来。

在半监督学习的框架下，$P(\mathbf x)$ 产生的未标记样本和 $P(\mathbf x, \mathbf y)$ 中的标记样本都用于估计 $P(\mathbf y \mid \mathbf x)$ 或者根据 $\mathbf x$ 预测 $\mathbf y$。

在深度学习的背景下，半监督学习通常指的是学习一个表示 $\boldsymbol h = f(\boldsymbol x)$。学习表示的目的是使相同类中的样本有类似的表示。无监督学习可以为如何在表示空间聚集样本提供有用线索。在输入空间紧密聚集的样本应该被映射到类似的表示。在许多情况下，新空间上的线性分类器可以达到较好的泛化。这种方法的一个经典变种是使用主成分分析作为分类前（在投影后的数据上分类）的预处理步骤。

我们可以构建这样一个模型，其中生成模型 $P(\mathbf x)$ 或 $P(\mathbf x, \mathbf y)$ 与判别模型 $P(\mathbf y \mid \mathbf x)$ 共享参数，而不用分离无监督和监督部分。我们权衡监督模型准则 $-\log P(\mathbf y \mid \mathbf x)$ 和无监督或生成模型准则（如 $-\log P(\mathbf x)$ 或 $-\log P(\mathbf x, \mathbf y)$）。生成模型准则表达了对监督学习问题解的特殊形式的先验知识，即 $P(\mathbf x)$ 的结构通过某种共享参数的方式连接到 $P(\mathbf y \mid \mathbf x)$。通过控制在总准则中的生成准则，我们可以获得比纯生成或纯判别训练准则更好的权衡。

Russ 描述了一种学习回归核机器中核函数的方法，其中建模 $P(\mathbf x)$ 时使用的未标记样本大大提高了 $P(\mathbf y \mid \mathbf x)$ 的效果。



# 相关

- 《深度学习》花书
