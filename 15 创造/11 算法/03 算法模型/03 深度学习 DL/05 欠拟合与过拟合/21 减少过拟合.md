---
title: 21 减少过拟合
toc: true
date: 2019-08-31
---

**降低“过拟合”风险的方法**

1. 从数据入手，获得更多的训练数据。使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据。<span style="color:red;">生成式对抗网络是怎么用来生成大量的新训练数据的？</span>
2. 降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。
3. 正则化方法。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以 L2 正则化为例：$C=C_0+\frac{\lambda}{2n}\cdot \sum_{i}w_i^2$ ，这样，在优化原来的目标函数 $C_0$ 的同时，也能避免权值过大带来的过拟合风险。<span style="color:red;">$\lambda$ 是怎么来的？而且，为什么是 $2n$？</span>
4. 集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如 Bagging 方法。<span style="color:red;">集成学习可以与深度学习配合吗？</span>





# 怎么预防和解决过拟合问题？


数据层面：

- 更多的数据。尽可能的扩大 training dataset 才是王道。这个是对于神经网络等大数据量模型来说是最佳方法，可以从本质上解决（减少）过拟合。包括采集真实数据，或者在已有的数据上做各种仿射变化（如旋转，缩放 等），毕竟过拟合产生的根本原因是模型参数相对训练数据量太多。
- 数据的采样，一定要尽可能的覆盖全部数据种类。<span style="color:red;">如果你的样本分布的方差比较大，且样本分布比较均匀，那么对于深度学习模型来说，数据可以不用那么多。</span>


模型与算法层面：


- 简化模型：在训练和建立模型的时候，一定要从相对简单的模型开始，不要一上来就把模型调的非常复杂，特征非常多，这样很容易造成过拟合。而且，当模型过于复杂而造成过拟合时，也较难排查具体的问题出现在那一部分特征。<span style="color:red;">那么当模型过于复杂而过拟合时，怎么排查呢？</span>
- 减少特征：<span style="color:red;">为什么？</span>
- 数据要经过清晰之后再进行算法训练，否则如果混入了大量噪声数据，会加大过拟合问题发生的概率。<span style="color:red;">如果就是采不到均匀覆盖的数据呢？</span>
- 交叉验证：cross validation ，当数据量较小的时候，应该是用来减轻过拟合的最好的方式了吧。<span style="color:red;">是什么？</span>
- early stop：结合 cross validation使用。
- 正则化：可以在算法中添加惩罚函数来预防过拟合。比如 L1、L2 规范。L2用的最多，L1也有用的。<span style="color:red;">惩罚函数为什么是起作用的？难道惩罚函数与模型的复杂度有关？可以衡量模型的复杂度吗？</span>
- Dropout：这个是一大利器。在算法层面去减少过拟合，之前也有叫 weight decay的另一技术都是为了使某些神经元值为 0，减少相互依赖，可以看成是一种正则化。<span style="color:red;">这个只能在深度学习中使用吗？普通的机器学习算法可以使用这个吗？使用了后效果怎么样？</span>
- Shuffling ：在训练之前记得 shuffle 一下数据集，一般是每次训练一个 epoch（就是把 training dataset 训练了一遍）后就 shuffle 一次，但是对于较大的数据集可以只 shuffle 一次，虽然这样会使得训练在第二个 epoch 就变得 biased，但是带来的好处可以 overcome 这种缺陷。<span style="color:red;">这个到底是什么？怎么做的？</span>
- 加入噪声：可以将噪声加入数据或参数中
- 使用 Bagging 等集成，好吧厉害了。
- 可以在构建机器模型时，将数据集拆分为相互独立的训练数据集、验证数据集和测试数据集等，而在训练过程中使用验证数据集来评估模型并据此更新超参数，训练结束中使用测试数据集评估训练好的最终模型的性能。<span style="color:red;">在训练过程中使用验证数据集来评估模型并据此更新超参数是怎么做到的？</span>






# 相关

- 《百面机器学习》
- 《机器学习 实践应用》
- [怎样消除机器学习中的过度拟合？](https://www.zhihu.com/question/26898675)
- [模型评估](https://feisky.xyz/machine-learning/basic/evaluation.html)
