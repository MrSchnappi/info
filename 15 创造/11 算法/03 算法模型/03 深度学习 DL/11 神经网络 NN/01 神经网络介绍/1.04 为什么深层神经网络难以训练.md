---
title: 1.04 为什么深层神经网络难以训练
toc: true
date: 2019-09-03
---

### 3.1.5 为什么深层神经网络难以训练？


1. 梯度消失


梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。

梯度消失的原因受到多种因素影响，例如学习率的大小，网络参数的初始化，激活函数的边缘效应等。在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。下图是不同隐含层的学习速率：

<center>

![](http://images.iterate.site/blog/image/20190722/Ntc6QPR3Rbaa.png?imageslim){ width=55% }

</center>

<span style="color:red;">嗯，感觉衰减的很快。</span>


2. 梯度爆炸

在深度网络或循环神经网络（Recurrent Neural Network, RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为 $NaN$ 值，再也无法更新。<span style="color:red;">这个是什么意思？只有 RNN 中才会有这个梯度爆炸吗？</span>

3. 权重矩阵的退化导致模型的有效自由度减少。

<span style="color:red;">什么意思？没看懂？</span>

参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度范数的贡献不均衡，随着相乘矩阵的数量（即网络深度）的增加，矩阵的乘积变得越来越退化。<span style="color:red;">什么意思？网络的可用自由度对学习中特度范数的贡献不均衡是什么生意？</span>在有硬饱和边界的非线性网络中（例如 ReLU 网络），随着深度增加，退化过程会变得越来越快。Duvenaud等人 2014 年的论文里展示了关于该退化过程的可视化：

<center>

![](http://images.iterate.site/blog/image/20190722/HCw9Gq8BPCXB.jpg?imageslim){ width=65% }

</center>


随着深度的增加，输入空间（左上角所示）会在输入空间中的每个点处被扭曲成越来越细的单丝，只有一个与细丝正交的方向影响网络的响应。沿着这个方向，网络实际上对变化变得非常敏感。<span style="color:red;">什么意思？</span>
