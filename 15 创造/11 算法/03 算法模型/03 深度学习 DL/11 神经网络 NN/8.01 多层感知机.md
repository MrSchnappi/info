---
title: 8.01 多层感知机
toc: true
date: 2019-08-31
---

# 多层感知机的反向传播算法

多层感知机中，输入信号通过各个网络层的隐节点产生输出的过程称为前向传播。图 9.10 定义了一个典型的多层感知机。

<center>

![](http://images.iterate.site/blog/image/20190413/tFGCamrlF14w.png?imageslim){ width=55% }

</center>

为便于表示，定义第 $(l)$ 层的输入为 $x^{(l)}$ ，输出为 $a^{(l)}$ ；在每一层中，首先利用输入 $x^{(l)}$ 和偏置 $b^{(l)}$ 计算仿射变换 $z^{(l)}=W^{(l)} x^{(l)}+b^{(l)}$ ；然后激活函数 $f$ 作用于 $z^{(l)}$ ，得到 $\boldsymbol{a}^{(l)}=\mathcal{L}_{W, b}\left(\boldsymbol{x}^{(l)}\right)=f\left(\boldsymbol{z}^{(l)}\right)$；

 $a^{(l)}$ 直接作为下一层的输入，即 $x^{(l+1)}$。设 $x^{(l)}$ 为 $m$ 维的向量，$z^{(l)}$ 和 $a^{(l)}$ 为 $n$ 维的向量，则 $W^{(l)}$ 为 $m\times n$ 维的矩阵。我们分别用 $z_{i}^{(l)}$， $a_{i}^{(l)}$ 和 $W_{i j}^{(l)}$ 表示其中的一个元素。<span style="color:red;">对于这个地方的 $m$、$n$ 还是要对应上的。</span>

在网络训练中，前向传播最终产生一个标量损失函数，反向传播算法（Back Propagation）则将损失函数的信息沿网络层向后传播用以计算梯度，达到优化网络参数的目的。<span style="color:red;">标量损失函数。嗯，这名字听起来，嗯，很恰当。</span>

反向传播是神经网络中非常重要的算法，从业者需要对反向传播算法熟悉掌握并灵活应用，因此相关问题在面试中也常有涉及。
