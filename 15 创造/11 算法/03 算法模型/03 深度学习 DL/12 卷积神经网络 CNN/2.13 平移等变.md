---
title: 2.13 平移等变
toc: true
date: 2019-08-31
---

## 平移等变

对于卷积，参数共享的特殊形式使得神经网络层具有对平移等变的性质。

- 如果一个函数满足输入改变，输出也以同样的方式改变这一性质，我们就说它是等变(equivariant)的。

特别地，如果函数 $f(x)$ 与 $g(x)$ 满足 $f(g(x))= g(f(x))$，我们就说 $f(x)$ 对于变换 $g$ 具有等变性。对于卷积来说，如果令 $g$ 是输入的任意平移函数，那么卷积函数对于 $g$ 具有等变性。

举个例子，令 $I$ 表示图像在整数坐标上的亮度函数，$g$ 表示图像函数的变换函数（把一个图像函数映射到另一个图像函数的函数）使得 $I' = g(I)$，其中图像函数 $I'$ 满足 $I'(x,y) = I(x-1, y)$。这个函数把 $I$ 中的每个像素向右移动一个单位。如果我们先对 $I$ 进行这种变换然后进行卷积操作所得到的结果，与先对 $I$ 进行卷积然后再对输出使用平移函数 $g$ 得到的结果是一样的。

- 当处理时间序列数据时，这意味着通过卷积可以得到一个由输入中出现不同特征的时刻所组成的时间轴。如果我们把输入中的一个事件向后延时，在输出中仍然会有完全相同的表示，只是时间延后了。
- 图像与之类似，卷积产生了一个 2 维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。当处理多个输入位置时，一些作用在邻居像素的函数是很有用的。例如在处理图像时，在卷积网络的第一层进行图像的边缘检测是很有用的。相同的边缘或多或少地散落在图像的各处，所以应当对整个图像进行参数共享。但在某些情况下，我们并不希望对整幅图进行参数共享。例如，在处理已经通过剪裁而使其居中的人脸图像时，我们可能想要提取不同位置上的不同特征（处理人脸上部的部分网络需要去搜寻眉毛，处理人脸下部的部分网络就需要去搜寻下巴了）。


卷积对其他的一些变换并不是天然等变的，例如对于图像的放缩或者旋转变换，需要其他的一些机制来处理这些变换。




# 相关

- 《深度学习》花书
