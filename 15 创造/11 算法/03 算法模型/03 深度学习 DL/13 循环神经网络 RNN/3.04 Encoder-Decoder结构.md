---
title: 3.04 Encoder-Decoder结构
toc: true
date: 2019-09-03
---

# Encoder-Decoder结构

原始的 sequence-to-sequence 结构的 RNN 要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。

其建模步骤如下：

**步骤一**：将输入数据编码成一个上下文向量 $c$，这部分称为 Encoder，得到 $c$ 有多种方式，最简单的方法就是把 Encoder 的最后一个隐状态赋值给 $c$，还可以对最后的隐状态做一个变换得到 $c$，也可以对所有的隐状态做变换。其示意如下所示：

<center>

![](http://images.iterate.site/blog/image/20190722/4QmjJMNXYfzB.jpg?imageslim){ width=56% }

</center>


**步骤二**：用另一个 RNN 网络（我们将其称为 Decoder）对其进行编码，

方法一是将步骤一中的 $c​$ 作为初始状态输入到 Decoder，示意图如下所示：

<center>

![](http://images.iterate.site/blog/image/20190722/XQhbHtVEOEMn.jpg?imageslim){ width=72% }

</center>


方法二是将 $c$ 作为 Decoder 的每一步输入，示意图如下所示：

<center>

![](http://images.iterate.site/blog/image/20190722/ke5ViPSbAStS.jpg?imageslim){ width=72% }

</center>



<span style="color:red;">编码解码器是指的这个吗？这个是 seq to seq 吧？是 Encoder-Decoder 吗？</span>





## Encoder-Decoder 框架的应用


Encoder-Decoder框架可以看作是一种深度学习领域的研究模式，应用场景异常广泛。

下图是文本处理领域里常用的 Encoder-Decoder框架最抽象的一种表示。



<center>

![mark](http://images.iterate.site/blog/image/20190927/1HUCXstTuUok.png?imageslim)

</center>

> 抽象的文本处理领域的 Encoder-Decoder框架

文本处理领域的 Encoder-Decoder框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对 `<Source,Target>`，我们的目标是给定输入句子 Source，期待通过 Encoder-Decoder框架来生成目标句子 Target。Source和 Target 可以是同一种语言，也可以是两种不同的语言。而 Source 和 Target 分别由各自的单词序列构成：

$$
\begin{array}{l}{\text { Source }=\left\langle\mathbf{x}_{1}, \mathbf{x}_{2} \dots \mathbf{x}_{\mathbf{m}}\right\rangle} \\ {\text { Target }=\left\langle\mathbf{y}_{1}, \mathbf{y}_{2} \dots \mathbf{y}_{\mathbf{n}}\right\rangle}\end{array}
$$

Encoder顾名思义就是对输入句子 Source 进行编码，将输入句子通过非线性变换转化为中间语义表示 C：

$$
\mathbf{C}=\mathcal{F}\left(\mathbf{x}_{1}, \mathbf{x}_{2} \dots \mathbf{x}_{\mathbf{m}}\right)
$$

对于解码器 Decoder 来说，其任务是根据句子 Source 的中间语义表示 C 和之前已经生成的历史信息 $y_{1}, y_{2} \dots \dots y_{i-1}$ 来生成 $i$ 时刻要生成的单词 $y_i$：

$$
\mathbf{y}_{\mathbf{i}}=\boldsymbol{g}\left(\mathbf{C}, \mathbf{y}_{\mathbf{1}}, \mathbf{y}_{\mathbf{2}} \dots \mathbf{y}_{\mathbf{i}-\mathbf{1}}\right)
$$


每个 $y_i$ 都依次这么产生，那么看起来就是整个系统根据输入句子 Source 生成了目标句子 Target。

这个框架比较通用：

- 如果 Source 是中文句子，Target是英文句子，那么这就是解决机器翻译问题的 Encoder-Decoder框架；
- 如果 Source 是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的 Encoder-Decoder框架；
- 如果 Source 是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的 Encoder-Decoder框架。

由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。

Encoder-Decoder 框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。

- 比如对于语音识别来说，上图所示的框架完全适用，区别无非是 Encoder 部分的输入是语音流，输出是对应的文本信息；
- 而对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。

一般而言，文本处理和语音识别的 Encoder 部分通常采用 RNN 模型，图像处理的 Encoder 一般采用 CNN 模型。
