---
title: 1.02 自编码器的几个特点
toc: true
date: 2019-09-01
---
# 自编码器的几个特点

![mark](http://images.iterate.site/blog/image/20190831/CSWCRKEx7IGh.png?imageslim)


自动编码器是一种数据的压缩算法，其中数据的压缩和解压缩函数是数据相关的、有损的、从样本中自动学习的。


1. 自动编码器是数据相关的（data-specific 或 data-dependent），这意味着自动编码器只能压缩那些与训练数据类似的数据。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时性能很差，因为它学习到的特征是与人脸相关的。
1. 自动编码器是有损的，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩算法也是如此。这与无损压缩算法不同。
1. 自动编码器是从数据样本中自动学习的，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。


在大部分提到自动编码器的场合，压缩和解压缩的函数是通过神经网络实现的。

搭建一个自动编码器需要完成下面三样工作：

- 搭建编码器
- 搭建解码器
- 设定一个损失函数，用以衡量由于压缩而损失掉的信息。

编码器和解码器一般都是参数化的方程，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化，例如 SGD。

自编码器是一个自监督的算法，并不是一个无监督算法。自监督学习是监督学习的一个实例，其标签产生自输入数据。要获得一个自监督的模型，你需要一个靠谱的目标跟一个损失函数，仅仅把目标设定为重构输入可能不是正确的选项。基本上，要求模型在像素级上精确重构输入不是机器学习的兴趣所在，学习到高级的抽象特征才是。

事实上，当主要任务是分类、定位之类的任务时，那些对这类任务而言的最好的特征基本上都是重构输入时的最差的那种特征。<span style="color:red;">是这样吗？</span>

目前自编码器的应用主要有两个方面：

- 第一是数据去噪
- 第二是为进行可视化而降维。

配合适当的维度和稀疏约束，自编码器可以学习到比 PCA 等技术更有意思的数据投影。

对于 2D 的数据可视化，t-SNE（读作 tee-snee）或许是目前最好的算法，但通常还是需要原数据的维度相对低一些。所以，可视化高维数据的一个好办法是首先使用自编码器将维度降低到较低的水平（如 32 维），然后再使用 t-SNE将其投影在 2D 平面上。<span style="color:red;">嗯。</span>



# 相关

- [深度学习之自编码器 AutoEncoder](https://blog.csdn.net/marsjhao/article/details/73480859)
