---
title: 1.06 深度强化学习算法小结
toc: true
date: 2019-09-04
---

## 10.10 深度强化学习算法小结

基于值函数概念的 DQN 及其相应的扩展算法在离散状态、离散动作的控制任务中已经表现了卓越的性能，但是受限于值函数离散型输出的影响，在连续型控制任务上显得捉襟见肘。

基于策略梯度概念的，以 DDPG，TRPO等为代表的策略型深度强化学习算法则更适用于处理基于连续状态空间的连续动作的控制输出任务，并且算法在稳定性和可靠性上具有一定的理论保证，理论完备性较强。

采用 actor-critic 架构的 A3C 算法及其扩展算法，相比于传统 DQN 算法，这类算法的数据利用效率更高，学习速率更快，通用性、可扩展应用性更强，达到的表现性能更优，但算法的稳定性无法得到保证。

而其他的如深度迁移强化学习、分层深度强化学习、深度记忆强化学习和多智能体深度强化学习等算法都是现在的研究热点，通过这些算法能应对更为复杂的场景问题、系统环境及控制任务，是目前深度强化学习算法研究的前沿领域。

展望未来，人工智能开发者们需要尽可能掌握上述框架以及其中所使用的各类强化学习算法。此外，还需要强化自身对于多代理强化学习架构的理解，因为其中多种框架都大量利用前沿博弈论研究成果。最后，还需要熟悉深度强化学习知识。





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
