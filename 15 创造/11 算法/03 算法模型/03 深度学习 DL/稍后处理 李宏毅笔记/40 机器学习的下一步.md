---
title: 40 机器学习的下一步
toc: true
date: 2019-08-18
---
![mark](http://images.iterate.site/blog/image/20190818/4T4zPjbS5xnD.png?imageslim)
# 机器学习的下一步
假设我们要把机器学习更多应用到生活中，还有哪些问题是需要我们克服的
## 机器能不能知道“我不知道”
这是一个很形而上的问题，你知道你不知道这样。机器能不能知道这件事情呢？很多时候，你可能训练一个动物识别器，机器知道这是一只猫，正确率可能非常高，真正上线后，输入不仅仅会是一只猫，可能输入一个人图像，这个时候，机器是把这个人硬塞进某一种动物，还是说你的机器有能力知道这个是我不知道的东西。机器会回答这是我不知道的，这样的技术就是 Anomaly Detection。

![mark](http://images.iterate.site/blog/image/20190818/azwCXdVo13s3.png?imageslim)

## 说出为什么“我知道”
今天我们看到各式各样机器学习非常强大的力量，感觉机器好像非常的聪明，过去有个例子神马汉斯，聪明到可以计算数学题，甚至可以解开根号的问题。人们觉得非常的惊叹，不要有任何的观众，让马来解决问题，之前他是学到了旁边人的反应，然后停下来踏蹄。今天我们看到的机器学习成果，它真的那么聪明吗？会不会它跟汉斯一样，用了非常奇怪的方法来得到答案。

![mark](http://images.iterate.site/blog/image/20190818/6kY2325Obiav.png?imageslim)

这个东西其实是有可能发生的，举例来说，有人做了一个马的辨识器，两个 model 的辨识率都很高。然后分析，机器是根据什么来标识马的。第一个模型是看到图上黄红部分正常分析出有马，第二个模型是看到下面红色部分，辨识出有马，它只是看到左下角的英文，标识出马，并没有学到马。

![mark](http://images.iterate.site/blog/image/20190818/TCb24fHlNMXi.png?imageslim)

我们不知道 AI 有没有那么聪明，我们需要一些技术，让 AI 不只是做出决定，还要让它告诉我们说它为什么做出这样的决定。
## 机器的错觉
我们知道说，人是有错觉的，比如下面两个圈圈，左边的圈圈颜色比较深，但是人有时会有错觉，觉得右边这个圈圈颜色比较深。
![mark](http://images.iterate.site/blog/image/20190818/GIW432C5gYkk.png?imageslim)

机器跟人一样，也很容易被骗，我们可以加一些噪声，让机器本来以为是的后来判断为不是。如本来判断出来是熊喵，加了噪声，就判断错误了。这种就叫做 Adversarial Attack，这个要如何防止呢？即如何防止机器发生错觉~

![mark](http://images.iterate.site/blog/image/20190818/Q4j8b5l8NP7t.png?imageslim)

## 终身学习
我们也要机器终生学习。人就是终生学习的，上学期修了线性代数，这学期学机器学习，学好线性代数，机器学习学得更容易。机器能不能跟人一样也做终生学习呢？现在我们一般只让一个模型学习一个任务，比如 Alpha Go就只学习下围棋，Alpha star就是玩星海，它们并不是同一个模型。

![mark](http://images.iterate.site/blog/image/20190818/c3NJKF2Cf4Lm.png?imageslim)

今天我们只让一个模型学习一个人任务，显然会存在如下问题
- 模型的数量无限增长
- 之前学到的技能对之后的学习没有帮助

为什么我们今天不让机器去终生学习呢？比如我们先让机器学下围棋，然后再让它学星海，那么尴尬了，学完星海之后它就不会下围棋了。这个叫做 Catastrophic Forgetting。如果想让机器做终身学习，还尚在解决的问题

![mark](http://images.iterate.site/blog/image/20190818/wcV3hWGeOE9k.png?imageslim)

## 学习如何学习
过去我们是写一个程序，让机器具有学习的能力，现在我们能不能写一个程序让机器学习具有学习的能力，这个程序能够写出程序让机器具备学习能力，这个技术叫做 Meta-Learning 或者 Learn to Learn。学习如何学习，过去我们设定了学习的演算法让机器学习，今天我们能不能让机器自己学习演算法，然后根据这些演算法进行学习。
## 一定需要很多训练资料吗？
- Few-shot learning
让机器看少量的资料，去学会
- Zero-shot learning
不给机器任何资料，只告诉机器物品的特征描述，然后机器根据描述进行判断。

## 增强式学习
Reinforcement Learning 真的有这么强吗？当你用 Reinforcement Learning 去打一些 apari 的电玩，Reinforcement Learning也许确实可以跟人做到差不多，但是需要很长时间才能达到，如下图机器需要 900 多个小时才能达到人类 2 个小时能达到的效果。机器感觉就是一个天资不佳却勤奋不解的笨小孩，即 Reinforcement Learning为什么学得这么慢，有没有办法让它快一点?

![mark](http://images.iterate.site/blog/image/20190818/poY3DSNmXeWl.png?imageslim)

## 神经网络压缩
假设我们要把机器学习的模型应用到生活当中，device的运算能力有限，内存有限，接下来的问题是我们能不能把 Network 架构缩小，让它有同样的能力。首先能不能把一个大的神经网络缩小，减掉多余的神经元；或者能不能把一个神经网络的参数进行二值化，都变成“+1”和“-1”。如果是连续数值，就需要大量的运算和内存，如果把所有参数进行二值化，那么运算起来就快，内存也占用少。
![mark](http://images.iterate.site/blog/image/20190818/aqM5aQIodUt9.png?imageslim)

## 机器学习的谎言
今天我们在训练的时候，假设训练和测试的数据分布是一样的或者至少非常相似，但是实际上在真实应用里面，这就是一个谎言。

![mark](http://images.iterate.site/blog/image/20190818/Kb0OvXq6aHX1.png?imageslim)

如果今天你在做手写数字辨识，训练资料和测试资料非常相似，可能会很容易达到 99.5%。但是实际中，可能图片有背景，正确率变成 57.5%，直接烂掉了。那么怎么解决机器在训练资料和测试资料不同的场景呢？现有技术有 Unsupervised Domain Adaptation。
![mark](http://images.iterate.site/blog/image/20190818/vX4N784jrsdM.png?imageslim)


如上是这学期想跟大家分享的东西。





# 相关

- [leeml-notes](https://github.com/datawhalechina/leeml-notes)
