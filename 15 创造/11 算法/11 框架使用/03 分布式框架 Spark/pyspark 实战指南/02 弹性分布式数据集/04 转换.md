---
title: 04 转换
toc: true
date: 2019-07-02
---
2.4 转换
转换可以调整数据集。包括映射、筛选、连接、转换数据集中的值。在本节中，我们将展示一些 RDD 中可用的转换。由于空间的限制，在这里我们只包含了最经常使用的转换和操作。对于一套完整的可用方法，我们建议你查看有关 RDD 的 PySpark 文档 http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD。
由于 RDD 是无 schema 的，在这一节中我们假设你已经知道产生数据集的 schema。如果你记不住解析数据集中信息的位置，我们建议你可以参考 GitHub 上 extractInformation（……）方法的定义，以及第 3 章的代码。
2.4.1 .map（……）转换
可以说，你会经常使用.map（……）转换。该方法应用在每个 RDD 元素上：在 data_from_file_conv的数据集情况里，你可以认为这是每一行的转换。
在这个例子里，我们会创建一个新的数据集，将死亡年份转换为数字值。
运行 data_2014.take（10）命令将产生以下结果：如果你不熟悉 lambda 表达式，请参考：https://pythonconquerstheuniverse.wordpress.com/2011/08/29/lambda_tutorial/。
当然，你可以使用更多列数据，但是你必须把它们打包成一个数组（tuple）、dict或者列表。包含一行里的第 17 个元素，以便我们可以确认.map（……）能按预期执行。
之前的代码将产生如下的结果：
2.4.2 .filter（……）转换
另外一个经常需要使用的转换方法是.filter（……），该方法可以让你从数据集中选择元素，该元素集符合特定的标准。像来自 data_from_file_conv数据集的例子，统计 2014 年死于车祸的人数：



请注意，前面的命令执行时间根据电脑的执行速度而定。对于我们来说，一条命令返回结果的时间大概是 2 分钟多一点。
2.4.3 .flatMap（……）转换
.flatMap（……）方法和.map（……）方法的工作类似，但是.flatMap（……）返回一个扁平的结果，而不是一个列表。如果我们执行一下代码：
该代码将输出：
你可以和 data_2014_2产生的结果对比。同时注意，如前所述，当你需要解析输入时.flatMap（……）可以用于过滤一些格式不正确的记录。在这个机制下，.flatMap（……）方法把每一行看做一个列表对待，然后将所有的记录简单地加入到一起。通过传递一个空列表可以丢弃格式不正确的记录。
2.4.4 .distinct（……）转换
该方法返回指定列中不同值的列表。如果你想知道你的数据集或者验证这个数据集，.distinct（……）方法会非常有用。检查性别列表是否只包含了男性和女性将验证我们是否准确解析了数据集。运行以下代码：
该代码将产生以下结果：
首先，我们只提取包含性别的列；接着，我们使用.distinct（）方法只选择列表中不同的值；最后，使用.collect（）方法在屏幕上打印出返回值。请注意这是一个高开销的方法，应该谨慎并且只在处理数据的必要时刻使用。
2.4.5 .sample（……）转换
.sample（……）方法返回数据集的随机样本。第一个参数指定采样是否应该替换，第二个参数定义返回数据的分数（指数学中的分数），第三个参数是伪随机数产生器的种子。
这个例子中，我们从原数据集里选择了随机抽样的 10％。为了确认这一点，我们将该数据集的大小打印出来：
之前的命令产生了以下的输出：
我们使用.count（）操作，统计相关 RDD 中的所有记录。
2.4.6 .leftOuterJoin（……）转换

leftOuterJoin（……），就像在 SQL 中一样，根据两个数据集中都有的值来连接两个 RDD，并返回左侧的 RDD 记录，而右边的记录附加在两个 RDD 匹配的地方：
rdd3运行.collect（……）将产生以下结果：请注意，这是一个高开销的方法，应该谨慎并且只在处理数据的必要时刻使用，不然会对性能产生影响。
你可以在这里看到所有来自于 RDD rdd1的元素和来自 RDD rdd2相应的值。如你所见，值‘a’在 rdd3 中出现了 2 次，在 RDD rrd2中出现了 2 次。rdd1中的值‘b’只出现了 1 次，并且和 rdd2 中的值‘6’组在了一起。有两个缺失的事件：来自 rdd1 的值‘c’和 rdd2 没有关联的值，所以返回的数组里出现的是 None，并且因为我们执行的是左外部连接，所以 rdd2 的值‘d’没有出现。
如果我们使用.join（……）方法，不一样的是，我们只会得到值‘a’和值‘b’，作为两个 RDD 之间的关联数值。运行以下代码：
输出结果如下：
另外一个有用的方法是.intersection（……），返回的是两个 RDD 中相等的记录。执行以下代码：
输出结果如下：
2.4.7 .repartition（……）转换
重新对数据集进行分区，改变了数据集分区的数量。此功能应该谨慎并且仅当真正需要它来对数据进行操作时使用，因为它会重组数据，导致对性能方面产生巨大的影响。
这段代码打印出来 4，作为新的分区数目。
和.collect（）方法不同，.glom（）方法会产生一个列表，其中每个元素是指定分区中数据集的所有元素的另一个列表。返回的主要列表的元素和分区的数量一样多。2.
