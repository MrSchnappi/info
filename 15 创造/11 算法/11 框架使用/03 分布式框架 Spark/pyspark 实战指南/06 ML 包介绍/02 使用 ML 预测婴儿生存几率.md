---
title: 02 使用 ML 预测婴儿生存几率
toc: true
date: 2019-07-02
---
6.2 使用 ML 预测婴儿生存几率
在本节中，我们将使用上一章的数据集部分来介绍 PySpark ML的理念。如果在阅读上一章时没有下载数据，可以访问这里下载：http://www.tomdrabas.com/data/LearningPySpark/births_transformed.csv.gz。
在本节中，我们再次尝试预测婴儿生存的机率。
6.2.1 加载数据
首先，使用以下代码帮助加载数据：
我们指定 DataFrame 的 schema，严格限制数据集只有 17 列。
6.2.2 创建转换器
在使用数据集来估计模型之前，需要做一些转换。由于统计模型只能对数值数据做操作，因此我们必须对 BIRTH_PLACE变量进行编码。
在做这些之前，由于我们将在本章后续当中使用一些不同的特征转换，所以先把它们导入进来：
我们将使用 OneHotEncoder 方法来对 BIRTH_PLACE列进行编码。但是，该方法不接受 StringType 列；它只能处理数字类型，所以我们首先将该列转换为 IntegerType：
做完这项工作，现在可以开始创建第一个转换器了：
现在我们来创建一个单一的列，它将所有特征整合在一起。我们将使用 VectorAssembler 方法：
传递给 VectorAssembler 对象的 inputCols 参数是一个列表，该列表包含所有要合并在一起以组成 outputCol——“features”的列。请注意，我们使用编码器对象的输出（调用.getOutputCol（）方法），因此如果我们在任何时候更改了编码器对象中输出列的名称，那么我们就不必更改此参数的值。


现在可以开始创建第一个评估器了。
6.2.3 创建一个评估器
本例中，我们将再次使用逻辑回归模型。不过在本章的后续部分，会展示一些 PySpark ML模型中.classification部分的更复杂模型，因此先导入这部分：
导入后，可以使用以下代码创建模型：
如果目标列的名称为“label”，则不必指定 labelCol 参数。另外，如果 featuresCreator 的输出名称不是“features”，那么必须通过在 featuresCreator 对象上调用 getOutputCol（）方法来指定 featuresCol（这是最方便的做法）。
6.2.4 创建一个管道
现在剩下的工作就是创建一个管道并拟合模型。首先，从 ML 包中加载管道：
创建管道非常容易。从概念上看管道如下图：
把这个结构转化为一个管道很简单：
完成了！管道现在创建完了，我们终于可以评估模型了。
6.2.5 拟合模型
拟合模型前，需要把数据集分成训练数据集和测试数据集。DataFrame API提供了方便使用的.randomSplit（……）方法：
第一个参数是数据集的比例列表，这些比例分别用来表示 births_train和 births_test子集最终所占比例。seed参数给 randomizer 提供一个种子。只要列表的元素总和为 1，也可以将数据集拆分成两个以上的子集，并输出多个子集。
例如，我们可以将出生数据集分为三个子集，如下所示：
上述代码随机将 70％的出生数据集放入训练对象中，20％放入测试对象，而 val DataFrame将保留剩余的 10％。
现在终于可以运行管道并评估我们的模型了：
管道对象的.fit（……）方法以训练数据集为输入。在方法内部，births_train数据集首先被传给 encoder 对象。在 encoder 阶段创建的 DataFrame 将被传递给创建“features”列的 featuresCreator。最后，此阶段的输出被传递给评估最终模型的 logistic 对象。
.fit（……）方法返回用于预测的 PipelineModel 对象（上述代码片段中的 model 对象），将之前创建的测试数据集传递给要调用的.transform（……）方法来获得预测。test_model示例在如下命令行中：


产生如下输出：
如你所见，我们通过转换器和评估器得到了所有的列。逻辑回归模型输出了几列：rawPrediction是特征和β系数的线性组合的值，probability是为每个类别计算出的概率，最后 prediction 是最终的类分配。
6.2.6 评估模型的性能
当然，我们想检验一下我们的模型表现如何。PySpark软件包的.evaluation部分提供了许多用于分类和回归的评估方法：
我们将使用 BinaryClassficationEvaluator 来检验模型表现如何：
rawPredictionCol可以是由评估器产生的 rawPrediction 列，也可以是 probability。
我们来看看我们的模型表现如何：
上述代码产生如下结果：
ROC区域 74％，而 PR 区域为 71％，这表明模型定义良好，但是并没有什么优越之处；如果有其他特征，我们可以提高一下，但是这不是本章的目的（也非本书的目的）。
6.2.7 保存模型
PySpark允许保存管道定义以备以后使用。不仅可以保存管道结构，还可以保存所有转换器和评估器的定义：
所以，你可以随后加载并直接使用来.fit（……）并预测：
以上代码产生相同结果（如预期一样）：
不过，如果你想保存评估的模型也是可以的；此时你需要保存 PipelineModel，而不是保存管道。


请注意，不仅可以保存 PipelineModel：实际上所有评估器或转换器上调用.fit（……）方法返回的模型都可以保存，可以加载重用。
参考以下示例来保存模型：
以上代码使用 PipelineModel 类的.load（……）方法来加载评估的模型。你可以将 test_reloadedModel.take（1）的结果与之前提到的 test_model.take（1）的输出做个比较。
