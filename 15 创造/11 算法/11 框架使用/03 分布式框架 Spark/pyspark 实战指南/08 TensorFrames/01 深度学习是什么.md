---
title: 01 深度学习是什么
toc: true
date: 2019-07-02
---
8.1 深度学习是什么
深度学习是基于数据学习表达的机器学习技术系列的一部分。深度学习是松散地基于我们自己大脑的神经网络，这个结构的目的是提供大量高度相互关联的元素（在生物系统中，这将是我们大脑中的神经元）；我们大脑中有大约 1000 亿个神经元，每个神经元连接到大约 10000 个其他的神经元，结果是不可思议的 1015 个突触连接。这些元素通过学习过程共同解决问题，其中包括模式识别和数据分类。
在这种架构中的学习涉及修改关联元素之间的连接，类似于我们自己的大脑如何调整神经元之间的突触连接。
传统的算法涉及对已知步骤或数量的编程，也就是说，你已经知道解决具体问题的步骤，现在重复该解决方案并使其运行更快。神经网络是一个有趣的范例，因为神经网络通过示例学习，实际上并不是为了执行特定任务本身而设计。这使得神经网络（和深度学习）中的训练过程非常重要，因为你必须为神经网络提供良好的示例，否则将学习错误的事情（即提供不可预测的结果）。
图片来源：Wikimedia Commons：File：Réseau de neurones.jpg；https://commons.wikimedia.org/wiki/File：Réseau_de_neurones.jpg
构建人造神经网络的最常见方法是创建三个层次：输入层、隐藏层和输出层。如下图所示：


如上图所示，每个层由一个或多个具有连接（即数据流）的节点组成。输入节点是被动的，因为它们接收数据，但不修改信息。隐藏层和输出层中的节点将主动修改数据。例如，输入层中的三个节点到第一个隐藏层中的一个节点的连接如下图所示：
参考信号处理神经网络示例，每个输入（表示为 xi）具有相应的权重（wi），这会产生一个新值。在这种情况下，其中一个隐藏节点（h1）是三个修改后的输入节点的结果：
h1＝x1w1＋x2w2＋x3w3
训练过程中，还可以通过一个偏差对这个总和进行调整。总和（我们示例中的 h1）通过所谓的激活函数确定神经元的输出。一些具此激活功能的例子如下图所示：



这个过程在隐藏层以及输出层中的每个节点都是重复的。输出节点是应用于每个活动层节点的输入值的所有权重的累加。学习过程是应用和重新应用这些权重（在这种情况下）的许多迭代并行运行的结果。
神经网络以各种不同的大小和形状出现。最流行的是单层和多层前馈型网络，类似于前面提到的那种。输出层中的这种结构（即使只有两层和一个神经元！）的神经元能够解决简单的回归问题（如线性和逻辑），还能解决高度复杂的回归和分类任务（具有许多隐藏层和多个神经元）。常用的另一种神经网络类型是自组织图。芬兰研究员 Teuvo Kohonen首先提出了这种结构，所以它有时也被称为 Kohonen 网络。这种结构可以在没有教练的情况下训练，也就是说，它们不需要目标（无监督的学习范例）。这种结构最常用于解决聚类问题，其目的是在数据中找到一个基础模式。有关神经网络类型的更多信息，我们建议你参阅此文档：http://www.ieee.cz/knihovna/Zhang/Zhang100-ch03.pdf。
请注意，除了 TensorFlow 之外，还有许多其他有趣的深度学习库；包括但不限于 Theano、Torch、Caffe、Microsoft Cognitive Toolkit（CNTK）、mxnet和 DL4J。
8.1.1 神经网络和深度学习的必要性
神经网络（以及深度学习）有很多潜在的应用。某些更受欢迎的应用包括人脸识别、手写数字识别、博弈、语音识别、语言翻译和对象分类。这里的关键因素是它涉及学习和模式识别。
虽然神经网络已经存在了很长时间（至少在计算机科学史的背景下），但是直到现在它才变得更被大众认可，其主要原因是：分布式计算的进步和其可用性的提高以及研究的进展：
·分布式计算和硬件的进步以及可用性的提高：分布式计算框架（如 Apache Spark）使你可以通过并行运行更多模型来更快地完成更多的训练迭代，以确定机器学习模型的最佳参数。随着 GPU（最初设计用于显示图形的图形处理单元）的流行，这些处理器开始擅长执行机器学习所需的资源密集型数学计算。还有云计算，利用分布式计算和 GPU 的优势变得更加容易，因为通过使用云计算可以降低前期成本，缩短部署时间，更容易提高系统的弹性部署。
·深度学习研究的进步：这些硬件的进步已经帮助神经网络重回数据科学的前沿，这些项目包括 TensorFlow 以及其他流行的项目例如 Theano、Caffe、Torch、Microsoft Cognitive Toolkit（CNTK）、mxnet和 DL4J。
要深入了解这些主题，这里有两个不错的参考文献：
·Lessons Learned from Deploying Deep Learning at Scale（http://blog.algorithmia.com/deploying-deep-learning-cloud-services/）：Algorithmia的这篇博客文章讨论了他们在大规模部署深度学习解决方案方面的研究。
·Neural Networks by Christos Stergio and Dimitrios Siganos（http://bit.ly/2hNSWar）：一本很好的神经网络入门书。
如前所述，深度学习是基于数据学习表达的机器学习方法系列的一部分。在学习表示形式的情况下，这也可以被定义为特征学习。深度学习令人兴奋的一点是它有可能替代或者最小化手动特征工程的需求。深度学习使得机器不仅学习一个特定的任务，还学习了该任务所需的功能。更简洁的是，使特征工程自动化或教机器学会如何学习（一个很好的特征学习参考文献来自斯坦福大学的无监督特征学习和深度学习教程：http://deeplearning.stanford.edu/tutorial/）。
为了将这些概念转化为基本原理，让我们从一个特征开始。正如 Christopher Bishop所著的《Pattern Recognition and machine learning》中和前面关于 MLlib 和 ML 的章节所描述的，特征是观察到的现象的可度量属性。
如果你对统计领域更为熟悉，则可以参考随机线性回归模型中的独立变量（x1，x2，…，xn）的特征：
在这个具体的例子中，y是因变量，xi是独立变量。
在机器学习情境的背景下，特征示例包括：
·餐厅推荐：特征包括与餐厅相关的评论、评级、其他内容和用户个人资料属性。一个不错的该模型例子是“Yelp Food Recommendation System”，http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf）。
·手写数字识别：特征包括块状直方图（沿 2D 方向的像素数）、孔、行程检测等。示例包括：
·Handwritten Digit Classification，http://ttic.uchicago.edu/～smaji/projects/digits/；
·Recognizing Handwritten Digits and Characters，http://cs231n.stanford.edu/reports/vishnu_final.pdf。



图像处理：特征包括图像中的点、边和对象。一些不错的例子包括：
·AndréAichert的 Seminar：Feature extraction，http://home.in.tum.de/～aichert/featurepres.pdf；
·University of Washington Computer Science&Engineering CSE455：Computer Vision Lecture6，https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect6.pdf。
特征工程是关于确定哪些特征（例如在统计学中的独立变量）对于定义你正在创建的模型是很重要的。通常，它涉及使用领域知识创建特征以允许 ML 模型工作的过程。
找到特征难度大，费时费力，需要专业知识。“应用机器学习”基本上是特征工程。
——Andrew Ng，Machine Learning and AI via Brain simulations（http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10595.pdf）
8.1.2 特征工程是什么
通常，执行特征工程涉及诸如特征选择（选择原始特征集的子集）或特征提取（从原始特征集构建新的特征集）之类的概念：
·在特征选择中，根据领域知识，你可以过滤你认为可以定义模型的变量（例如根据营业额预测足球分数）。通常，数据分析技术（如回归和分类）也可用于帮助你确定这一点。
·特征提取的方法是将数据从高维空间（即许多不同的独立变量）转换为维度更少的较小空间。继续用美式橄榄球来类比，这将是四分卫等级，它基于几个选定的功能（例如，完成、达阵、拦截、每次尝试的平均得分等）。线性数据转换空间中特征提取的常用方法是主成分分析（PCA）：http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html＃principal-component-analysis-pca。其他常见机制包括：
Nonlinear dimensionality reduction，https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction；
Multilinear subspace learning，https://en.wikipedia.org/wiki/Multilinear_subspace_learning。一份有关特征选择与特征提取话题的很好的参考资料是 What is dimensionality reduction？What is the difference between feature selection and extraction？（http://datascience.stackexchange.com/questions/130/what-is-dimensionality-reduction-what-is-the-difference-between-feature-selecti/132#132）。
8.1.3 桥接数据和算法
我们在特征选择的上下文中使用餐厅推荐的例子来把特征和特征工程定义桥接起来：
虽然这是一个简化的模型，但是它用类比的手法描述了应用机器学习的基本前提。由数据科学家来分析数据，以确定该餐厅推荐模型的主要特征。
在我们的餐厅推荐案例中，虽然很容易假设地理定位和美食类型是主要因素，但是需要一些数据挖掘才能了解用户（即餐厅的食客）选择餐厅的偏好。不同的餐厅通常具有不同的特征或权重。
例如，高档餐饮餐饮企业的主要特征往往与位置（即离客户比较近）、大规模聚会的预约能力以及酒单的多样性有关：



同时，对于特色餐厅，往往很少涉及上述因素；相反，重点是评论、评级、社交媒体上发布的消息以及餐厅是否适合小孩：
划分这些不同餐厅（及其目标受众）的能力是应用机器学习的关键方面。这可能是一个艰巨的过程，你可以尝试使用不同变量和权重的不同模型和算法，然后在重复训练和测试许多不同的组合后重试。但请注意，这种耗时的迭代方法本身是否可以成为一个自动化的过程？这是建立帮助机器学习学习的算法的关键环节——深度学习有可能在构建模型时将学习过程自动化。8
