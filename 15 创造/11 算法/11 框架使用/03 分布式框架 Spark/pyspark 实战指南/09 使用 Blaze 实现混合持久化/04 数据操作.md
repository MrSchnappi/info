---
title: 04 数据操作
toc: true
date: 2019-07-02
---


9.4 数据操作
我们已经介绍了一些用于 DataShape 的最常用的方法（例如.peek（）），以及基于列值过滤数据的方法。Blaze已经实现了许多方法，这使任何数据的处理都非常容易。
在本节中，我们将回顾一系列其他常用的处理数据的途径以及与之相关的方法。对于那些使用 pandas 或 SQL 的人，我们将提供等价的相应的语法。
9.4.1 访问列
有两种访问列的方式：每次访问它们获得一个列，就像一个 DataShape 属性一样：
上述脚本生成以下输出：
你还可以使用允许一次选择多个列的索引：
这将生成以下输出：
上述语法对于 pandas 的 DataFrame 是一样的。对于那些不熟悉 python 和 pandas API的人，请注意以下三点：
1.要指定多个列，你需要将它们包含在另一个列表中：注意双括号[[和]]。
2.如果所有方法的链一行中放不下（或者你想要打破链以获得更好的可读性），则有两个选择：将整个方法链放在括号（……）中，其中……是所有方法组成的链。或者，在开始新的一行之前，将反斜杠字符\放在链中每一行的末尾。我们更喜欢后者，并将在现在的例子中使用。
3.请注意，等效的 SQL 代码将是：
9.4.2 符号转换
Blaze的美丽来自于它可以象征性地运作的事实。这意味着你可以在数据上指定转换、过滤器或其他操作，并将其存储为对象。然后，你可以使用几乎任何形式的符合原始模式的数据来提供此类对象，而 Blaze 将返回已转换的数据。
例如，让我们选择 2013 年发生的所有违章行为，并且只返回“Arrest_Type”，“Color”和“Charge”列。首先，如果我们无法从已经存在的对象映射出模式，则必须手动指定模式。为此，我们将使用.symbol（……）方法来实现；该方法的第一个参数指定了转换的符号名称（我们希望保持与对象的名称相同，但可以是任何内容），第二个参数是一个长字符串，用于指定<column_name>：<column_type>方法，用逗号分隔：
现在，你可以使用 schema_example对象并指定一些转换。但是，由于我们已经有一个现有的 traffic 数据集，我们可以通过使用 traffic


dshape并指定我们的转换模式：
为了介绍它的工作原理，让我们将原始数据集读入 pandas 的 DataFrame：
读取之后，我们将数据集直接传递到 traffic_2013对象，并使用 Blaze 的.compute（……）方法执行计算；该方法的第一个参数指定了转换对象（我们的是 traffic_2013），第二个参数是要执行转换的数据：
以下是上述代码片段的输出：
你还可以传递表的列表或 NumPy 数组的列表。在这里，我们使用 DataFrame 的.values属性访问构成 DataFrame 的 NumPy 数组的基础列表：
这段代码将精确地产生我们期望的结果：
9.4.3 列的操作
Blaze允许在数字列上进行简单的数学运算。数据集中引用的所有交通违章发生在 2013 年至 2016 年之间。你可以使用.distinct（）方法获取 Stop_year列的所有不同值。.sort（）方法按照升序对结果进行排序：
上述代码生成以下输出表：
pandas的等效语法如下：
对于 SQL，请使用以下代码：





你还可以对列进行一些数学转换/计算。由于所有交通违章发生在 2000 年以后，我们可以从 Stop_year列减去 2000，而不会失去任何准确性：
这是你应该得到的返回结果：
相同的效果可以从 pandas 的 DataFrame 中用相同语法获得（假设 traffic 是 pandas DataFrame的类型）。对于 SQL，等价的代码是：
然而，如果你想做一些更复杂的数学运算（例如 log 或 pow），那么你首先需要使用 Blaze 提供的一个操作（即在后台将你的命令转换成 NumPy、math或者 pandas 的一个合适的方法）。
例如，如果要对 Stop_year进行日志转换，则需要使用以下代码：
这将产生以下输出：
9.4.4 降阶数据
还可以使用一些降阶方法，例如.mean（）（计算平均值），.std（计算标准偏差）或.max（）（从列表中返回最大值）。执行以下代码：
将返回以下输出：
如果你有一个 pandas DataFrame，你可以使用相同的语法。而对于 SQL 则可以使用以下代码：
为数据集添加更多列也很容易。比如说你想计算违规发生时的汽车车龄（以年数表示）。首先，你将设置 Stop_year并减去制造的年份。
在下面的代码片段中，.transform（……）方法的第一个参数是 DataShape，要进行转换，另一个将是转换列表。在.transform（……）方法的源代码中，这样的列表将被表示为*args，因为你可以一次指定要创建的多个列。任何方法的*args参数都会占用任意数量的后续参数，并将其视为列表。
上述代码将生成下表：



pandas等效操作可通过下面的代码来实现：
对于 SQL，你可以使用以下代码：
如果你想计算涉及造成致命结果的交通违章的汽车的平均车龄并计算出现次数，则可以使用.by（……）操作执行 group by操作：
.by（……）的第一个参数指定了要执行聚合的 DataShape 的列，之后是我们要获取的一系列聚合。在本例中，我们选择 Age_of_car列，并计算该列的平均值和对应于每个值“Fatal”列为真的行数。
上述脚本生成以下聚合结果：
对于 pandas，等效代码如下：
对于 SQL，代码将如下所示：


9.4.5 连接
将两个 DataShape 进行连接也是很简单的。为了说明如何做到这一点，尽管相同的结果可以用不同方法获得，但我们还是首先选择违章类型（violation对象）和涉及安全带（belts对象）的所有交通违章行为：
现在我们通过 6 个时间日期把这两个对象连接起来。如果我们只是简单地选择两个列：Violation_type和 Belts，那我们一次就可以获得相同的效果。但是，这个例子是展示.join（……）方法的机制，所以请理解一下我们。
.join（……）方法的第一个参数是我们要加入连接的第一个 DataShape，第二个参数是第二个 DataShape，而第三个参数可以是单个列或列的列表，用于执行连接：
我们拥有了完整的数据集之后，让我们来看看有多少交通违章涉及到安全带，并对司机做出了什么样的处罚：
以下是上一个脚本的输出：
pandas也可以使用以下代码来获取相同的结果：
如果是 SQL 你将使用以下代码片段：
