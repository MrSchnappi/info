---
title: 05 全局聚合快速入门
toc: true
date: 2019-07-02
---

10.5 全局聚合快速入门
如上一节所述，到目前为止，我们的脚本已经执行了某一时间点上流的单词计数。根据上节中我们脚本是如何执行的，下图展示了 lines DStream及其微批量数据：
在第 1 秒的标记处，我们的 python Spark Streaming脚本返回值为{（blue，5），（green，3）}，第 2 秒标记处返回{（gohawks，1）}，而在第 4 秒标记处，返回的是{（green，2）}。但是，如果你想要的是一个特定时间窗口内的总字数呢？
下图表示我们计算的是有状态的聚合：
在这种情况下，我们有一个 0～5秒之间的时间窗口。注意，在我们的脚本中，我们没有指定的时间窗口：我们每秒都计算单词的累积之和。因此，在第 2 秒的标记处，输出不仅仅是第 1 秒而来的 green 和 blue，而且还包括从第 2 秒而来的 gohawks：{（blue，5），（green，3），（gohawks，1）}。在第 4 秒时，加上后进来的 2 个 green，为我们提供的总数是{（blue，5），（green，5），（gohawks，1）}。
对于那些经常使用关系数据库的人来说，这似乎只是一个 GROUP BY，SUM（）语句。然而，在流分析的情况下，持久化数据足够长以运行 GROUP BY，SUM（）语句的时间长于批间隔（例如 1 秒）。这意味着我们会持续在后台运行，试图同步数据流。
例如，如果你要运行“1.Streaming and DataFrames.scala”Databricks笔记本（https://github.com/dennyglee/databricks/blob/master/notebooks/Users/denny％40databricks.com/content/Streaming％20Meetup％20 RSVPs/1.％20Streaming％20and％20DataFrames.scala），并且想查看 Spark 界面上的 Streaming 作业，你得到结果类似下图：


注意在图表中，调度延迟（Scheduling Delay）和总延迟（Total Delay）这两个数字在快速增加（例如，平均总延迟为 54 秒 254 ms，实际总延迟为>2min），batch interval阈值为 1 秒。我们看到这个延迟的原因是因为在这个笔记本的流代码中，还运行了以下代码：
也就是说，要插入任何新的数据块（即 1 秒的 RDD 微批次），将它们转换成 DataFrame（meetup_stream_json表），并将数据插入到持久化表（meetup_stream表）中。随着调度延迟的日益增加，以这种方式来做数据持久化会导致流性能变慢。可以使用流分析（streaming analytics）来解决这个问题，通过 UpdateStateByKey（Spark 1.5及更早版本）或 mapWithState（Spark 1.6以上）创建全局聚合。更多 Spark Streaming可视化信息，请浏览 New Visualizations for Understanding Apache Spark Streaming Applications。（https://databricks.com/blog/2015/07/08/new-visualizations-for-understanding-apache-spark-streaming-applications.html）。
知道了这一点，让我们重写原来的 streaming_word_count.py，来获得这个名为 stateful_streaming_word_count.py的有状态的版本；获取该脚本的完整版本，请访问 https://github.com/drabastomek/learningPySpark/blob/master/Chapter10/stateful_streaming_word_count.py。
脚本的初始命令集注解如下：
·如果你还记得 streaming_word_count.py，主要区别始于第 11 行：
·第 12 行的 ssc.checkpoint（“checkpoint”）给 Spark Streaming配置了一个检查点（checkpoint）。为了确保 Spark Streaming因其持续运行可以容错，需要检查足够的信息以进行容错存储，从而可以从故障中恢复。请注意，我们不会深入了解此概念（尽管下面的提示部分提供了更多信息），因为这些配置中的大部分将被抽出结构化流。
·第 15 行的 updateFunc 告诉程序通过 UpdateStateByKey 更新应用程序的状态（在后续代码中）。在这种情况下，它返回上一个值（last_sum）和新值（sum（new_values）＋（last_sum或 0））之和。
·第 19 行的 ssc.socketTextStream与之前的脚本相同。有关 Spark Streaming检查点的更多信息，这里提供了一些很好的参考：
Spark Streaming Programming Guide>Checkpoint（https://spark.apache.org/docs/1.6.0/streaming-programming-guide.html#checkpointing）；
Exploring Stateful Streaming with Apache Spark（http://asyncified.io/2016/07/31/exploring-stateful-streaming-with-apache-spark/）。
代码的最后一部分如下：
虽然第 10-14行与之前的脚本相同，但区别在于，我们现在有一个 running_counts变量，它可以通过分隔来获取单词并运行一个映射函数以便统计每批中的每个单词（在之前的脚本中，是 words 和 pairs 变量）。
主要区别在于使用了 updateStateByKey 方法，该方法将执行前面提到的执行加和的 updateFunc。updateStateByKey是 Spark Streaming的方法，用于对数据流执行计算，并以有利于性能的方式更新每个 key 的状态。有一点非常重要的是，通常在 Spark 1.5及更早版本中使用 updateStateByKey；这些有状态的全局聚合的性能与状态的大小成比例。从 Spark 1.6起，你应该使用 mapWithState，因为性能


与批量的大小成正比。
请注意，通常有更多的代码使用 mapWithState（与 updateStateByKey 相比），因此这里的示例使用 updateStateByKey 编写。关于有状态 Spark Streaming的更多信息，包括如何使用 mapWithState，请参考：Stateful Network Wordcount python example：https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/stateful_network_wordcount.py；
Global Aggregation using mapWithState（Scala）：https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html#07％20Spark％20Streaming/12％20Global％20 Aggregations％20-％20mapWithState.html；
Word count using mapWithState（Scala）：https://docs.cloud.databricks.com/docs/spark/1.6/examples/Streaming％20 mapWithState.html；
Faster Stateful Stream Processing in Apache Spark Streaming：https://databricks.com/blog/2016/02/01/faster-stateful-stream-processing-in-apache-spark-streaming.html。
