---
title: 05 其他应用
toc: true
date: 2019-06-05
---
# 可以补充进来的

- 知识表示、推理和回答没看懂


# 其他应用

在本节中，我们介绍深度学习一些其他类型的应用，它们与上面讨论的标准对象识别、语音识别和自然语言处理任务不同。本书的第 3 部分将扩大这个范围，甚至进一步扩展到仍是目前主要研究领域的任务。

## 1. 推荐系统

信息技术部门中机器学习的主要应用之一是向潜在用户或客户推荐项目。这可以分为两种主要的应用：在线广告和项目建议(通常这些建议的目的仍然是为了销售产品)。两者都依赖于预测用户和项目之间的关联，一旦向该用户展示了广告或推荐了该产品，推荐系统要么预测一些行为的概率(用户购买产品或该行为的一些代替)或预期增益(其可取决于产品的价值)。目前，互联网的资金主要来自各种形式的在线广告。经济的主要部分依靠网上购物。包括 Amazon 和 eBay 在内的公司都使用了机器学习(包括深度学习)推荐他们的产品。有时，项目不是实际出售的产品，如选择在社交网络新闻信息流上显示的帖子、推荐观看的电影、推荐笑话、推荐专家建议、匹配视频游戏的玩家或匹配约会的人。

通常，这种关联问题可以作为监督学习问题来处理：给出一些关于项目和关于用户的信息，预测感兴趣的行为(用户点击广告、输入评级、点击“喜欢”按钮、购买产品，在产品上花钱、花时间访问产品页面等)。通常这最终会归结到回归问题(预测一些条件期望值)或概率分类问题(预测一些离散事件的条件概率)。

早期推荐系统的工作依赖于这些预测输入的最小信息：用户 ID 和项目 ID。在这种情况下，唯一的泛化方式依赖于不同用户或不同项目的目标变量值之间的模式相似性。假设用户 1 和用户 2 都喜欢项目 A，B和 C。由此，我们可以推断出用户 1 和用户 2 具有类似的口味。如果用户 1 喜欢项目 D，那么这可以强烈提示用户 2 也喜欢 D。基于此原理的算法称为协同过滤(collaborative filtering)。<span style="color:red;">嗯。</span>非参数方法(例如基于估计偏好模式之间相似性的最近邻方法)和参数方法都可能用来解决这个问题。参数方法通常依赖于为每个用户和每个项目学习分布式表示(也称为嵌入)。<span style="color:red;">为什么叫做嵌入呢？嵌入这个词哪来的？</span>目标变量的双线性预测(例如评级)是一种简单的参数方法，这种方法非常成功，通常被认为是最先进系统的组成部分。通过用户嵌入和项目嵌入之间的点积(可能需要使用仅依赖于用户 ID 或项目 ID 的常数来校正)获得预测。令 $\hat{\boldsymbol{R}}$ 是包含我们预测的矩阵，$\boldsymbol{A}$ 矩阵行中是用户嵌入，$\boldsymbol{B}$ 矩阵列中具有项目嵌入。令 $\boldsymbol{b}$ 和 $\boldsymbol{c}$ 是分别包含针对每个用户(表示用户平常坏脾气或积极的程度)以及每个项目(表示其大体受欢迎程度)的偏置向量。因此，双线性预测如下获得：

$$
\hat{R}_{u, i}=b_{u}+c_{i}+\sum_{j} A_{u, j} B_{j, i\cdot}\tag{12.20}
$$

通常，人们希望最小化预测评级 $\hat{R}_{u, i}$ 和实际评级 $R_{u, i}$ 之间的平方误差。当用户嵌入和项目嵌入首次缩小到低维度(两个或三个)时，它们就可以方便地可视化，或者可以将用户或项目彼此进行比较(就像词嵌入)。获得这些嵌入的一种方式是对实际目标(例如评级)的矩阵 $\boldsymbol{R}$ 进行奇异值分解。这对应于将 $\boldsymbol{R}=\boldsymbol{U} \boldsymbol{D} \boldsymbol{V}^{\prime}$ (或归一化的变体)分解为两个因子的乘积，低秩矩阵 $\boldsymbol{A}=\boldsymbol{U} \boldsymbol{D}$ 和 $\boldsymbol{B}=\boldsymbol{V}^{\prime}$。SVD的一个问题是它以任意方式处理缺失条目，如同它们对应于目标值 0。相反，我们希望避免为缺失条目做出的预测付出任何代价。幸运的是，观察到的评级的平方误差总和也可以使用基于梯度的优化最小化。SVD和式(12.20)中的双线性预测在 Netflix 奖竞赛中(目的是仅基于大量匿名用户的之前评级预测电影的评级)表现得非常好(Bennett and Lanning,2007)。许多机器学习专家参加了 2006 年和 2009 年之间的这场比赛。它提高了使用先进机器学习的推荐系统的研究水平，并改进了推荐系统。即使简单的双线性预测或 SVD 本身并没有赢得比赛，但它是大多数竞争对手提出的整体模型中一个组成部分，包括胜者(T-scher et al.,2009;Koren,2009)。

除了这些具有分布式表示的双线性模型之外，第一次用于协同过滤的神经网络之一是基于 RBM 的无向概率模型(Salakhutdinov et al.,2007)。RBM是 Netflix 比赛获胜方法的一个重要组成部分(T-scher et al.,2009;Koren,2009)。神经网络社群中也已经探索了对评级矩阵进行因子分解的更高级变体(Salakhutdinov and Mnih,2008)。<span style="color:red;">什么更高级变体？</span>

然而，协同过滤系统有一个基本限制：当引入新项目或新用户时，缺乏评级历史意味着无法评估其与其他项目或用户的相似性，或者说无法评估新的用户和现有项目的联系。这被称为冷启动推荐问题。解决冷启动推荐问题的一般方式是引入单个用户和项目的额外信息。例如，该额外信息可以是用户简要信息或每个项目的特征。使用这种信息的系统被称为基于内容的推荐系统(content-based recommender system)。<span style="color:red;">嗯。</span>从丰富的用户特征或项目特征集到嵌入的映射可以通过深度学习架构学习(Huang et al.,2013;Elkahky et al.,2015)。<span style="color:red;">还有这个名词吗？</span>

专用的深度学习架构，如卷积网络已经应用于从丰富内容中提取特征，如提取用于音乐推荐的音乐音轨(vanden O-rd et al.,2013)。在该工作中，卷积网络将声学特征作为输入并计算相关歌曲的嵌入。该歌曲嵌入和用户嵌入之间的点积则可以预测用户是否将收听该歌曲。<span style="color:red;">嗯，是的。</span>

### 1.1 探索与利用

当向用户推荐时，会产生超出普通监督学习范围的问题，并进入强化学习的领域。理论上，许多推荐问题最准确的描述是 contextual bandit(Langford and Zhang,2008; Lu et al.,2010)。问题是，当我们使用推荐系统收集数据时，我们得到是一个有偏且不完整的用户偏好观：我们只能看到用户对推荐给他们项目的反应，而不是其他项目。此外，在某些情况下，我们可能无法获得未向其进行推荐的用户的任何信息(例如，在广告竞价中，可能是广告的建议价格低于最低价格阈值，或者没有赢得竞价，因此广告不会显示)。更重要的是，我们不知道推荐任何其他项目会产生什么结果。这就像训练一个分类器，为每个训练样本 $\boldsymbol{x}$ 挑选一个类别 $\hat{y}$(通常是基于模型最高概率的类别)，然后只能获得该类别正确与否的反馈。显然，每个样本传达的信息少于监督的情况(其中真实标签 $y$ 是可直接访问的)，因此需要更多的样本。更糟糕的是，如果我们不够小心，即使收集越来越多的数据，我们得到的系统可能会继续选择错误的决定，因为正确的决定最初只有很低的概率：直到学习者选择正确的决定之前，该系统都无法学习正确的决定。这类似于强化学习的情况，其中仅观察到所选动作的奖励。一般来说，强化学习会涉及许多动作和许多奖励的序列。bandit 情景是强化学习的特殊情况，其中学习者仅采取单一动作并接收单个奖励。bandit问题在学习者知道哪个奖励与哪个动作相关联的时候更容易。在一般的强化学习场景中，高奖励或低奖励可能是由最近的动作或很久以前的动作引起的。术语 contextual bandit 指的是在一些输入变量可以通知决定的上下文中采取动作的情况。例如，我们至少知道用户身份，并且我们要选择一个项目。从上下文到动作的映射也称为策略(policy)。学习者和数据分布(现在取决于学习者的动作)之间的反馈循环是强化学习和 bandit 研究的中心问题。<span style="color:red;">挺好。</span>

强化学习需要权衡探索(exploration)与利用(exploitation)。利用指的是从目前学到的最好策略采取动作，也就是我们所知的将获得高奖励的动作。探索是指采取行动以获得更多的训练数据。如果我们知道给定上下文 $\boldsymbol{x}$，动作 $a$ 给予我们 $1$ 的奖励，但我们不知道这是否是最好的奖励。我们可能想利用我们目前的策略，并继续采取行动 $a$ 相对肯定地获得 $1$ 的奖励。然而，我们也可能想通过尝试动作 $a^{\prime}$ 来探索。我们不知道尝试动作 $a^{\prime}$ 会发生什么。我们希望得到 $2$ 的奖励，但有获得 $0$ 奖励的风险。无论如何，我们至少获得了一些知识。<span style="color:red;">是的，会获得一些知识。</span>

探索可以以许多方式实现，从覆盖可能动作的整个空间的随机动作到基于模型的方法(基于预期回报和模型对该回报不确定性的量来计算动作的选择)。

许多因素决定了我们喜欢探索或利用的程度。最突出的因素之一是我们感兴趣的时间尺度。如果代理只有短暂的时间积累奖励，那么我们喜欢更多的利用。如果代理有很长时间积累奖励，那么我们开始更多的探索，以便使用更多的知识更有效地规划未来的动作。<span style="color:red;">时间尺度的影响。</span>

监督学习在探索或利用之间没有权衡，因为监督信号总是指定哪个输出对于每个输入是正确的。我们总是知道标签是最好的输出，没有必要尝试不同的输出来确定是否优于模型当前的输出。

除了权衡探索和利用之外，强化学习背景下出现的另一个困难是难以评估和比较不同的策略。强化学习包括学习者和环境之间的相互作用。这个反馈回路意味着使用固定的测试集输入评估学习者的表现不是直接的。策略本身确定将看到哪些输入。Dudik et al.(2011)提出了评估 contextualb andit 的技术。<span style="color:red;">怎么评估的？想知道。</span>

## 2. 知识表示、推理和回答

<span style="color:red;">没看懂。再看下。</span>


因为使用符号(Rumelhart et al.,1986a)和词嵌入(Deerwester et al.,1990;Bengio et al.,2001b)，深度学习方法在语言模型、机器翻译和自然语言处理方面非常成功。这些嵌入表示关于单个词或概念的语义知识。研究前沿是为短语或词和事实之间的关系开发嵌入。搜索引擎已经使用机器学习来实现这一目的，但是要改进这些更高级的表示还有许多工作要做。

### 2.1 知识、联系和回答


一个有趣的研究方向是确定如何训练分布式表示才能捕获两个实体之间的关系(relation)。

数学中，二元关系是一组有序的对象对。集合中的对具有这种关系，而那些不在集合中的对则没有。例如，我们可以在实体集 $\{1,2,3\}$ 上定义关系“小于”来定义有序对的集合 $\mathbb{S}=\{(1,2),(1,3),(2,3)\}$。一旦这个关系被定义，我们可以像动词一样使用它。因为 $(1,2) \in \mathbb{S}$，我们说 1 小于 2。因为 $(2,1) \notin \mathrm{S}$ ，我们不能说 2 小于 1。当然，彼此相关的实体不必是数字。我们可以定义关系 `is_a_type_of` 包含如 $(狗，哺乳动物)$ 的元组。

在 AI 的背景下，我们将关系看作句法上简单且高度结构化的语言。关系起到动词的作用，而关系的两个参数发挥着主体和客体的作用。这些句子是一个三元组标记的形式：

$$
(subject, verb, object)
$$

其值是

$$
(entity _{i},relation _{j}, entity _{k} )
$$

我们还可以定义属性(attribute)，类似于关系的概念，但只需要一个参数：

$$
(entity_i, attribute _{j} )
$$


例如，我们可以定义 `has_fur` 属性，并将其应用于像狗这样的实体。

许多应用中需要表示关系和推理。我们如何在神经网络中做到这一点？

机器学习模型当然需要训练数据。我们可以推断非结构化自然语言组成的训练数据集中实体之间的关系，也可以使用明确定义关系的结构化数据库。这些数据库的共同结构是关系型数据库，它存储这种相同类型的信息，虽然没有格式化为三元标记的句子。当数据库旨在将日常生活中常识或关于应用领域的专业知识传达给人工智能系统时，我们将这种数据库称为知识库。知识库包括一般的，像 Freebase、Open Cyc、Word Net、Wikibase 等；还包括专业的知识库，如 Gene Ontology。实体和关系的表示可以将知识库中的每个三元组作为训练样本来学习，并且以最大化捕获它们的联合分布为训练目标(Bordes et al.,2013a)。<span style="color:red;">厉害厉害，想知道这个后续是什么样了。</span>

除了训练数据，我们还需定义训练的模型族。一种常见的方法是将神经语言模型扩展到模型实体和关系。神经语言模型学习提供每个词分布式表示的向量。他们还通过学习这些向量的函数来学习词之间的相互作用，例如哪些词可能出现在词序列之后。我们可以学习每个关系的嵌入向量将这种方法扩展到实体和关系。事实上，建模语言和通过关系编码建模知识的联系非常接近，研究人员可以同时使用知识库和自然语言句子训练这样的实体表示(Bordes et al.,2011,2012;Wang et al.,2014a)，或组合来自多个关系型数据库的数据(Bordes et al.,2013b)。可能与这种模型相关联的特定参数化有许多种。早期关于学习实体间关系的工作(Paccanaro and Hinton,2000)假定高度受限的参数形式(“线性关系嵌入”)，通常对关系使用与实体形式不同的表示。例如，Paccanaro and Hinton(2000)和 Bordes et al.(2011)用向量表示实体而矩阵表示关系，其思想是关系在实体上相当于运算符。或者，关系可以被认为是任何其他实体(Bordes et al.,2012)，允许我们关于关系作声明，但是更灵活的是将它们结合在一起并建模联合分布的机制。

这种模型的实际短期应用是链接预测(link prediction)：预测知识图谱中缺失的弧。这是基于旧事实推广新事实的一种形式。目前存在的大多数知识库都是通过人力劳动构建的，这往往使知识库缺失许多并且可能是大多数真正的关系。请查看 Wang et al.(2014b)、Lin et al.(2015)和 Garcia-Duran et al.(2015)中这样应用的例子。

我们很难评估链接预测任务上模型的性能，因为我们的数据集只有正样本(已知是真实的事实)。如果模型提出了不在数据集中的事实，我们不确定模型是犯了错误还是发现了一个新的以前未知的事实。度量基于测试模型如何将已知真实事实的留存集合与不太可能为真的其他事实相比较，因此有些不精确。构造感兴趣的负样本(可能为假的事实)的常见方式是从真实事实开始，并创建该事实的损坏版本，<span style="color:red;">哦，原来这就是损坏样本。嗯。</span>例如用随机选择的不同实体替换关系中的一个实体。通用的测试精度(10%度量)计算模型在该事实的所有损坏版本的前 10%中选择“正确”事实的次数。

知识库和分布式表示的另一个应用是词义消歧(word-sense disambiguation)(Navigli and Velardi,2005;Bordes et al.,2012)，这个任务决定在某些语境中哪个词的意义是恰当的。

最后，知识的关系结合一个推理过程和对自然语言的理解可以让我们建立一个一般的问答系统。一般的问答系统必须能处理输入信息并记住重要的事实，并以之后能检索和推理的方式组织。这仍然是一个困难的开放性问题，只能在受限的“玩具”环境下解决。目前，记住和检索特定声明性事实的最佳方法是使用显式记忆机制，如第 10.12节所述。记忆网络最开始是被用来解决一个玩具问答任务(Weston et al.,2014)。Kumar et al.(2015b)提出了一种扩展，使用 GRU 循环网络将输入读入存储器并且在给定存储器的内容后产生回答。

深度学习已经应用于其他许多应用(除了这里描述的应用以外)，并且肯定会在此之后应用于更多的场景。我们不可能全面描述与此主题相关的所有应用。本项调查尽可能地提供了在本文写作之时的代表性样本。

本书第 2 部分介绍了涉及深度学习的现代实践，囊括了所有非常成功的方法。一般而言，这些方法使用代价函数的梯度寻找模型(近似于某些所期望的函数)的参数。当具有足够的训练数据时，这种方法是非常强大的。我们现在转到第 3 部分，开始进入研究领域，旨在使用较少的训练数据或执行更多样的任务。而且相比目前为止所描述的情况，其中的挑战更困难并且远远没有解决。



# 相关

- 《深度学习》花书
