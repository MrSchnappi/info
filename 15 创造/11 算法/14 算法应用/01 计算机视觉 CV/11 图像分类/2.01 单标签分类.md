---
title: 2.01 单标签分类
toc: true
date: 2019-09-04
---
# 单标签分类

单标签分类是 简单的分类任务，图片的内容相对简单，只包含一个物体或者场景。ImageNet就属于单标签分类的数据集。下面通过 ImageNet 比赛的时间脉络，介绍下单标签分类的进展情况。

**AlexNet：** 2012年提出的 AlexNet 网络结构模型引爆了神经网络的应用热潮，并赢得了 2012 届图像识别大赛的冠军，使得 CNN 成为在图像分类上的核心算法模型。

**ZFNet：** 2013年 ILSVRC 分类任务冠军网络是 Clarifai，不过更为我们熟知的是 ZFNet。Hinton的学生 Zeiler 和 Fergus 在研究中利用反卷积技术引入了神经网络的可视化，对网络的中间特征层进行了可视化，为研究人员检验不同特征激活及其与输入空间的关系成为了可能。在这个指导下对 AlexNet 网络进行了简单改进，包括使用了更小的卷积核和步长，将 11x11 的卷积核变成 7x7 的卷积核，将 stride 从 4 变成了 2，性能超过了原始的 AlexNet 网络。

**VGGNet：** 2014年的亚军，VGGNet包括 16 层和 19 层两个版本，共包含参数约为 550M。全部使用 3×3的卷积核和 2×2的 大池化核，简化了卷积神经网络的结构。VGGNet很好的展示了如何在先前网络架构的基础上通过简单地增加网络层数和深度就可以提高网络的性能。虽然简单，但是却异常的有效，在今天，VGGNet仍然被很多的任务选为基准模型。

**GoogLeNet：** 来自于 Google 的 Christian Szegedy等人提出的 22 层的网络，其 top-5分类错误率只有 6.7%。GoogleNet的核心是 Inception Module，它采用并行的方式。一个经典的 inception 结构，包括有四个成分。1×1卷积，3×3卷积，5×5卷积，3×3大池化，后对四个成分运算结果进行通道上组合。这就是 Inception Module的核心思想。通过多个卷积核提取图像不同尺度的信息然后进行融合，可以得到图像更好的表征。自此，深度学习模型的分类准确率已经达到了人类的水平(5%~10%)。

**ResNet：** 2015年获得了分类任务冠军。它以 3.57%的错误率表现超过了人类的识别水平，并以 152 层的网络架构创造了新的模型记录。由于 ResNet 采用了跨层连接的方式，它成功的缓解了深层神经网络中的梯度消散问题，为上千层的网络训练提供了可能。

**ResNet** 2016年依旧诞生了许多经典的模型，包括赢得分类比赛第二名的 ResNeXt，101层的 ResNeXt 可以达到 ResNet152 的精确度，却在复杂度上只有后者的一半，核心思想为分组卷积。即首先将输入通道进行分组，经过若干并行分支的非线性变换，后合并。

**DenseNet：** 在 ResNet 基础上，密集连接的 DenseNet 在前馈过程中将每一层与其他的层都连接起来。对于每一层网络来说，前面所有网络的特征图都被作为输入，同时其特征图也都被后面的网络层作为输入所利用。DenseNet中的密集连接还可以缓解梯度消失的问题，同时相比 ResNet，可以更强化特征传播和特征的复用，并减少了参数的数目。DenseNet相较于 ResNet 所需的内存和计算资源更少，并达到更好的性能。

**SeNet：** 2017年也是 ILSVRC 图像分类比赛的 后一年，SeNet获得了冠军。这个结构，仅仅使用了“特征重标定”的策略来对特征进行处理，通过学习获取每个特征通道的重要程度，根据重要性去降低或者提升相应的特征通道的权重。

至此，图像分类的比赛基本落幕，也接近算法的极限。但是，在实际的应用中，却面临着比比赛中更加复杂和现实的问题，需要大家不断积累经验。

目前，随着 NASNet（Neural Architecture Search Network）的崛起，效果好的基本都是这些网络比如：NASNet、PNasNet、AmoebaNet，尤其是近 Google 新出的 EfficientNet，更是对其他网络有碾压式的提升，下面的图片一目了然：


<center>

![mark](http://images.iterate.site/blog/image/20190903/evofhl8Sm81Q.png?imageslim)

</center>
