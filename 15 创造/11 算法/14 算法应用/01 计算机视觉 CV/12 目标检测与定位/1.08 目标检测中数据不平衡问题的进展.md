---
title: 1.08 目标检测中数据不平衡问题的进展
toc: true
date: 2019-09-20
---
# 目标检测中的不平衡问题的进展

## 1 GHM_Detection

*论文：https://arvix.org/pdf/1811.05181.pdfgithub：https://github.com/libuyu/GHM_Detection*

本文是香港中文大学发表于 AAAI 2019 的工作，**文章从梯度的角度解决样本中常见的正负样本不均衡的问题。**从梯度的角度给计算 loss 的样本加权，相比与 OHEM 的硬截断，这种思路和 Focal Loss 一样属于软截断。

**文章设计的思路不仅可以用于分类 loss 改进，对回归 loss 也很容易进行嵌入。****不需要考虑 Focal Loss 的超参设计问题，同时文章提出的方法效果比 Focal Loss 更好。**创新点相当于 FL 的下一步方案，给出了解决 class-imbalance 的另一种思路，开了一条路，估计下一步会有很多这方面的 paper 出现。

## 2 Focal Loss for Dense Object Detection

论文：

Focal Loss：https://arxiv.org/abs/1708.02002

RetinaNet：https://github.com/unsky/RetinaNet

github：https://github.com/unsky/focal-loss

本文通过重塑标准交叉熵损失来解决这一类不平衡问题。他们的想法是降低简单的负面样本所占的权重，所以他们提出的焦点损失（Focal Loss）方法将训练集中在一系列难点上，并且防止了大量的简单负面例子在训练过程中阻碍探测器学习。如上图，参数 γ 的值选择得越大，模型就会对已经得到了很好的分类的样本忽略得越多，越专注于难的样本的学习。这样的机制就让他们的检测器在密集对象检测这样的真实正面样本比例很低的情况下取得了很高的准确率。对于应对样本不平衡问题的关键方法“焦距损失”，作者们在论文中还提出了两种不同的表现形式，都起到了很好的效果.

## 3 在线困难样例挖掘(online hard example mining, OHEM)

目标检测的另一个问题是类别不平衡，图像中大部分的区域是不包含目标的，而只有小部分区域包含目标。此外，不同目标的检测难度也有很大差异，绝大部分的目标很容易被检测到，而有一小部分目标却十分困难。OHEM和 Boosting 的思路类似，其根据损失值将所有候选区域进行排序，并选择损失值最高的一部分候选区域进行优化，使网络更关注于图像中更困难的目标。此外，为了避免选到相互重叠很大的候选区域，OHEM对候选区域根据损失值进行 NMS。


总之，针对数据不平衡问题，有多重解决方式，但是不能为了解决这个问题就去改变数据的真实分布来得到更好的结果，可以从算法、loss function的设计等等多种角度来选择解决数据不平衡的方法。



# 相关

- [【机器学习】如何解决数据不平衡问题](https://www.cnblogs.com/charlotte77/p/10455900.html)
