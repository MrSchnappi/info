---
title: 2.11 R-CNN
toc: true
date: 2019-09-03
---

### 8.2.1 R-CNN

**R-CNN 有哪些创新点？**

1. 使用 CNN（ConvNet）对 region proposals 计算 feature vectors。从经验驱动特征（SIFT、HOG）到数据驱动特征（CNN feature map），提高特征对样本的表示能力。<span style="color:red;">嗯，的确是从经验驱动特征到数据驱动特征。</span>
2. 采用大样本下（ILSVRC）有监督预训练和小样本（PASCAL）微调（fine-tuning）的方法解决小样本难以训练甚至过拟合等问题。<span style="color:red;">嗯，是的，现在大家都是这么做的。</span>

注：ILSVRC 其实就是众所周知的 ImageNet 的挑战赛，数据量极大；PASCAL 数据集（包含目标检测和图像分割等），相对较小。

**R-CNN 介绍**

R-CNN 作为 R-CNN 系列的第一代算法，其实没有过多的使用“深度学习”思想，而是将 “深度学习” 和传统的 “计算机视觉” 的知识相结合。比如 R-CNN pipeline 中的第二步和第四步其实就属于传统的“计算机视觉”技术。使用 selective search 提取 region proposals，使用 SVM 实现分类。<span style="color:red;">嗯，使用 SVM 实现的分类。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/HQGfE144145F.png?imageslim){ width=75% }

</center>


原论文中 R-CNN pipeline 只有 4 个步骤，光看上图无法深刻理解 R-CNN 处理机制，下面结合图示补充相应文字

1. 预训练模型。选择一个预训练 （pre-trained）神经网络（如 AlexNet、VGG）。

2. 重新训练全连接层。使用需要检测的目标重新训练（re-train）最后全连接层（connected layer）。<span style="color:red;">嗯，只微调全连接层。</span>

3. 提取 proposals 并计算 CNN 特征。利用选择性搜索（Selective Search）算法提取所有 proposals（大约 2000 幅 images），调整（resize/warp）它们成固定大小，以满足 CNN 输入要求（因为全连接层的限制），然后将 feature map 保存到本地磁盘。<span style="color:red;">selective search 怎么提取所有的 proposal 的？resize 成固定大小不是会发生形变吗？</span>

<center>

![](http://images.iterate.site/blog/image/20190722/G1WEgDavMlNb.png?imageslim){ width=75% }

</center>


4. 训练 SVM。利用 feature map 训练 SVM 来对目标和背景进行分类（每个类一个二进制 SVM）<span style="color:red;">什么是每个类一个二进制 SVM？是多个 SVM 来实现多分类吗？</span>

5. 边界框回归（Bounding boxes Regression）。训练将输出一些校正因子的线性回归分类器。<span style="color:red;">什么意思？矫正因子的线性回归分类器？是什么？</span>

<center>

![](http://images.iterate.site/blog/image/20190722/aMqfVHPre5TE.png?imageslim){ width=55% }

</center>


**R-CNN 实验结果**

R-CNN 在 VOC 2007 测试集上 mAP 达到 58.5%，打败当时所有的目标检测算法。<span style="color:red;">mAP 是什么指标，忘记了。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/YE2FYzYIKA5c.png?imageslim){ width=85% }

</center>

















R-CNN

Region CNN(简称 R-CNN)由 Ross Girshick

（江湖人称 RBG 大神，Felzenszwalb的学生）提出，是利用深度学习进行目标检测的里程碑之作，奠定了这个子领域的基础。这篇文章思路清奇，在 DPM 方法经历多年瓶颈期后，显著提升了检测率（ILSVRC 2013数据集上的 mAP 为 31.4%）。RBG是这个领域神一样的存在，后续的一些改进方法如 Fast R-CNN、Faster R-CNN、YOLO等相关工作都和他有关。



![mark](http://images.iterate.site/blog/image/20190905/Xp5fnErX4gGr.png?imageslim)

R-CNN检测时的主要步骤为：

1.使用 Selective Search算法从待检测图像中提取 2000 个左右的区域候选框，这些候选框可能包含要检测的目标。

2.把所有侯选框缩放成固定大小（原文采用 227×227）。

3.用 DCNN 提取每个候选框的特征，得到固定长度的特征向量。

4.把特征向量送入 SVM 进行分类得到类别信息，送入全连接网络进行回归得到对应位置坐标信息。



R-CNN不采用滑动窗口方案的原因一是计算成本高，会产生大量的待分类窗口；另外不同类型目标的矩形框有不同的宽高比，无法使用统一尺寸的窗口对图像进行扫描。用于提取特征的卷积网络有 5 个卷积层和 2 个全连接层，其输入是固定大小的 RGB 图像，输出为 4096 维特征向量。对候选区域的分类采用线性支持向量机，对每一张待检测图像计算所有候选区域的特征向量，送入支持向量机中进行分类；同时送入全连接网络进行坐标位置回归。



![mark](http://images.iterate.site/blog/image/20190905/eXLVTHBhvMkp.png?imageslim)


R-CNN虽然设计巧妙，但仍存在很多缺点：

1.重复计算。R-CNN虽然不再是穷举，但通过 Proposal（Selective Search）的方案依然有两千个左右的候选框，这些候选框都需要单独经过 backbone 网络提取特征，计算量依然很大，候选框之间会有重叠，因此有不少其实是重复计算。

2.训练测试不简洁。候选区域提取、特征提取、分类、回归都是分开操作，中间数据还需要单独保存。

3.速度慢。前面的缺点最终导致 R-CNN出奇的慢，GPU上处理一张图片需要十几秒，CPU上则需要更长时间。

4.输入的图片 Patch 必须强制缩放成固定大小（原文采用 227×227），会造成物体形变，导致检测性能下降。






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
