---
title: 3.11 YOLOv1
toc: true
date: 2019-09-03
---
# 可以补充进来的

- [你真的读懂yolo了吗？](https://zhuanlan.zhihu.com/p/37850811)

# YOLOv1

2015年，随着 YOLO 算法的出现，深度学习目标检测算法开始有了两步（two-stage）和单步（single-stage）之分。区别于 R-CNN系列为代表的两步检测算法，YOLO舍去了候选框提取分支（Proposal阶段），直接将特征提取、候选框回归和分类在同一个无分支的卷积网络中完成，使得网络结构变得简单，检测速度较 Faster R-CNN也有近 10 倍的提升。这使得深度学习目标检测算法在当时的计算能力下开始能够满足实时检测任务的需求。



算法将待检测图像缩放到统一尺寸，为了检测不同位置的目标，将图像等分成的网格，如果某个目标的中心落在一个网格单元中，此网格单元就负责预测该目标。



YOLOv1只针对最后 7x7 的特征图进行分析，使得它对小目标的检测效果不佳，当多个目标出现在一个 Grid Cell时不容易区分。

![mark](http://images.iterate.site/blog/image/20190905/kfePnEhy0TDr.png?imageslim)


YOLOv1原理图

![img](https://mmbiz.qpic.cn/mmbiz_gif/75DkJnThACk7Enjq0LvHgt8DtQeUV9nQWcZQVTDiaRQDzEmeRuqOCXDeicK2Zdr7BK3AZhu2zMsSTrUicd9HEXzPg/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

YOLOv1在 7X7 特征图上对每个 Grid cell进行操作






**YOLOv1 有哪些创新点？**

1. 将整张图作为网络的输入，直接在输出层回归 bounding box 的位置和所属的类别
2. 速度快，one stage detection 的开山之作

**YOLOv1 介绍**

YOLO（You Only Look Once: Unified, Real-Time Object Detection）是 one-stage detection 的开山之作。之前的物体检测方法首先需要产生大量可能包含待检测物体的先验框，然后用分类器判断每个先验框对应的边界框里是否包含待检测物体，以及物体所属类别的概率或者置信度，同时需要后处理修正边界框，最后基于一些准则过滤掉置信度不高和重叠度较高的边界框，进而得到检测结果。这种基于先产生候选区再检测的方法虽然有相对较高的检测准确率，但运行速度较慢。

YOLO 创造性的将物体检测任务直接当作回归问题（regression problem）来处理，将候选区和检测两个阶段合二为一。<span style="color:red;">怎么作为回归问题进行处理的？</span>只需一眼就能知道每张图像中有哪些物体以及物体的位置。下图展示了各物体检测系统的流程图。

<center>

![](http://images.iterate.site/blog/image/20190722/B1kjzxHDEK3y.png?imageslim){ width=75% }

</center>


事实上，YOLO 也并没有真正的去掉候选区，而是直接将输入图片划分成 7x7=49 个网格，每个网格预测两个边界框，一共预测 49x2=98 个边界框。可以近似理解为在输入图片上粗略的选取 98 个候选区，这 98 个候选区覆盖了图片的整个区域，进而用回归预测这 98 个候选框对应的边界框。

**1. 网络结构是怎样的？**

YOLO 网络借鉴了 GoogLeNet 分类网络结构，不同的是 YOLO 使用 1x1 卷积层和 3x3 卷积层替代 inception module。如下图所示，整个检测网络包括 24 个卷积层和 2 个全连接层。其中，卷积层用来提取图像特征，全连接层用来预测图像位置和类别概率值。

<center>

![](http://images.iterate.site/blog/image/20190722/jDIRdjtMFrbl.png?imageslim){ width=75% }

</center>


**2. YOLO 的输入、输出、损失函数分别是什么？**

前面说到 YOLO 将输入图像分成 7x7 的网格，最后输出是 7x7xk 的张量。YOLO 网络最后接了两个全连接层，全连接层要求输入是固定大小的，所以 YOLO 要求输入图像有固定大小，论文中作者设计的输入尺寸是 448x448。

YOLO 将输入图像分成 7x7 的网格，每个网格预测 2 个边界框。若某物体的 ground truth 的中心落在该网格，则该网格中与这个 ground truth IOU 最大的边界框负责预测该物体。对每个边界框会预测 5 个值，分别是边界框的中心 x,y（相对于所属网格的边界），边界框的宽高 w,h（相对于原始输入图像的宽高的比例），以及这些边界框的 confidencescores（边界框与 ground truth box 的 IOU 值）。同时每个网格还需要预测 c 个类条件概率 （是一个 c 维向量，表示某个物体 object 在这个网格中，且该 object 分别属于各个类别的概率，这里的 c 类物体不包含背景）。论文中的 c=20，则每个网格需要预测 2x5+20=30 个值，这些值被映射到一个 30 维的向量。

为了让边界框坐标损失、分类损失达到很好的平衡，损失函数设计如下图所示。

<center>

![](http://images.iterate.site/blog/image/20190722/LFLA0ywdA2Ky.png?imageslim){ width=85% }

</center>

<center>

![](http://images.iterate.site/blog/image/20190729/SzXSnhbQKLUy.png?imageslim)

</center>


如上图所示，损失函数分为坐标预测（蓝色框）、含有物体的边界框的 confidence 预测（红色框）、不含有物体的边界框的 confidence 预测（黄色框）、分类预测（紫色框）四个部分。

由于不同大小的边界框对预测偏差的敏感度不同，小的边界框对预测偏差的敏感度更大。为了均衡不同尺寸边界框对预测偏差的敏感度的差异。作者巧妙的对边界框的 $w,h$ 取均值再求 L2 loss. YOLO 中更重视坐标预测，赋予坐标损失更大的权重，记为 coord，在 pascal voc 训练中 coodd=5 ，classification error 部分的权重取 1。

某边界框的置信度定义为：

某边界框的 confidence = 该边界框存在某类对象的概率 pr(object)*该边界框与该对象的 ground truth 的 IOU 值

若该边界框存在某个对象 pr(object)=1 ，否则 pr(object)=0 。由于一幅图中大部分网格中是没有物体的，这些网格中的边界框的 confidence 置为 0，相比于有物体的网格，这些不包含物体的网格更多，对梯度更新的贡献更大，会导致网络不稳定。为了平衡上述问题，YOLO 损失函数中对没有物体的边界框的 confidence error 赋予较小的权重，记为 noobj，对有物体的边界框的 confidence error 赋予较大的权重。在 pascal VOC 训练中 noobj=0.5，有物体的边界框的 confidence error 的权重设为 1。

**3. YOLO 怎样预测？**

YOLO 最后采用非极大值抑制（NMS）算法从输出结果中提取最有可能的对象和其对应的边界框。

输入一张图片到 YOLO 网络将输出一个 $7*7*30$ 的张量表示图片中每个网格对应的可能的两个边界框以及每个边界框的置信度和包含的对象属于各个类别的概率。由此可以计算某对象 $i$ 属于类别 同时在第 $j$ 个边界框中的得分：

$$
\text {Score}_{i j}=p_{r}\left(\text {class}_{i} | \text { object }\right) * \text { confidence}_{j}
$$


每个网格有 20 个类条件概率，2 个边界框置信度，相当于每个网格有 40 个得分，7x7 个网格有 1960 个得分，每类对象有 1960/20=98 个得分，即 98 个候选框。

**NMS 步骤如下：**

1. 设置一个 Score 的阈值，一个 IOU 的阈值；
2. 对于每类对象，遍历属于该类的所有候选框，
    a. 过滤掉 Score 低于 Score 阈值的候选框；
    b. 找到剩下的候选框中最大 Score 对应的候选框，添加到输出列表；
    c. 进一步计算剩下的候选框与 b 中输出列表中每个候选框的 IOU，若该 IOU 大于设置的 IOU 阈值，将该候选框过滤掉，否则加入输出列表中；
    d. 最后输出列表中的候选框即为图片中该类对象预测的所有边界框
3. 返回步骤 2 继续处理下一类对象。

YOLO 将识别与定位合二为一，结构简便，检测速度快，更快的 Fast YOLO 可以达到 155FPS。相对于 R-CNN 系列， YOLO 的整个流程中都能看到整张图像的信息，因此它在检测物体时能很好的利用上下文信息，从而不容易在背景上预测出错误的物体信息。同时 YOLO 可以学习到高度泛化的特征，能将一个域上学到的特征迁移到不同但相关的域上，如在自然图像上做训练的 YOLO，在艺术图片上可以得到较好的测试结果。

由于 YOLO 网格设置比较稀疏，且每个网格只预测 2 个边界框，其总体预测精度不高，略低于 Fast RCNN。其对小物体的检测效果较差，尤其是对密集的小物体表现比较差。<span style="color:red;">嗯。</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
