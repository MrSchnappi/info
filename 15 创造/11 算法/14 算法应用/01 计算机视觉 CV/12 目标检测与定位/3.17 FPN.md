---
title: 3.17 FPN
toc: true
date: 2019-09-03
---

### 8.2.5 FPN



FPN

FPN（Feature Pyramid Network）方法同时利用低层特征高分辨率和高层特征的高语义信息，通过融合这些不同层的特征达到提升预测的效果的作用。FPN中预测是在每个融合后的特征层上单独进行的，这和常规的特征融合方式有所不同。



FPN 网络结构如下图 d（其中 YOLO 使用 b 结构，SSD使用 c 结构）所示，它的结构具有相当的灵活性，可以和各种特征提取网络结合作为检测算法的基础网络。在后文中会看到，目前大多数 state-of-art的模型都采用了这种结构。其中 RetinaNet 在 FPN 的基础上使用了 ResNet 网络提取特征，并用 Focal Loss损失改善单步目标检测算法中普遍存在的前景类和背景类损失不均衡的问题。这些基于 FPN 结构的检测算法能够在增加网络深度、获取更丰富语义信息的同时从浅层特征图中获取更丰富且高分辨率的图像特征，这使得这种网络结构在实际应用中表现出优异的性能。



目前主流检测框架有 4 种使用特征的形式：



1.图像金字塔。即将图像缩放到不同的大小，然后不同大小的图像生成对应的特征。这种方法的缺点是增加了时间成本。有些算法会在检测时采用这种图像金字塔的方案。

2.单一尺度特征层。SPPNet，Fast RCNN，Faster RCNN采用这种方式，即仅采用网络最后一层卷积层的特征。

3.SSD采用这种多尺度特征融合的方式，但是没有上采样过程，即从网络不同层抽取不同尺度的特征做预测，这种方式不会增加额外的计算量。SSD算法中没有用到足够低层的特征（在 SSD 中，最低层的特征是 VGG 网络的 conv4_3），而足够低层的特征对于检测小物体是很有帮助的。

4.FPN采用 bottom-up与 top-down的结构，实现了低层特征和高层语义特征的融合，提高了特征映射的信息密度和分辨率，提高了小目标物体的检测效果；区别于 SSD，FPN每层都是独立预测的。

![mark](http://images.iterate.site/blog/image/20190905/D2QGsR81Wmnp.png?imageslim)





**FPN 有哪些创新点？**

1. 多层特征
2. 特征融合

解决目标检测中的多尺度问题，通过简单的网络连接改变，在基本不增加原有模型计算量的情况下，大幅度提升小物体（small object）检测的性能。

在物体检测里面，有限计算量情况下，网络的深度（对应到感受野）与 stride 通常是一对矛盾的东西，常用的网络结构对应的 stride 一般会比较大（如 32），而图像中的小物体甚至会小于 stride 的大小，造成的结果就是小物体的检测性能急剧下降。

传统解决这个问题的思路包括：

1. 图像金字塔（image pyramid），即多尺度训练和测试。但该方法计算量大，耗时较久。<span style="color:red;">嗯。</span>
2. 特征分层，即每层分别预测对应的 scale 分辨率的检测结果，如 SSD 算法。该方法强行让不同层学习同样的语义信息，但实际上不同深度对应于不同层次的语义特征，浅层网络分辨率高，学到更多是细节特征，深层网络分辨率低，学到更多是语义特征。<span style="color:red;">嗯。</span>

因而，目前多尺度的物体检测主要面临的挑战为：

1. 如何学习具有强语义信息的多尺度特征表示？
2. 如何设计通用的特征表示来解决物体检测中的多个子问题？如 object proposal, box localization, instance segmentation.
3. 如何高效计算多尺度的特征表示？

FPN 网络直接在 Faster R-CNN 单网络上做修改，每个分辨率的 feature map 引入后一分辨率缩放两倍的 feature map 做 element-wise 相加的操作。<span style="color:red;">怎么引入的？</span>通过这样的连接，每一层预测所用的 feature map 都融合了不同分辨率、不同语义强度的特征，融合的不同分辨率的 feature map 分别做对应分辨率大小的物体检测。这样保证了每一层都有合适的分辨率以及强语义（rich semantic）特征。同时，由于此方法只是在原网络基础上加上了额外的跨层连接，在实际应用中几乎不增加额外的时间和计算量。

作者接下来实验了将 FPN 应用在 Faster RCNN 上的性能，在 COCO 上达到了 state-of-the-art 的单模型精度。<span style="color:red;">什么是 state-of-the-art ？</span>在 RPN 上，FPN 增加了 8.0 个点的平均召回率（average recall，AR）；在后面目标检测上，对于 COCO 数据集，FPN 增加了 2.3 个点的平均精确率（average precision，AP），对于 VOC 数据集，FPN 增加了 3.8 个点的 AP。



<center>

![](http://images.iterate.site/blog/image/20190722/rzT6eKNyOl1T.png?imageslim){ width=55% }

</center>


FPN 算法主要由三个模块组成，分别是：

1. Bottom-up pathway（自底向上线路）
2. Lareral connections（横向链接）
3. Top-down path（自顶向下线路）

<center>

![](http://images.iterate.site/blog/image/20190722/198amECeWrS4.png?imageslim){ width=55% }

</center>


**Bottom-up pathway**

FPN 是基于 Faster R-CNN 进行改进，其 backbone 是 ResNet-101，FPN 主要应用在 Faster R-CNN 中的 RPN（用于 bouding box proposal generation）和 Fast R-CNN（用于 object detection）两个模块中。

其中 RPN 和 Fast RCNN 分别关注的是召回率（recall）和精确率（precision），在这里对比的指标分别为 Average Recall(AR) 和 Average Precision(AP)。<span style="color:red;">嗯。</span>

注：Bottom-up 可以理解为自底向上，Top-down 可以理解为自顶向下。这里的下是指 low-level，上是指 high-level，分别对应于提取的低级（浅层）特征和高级语义（高层）特征。

Bottom-up pathway 是卷积网络的前向传播过程。在前向传播过程中，feature map 的大小可以在某些层发生改变。一些尺度（scale）因子为 2，所以后一层 feature map 的大小是前一层 feature map 大小的二分之一，根据此关系进而构成了 feature pyramid（hierarchy）。<span style="color:red;">嗯。</span>

然而还有很多层输出的 feature map 是一样的大小（即不进行缩放的卷积），作者将这些层归为同一 stage。对于 feature pyramid，作者为每个 stage 定义一个 pyramid level。

作者将每个 stage 的最后一层的输出作为 feature map，然后不同 stage 进行同一操作，便构成了 feature pyramid。<span style="color:red;">不同 stage 怎么进行同一操作的？</span>

具体来说，对于 ResNets-101，作者使用了每个 stage 的最后一个残差结构的特征激活输出。将这些残差模块输出表示为{C2, C3, C4, C5}，对应于 conv2，conv3，conv4 和 conv5 的输出，并且注意它们相对于输入图像具有{4, 8, 16, 32}像素的步长。考虑到内存占用，没有将 conv1 包含在金字塔中。<span style="color:red;">嗯。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/Ggp0OICjEH6P.png?imageslim){ width=85% }

</center>


**Top-down pathway and lateral connections**

Top-town pathway 是上采样（upsampling）过程。而 later connection（横向连接）是将上采样的结果和 bottom-up pathway 生成的相同大小的 feature map 进行融合（merge）。<span style="color:red;">怎么生成相同大小的 feature map 的？怎么进行融合的？</span>

注：上采样尺度因子为 2，因为为了和之前下采样卷积的尺度因子=2 一样。上采样是放大，下采样是缩小。

具体操作如下图所示，上采样（2x up）feature map 与相同大小的 bottom-up feature map 进行逐像素相加融合（element-wise addition），其中 bottom-up feature 先要经过 1x1 卷积层，目的是为了减少通道维度（reduce channel dimensions）。

注：减少通道维度是为了将 bottom-up feature map 的通道数量与 top-down feature map 的通道数量保持一致，又因为两者 feature map 大小一致，所以可以进行对应位置像素的叠加（element-wise addition）。

<center>

![](http://images.iterate.site/blog/image/20190722/thnB7WAFohHf.png?imageslim){ width=55% }

</center>

<span style="color:red;">嗯，有点懂，又有点云里雾里。这个网络要怎么进行训练？</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
