---
title: 3.20 CornerNet
toc: true
date: 2019-09-30
---
# 可以补充进来的

- CornerNet 是不是应该放在这个地方？顺序确认下。


# CornerNet

CornerNet是密歇根大学Hei Law等人在发表ECCV2018的一篇论文，主要实现目标检测。

## Motivation

CornerNet认为Two-stage目标检测最明显的缺点是 Region Proposal 阶段需要提取的anchor boxes。(1)、提取的anchor boxes数量较多，比如DSSD使用40k， RetinaNet使用100k，anchor boxes众多造成anchor boxes征服样本均衡。(2)、anchor boxes需要调整很多超参数，比如anchor boxes数量、尺寸、比率，影响模型的训练和推断速率。

论文提出one-stage的检测方法，舍弃传统的 anchor boxes思路，提出CornerNet模型预测目标边界框的左上角和右下角一对顶点，既使用单一卷积模型生成热点图和连接矢量：所有目标的左上角和所有目标的右下角热点图，每个顶点的连接矢量(embedding vector)。



<center>

![mark](http://images.iterate.site/blog/image/20190930/mpcYDF1zbFFR.png?imageslim)

</center>

> CornerNet框架

作者的思路其实来源于一篇多人姿态估计的论文[1]。基于CNN的2D多人姿态估计方法，通常有2个思路（Bottom-Up Approaches和Top-Down Approaches）：

（1）Top-Down framework，就是先进行行人检测，得到边界框，然后在每一个边界框中检测人体关键点，连接成每个人的姿态，缺点是受人体检测框影响较大，代表算法有RMPE。

（2）Bottom-Up framework，就是先对整个图片进行每个人体关键点部件的检测，再将检测到的人体部位拼接成每个人的姿态，缺点就是可能将，代表方法就是openpose。

论文的第一个创新是讲目标检测上升到方法论，基于多人姿态估计的Bottom-Up思想，首先同时预测定位框的顶点对（左上角和右下角）热点图和embedding vector，根据embedding vector对顶点进行分组。

论文第二个创新是提出了corner pooling用于定位顶点。自然界的大部分目标是没有边界框也不会有矩形的顶点，依top-left corner pooling 为例，对每个channel，分别提取特征图的水平和垂直方向的最大值，然后求和。



<center>

![mark](http://images.iterate.site/blog/image/20190930/eSCOuMo6nr3S.png?imageslim)

</center>



图 3 corner pooling计算方式

论文认为corner pooling之所以有效，是因为（1）目标定位框的中心难以确定，和边界框的4条边相关，但是每个顶点只与边界框的两条边相关，所以corner 更容易提取。（2）顶点更有效提供离散的边界空间，实用O(wh)顶点可以表示O(w2h2) anchor boxes。

论文的第三个创新是模型基于hourglass架构，使用focal loss[5]的变体训练神经网络。

论文提出的CornerNet在MS COCO测试验证，达到42.1% AP，完胜所有的one-stage目标检测方法，同时在git公布基于PyTorch源码：

https://github.com/umich-vl/CornerNet

## Architecture

## Overview



<center>

![mark](http://images.iterate.site/blog/image/20190930/6iupWqIlT0sn.png?imageslim)

</center>



> 图 4 CornerNet模型架构

如图 4所示，CornerNet模型架构包含三部分，Hourglass[7] Network,Bottom-right corners&Top-left Corners Heatmaps和Prediction Module。

Hourglass Network是人体姿态估计的典型架构，论文堆叠两个Hourglass Network生成Top-left和Bottom-right corners，每一个corners都包括corners Pooling，以及对应的Heatmaps, Embeddings vector和offsets。embedding vector使相同目标的两个顶点（左上角和右下角）距离最短， offsets用于调整生成更加紧密的边界定位框。

## Detecting Corners

论文模型生成的heatmaps包含C channels（C是目标的类别，没有background channel），每个channel是二进制掩膜，表示相应类别的顶点位置。

对于每个顶点，只有一个ground-truth，其他位置都是负样本。在训练过程，模型减少负样本，在每个ground-truth顶点设定半径r区域内都是正样本，这是因为落在半径r区域内的顶点依然可以生成有效的边界定位框，论文中设置IoU=0.7。

$p_{cij}$表示类别为$c$，坐标是$(i,j)$的预测热点图，$y_{cij}$表示相应位置的ground-truth，论文提出变体Focal loss表示检测目标的损失函数：

$$
L_{d e t}=\frac{-1}{N} \sum_{c=1}^{C} \sum_{i=1}^{H} \sum_{j=1}^{W}\left\{\begin{array}{l}{\left(1-p_{c i j}\right)^{\alpha} \log \left(p_{c i j}\right)} \;\; \text{if} \;y_{cij}=1\\ {\left(1-y_{c i j}\right)^{\beta}\left(p_{c i j}\right)^{\alpha} \log \left(1-p_{c i j}\right) \text { otherwise }}\end{array}\right.
$$


由于下采样，模型生成的热点图相比输入图像分辨率低。论文提出偏移的损失函数，用于微调corner和ground-truth偏移。


$$
L_{o f f}=\frac{1}{N} \sum_{k=1}^{N} \operatorname{SmoothL} 1 \operatorname{Loss}\left(\boldsymbol{o}_{k}, \hat{\boldsymbol{o}}_{k}\right)
$$

## Grouping Corners

输入图像会有多个目标，相应生成多个目标的左上角和右下角顶点。对顶点进行分组，论文引入 Associative Embedding的思想，模型在训练阶段为每个corner预测相应的embedding vector，通过embedding vector使同一目标的顶点对距离最短，既模型可以通过embedding vector为每个顶点分组。

模型训练Lpull损失函数使同一目标的顶点进行分组， Lpush损失函数用于分离不同目标的顶点。



$$
L_{p u l l}=\frac{1}{N} \sum_{k=1}^{N}\left[\left(e_{t_{k}}-e_{k}\right)^{2}+\left(e_{b_{k}}-e_{k}\right)^{2}\right]
$$

$$
L_{p u s h}=\frac{1}{N(N-1)} \sum_{k=1}^{N} \sum_{j=1 \atop j \neq k}^{N} \max \left(0, \Delta-\left|e_{k}-e_{j}\right|\right)
$$

## Hourglass Network

Hourglass Network同时包含了bottom-up（from high resolutions to low resolutions)和top-down (from low resolutions to high resolutions)。而且，整个网络有多个bottom-up和top-down过程。这样设计的目的是在各个尺度下抓取信息。针对目标检测任务，论文调整了Hourglass一些策略。





## Experiments

论文的训练损失函数包含了第三部分介绍的4个损失函数，$\alpha$, $\beta$ 和 $\gamma$ 用于调整相应损失函数的权重：



$$
L=L_{d e t}+\alpha L_{p u l l}+\beta L_{p u s h}+\gamma L_{o f f}
$$


模型训练过程中使用10个Titan X (PASCAL) GPUs，详细的训练参数可参考原论文。模型的推断时间是244ms/ image (Titan X PASCAL GPU)。

CornerNet相比其它one-stage目标检测算法，MS COCO数据集测试AP有明显提高，虽然性能接近于Two-stage检测算法，但是推断时间无明显优势。



![img](https://pic3.zhimg.com/80/v2-ead1454dcd573b3270df00661a205d8e_hd.jpg)



Table 4 MS COCO test-dev数据集性能对比

## Discussion

个人观点：CornerNet创新来自于多人姿态估计的Bottom-Up思路，预测corner的heatmps,根据Embeddings vector对corner进行分组，其主干网络也来自于姿态估计的Hourglass Network。模型的源码在github已经公布，可以放心大胆的研究测试。

CV的很多任务之间是相通的，CVPR2018 best paper [8]也印证这一观点，在不同的子领域寻找相似性，迁移不同领域的算法，是CV行业一个趋势。

多人姿态估计的Hourglass Network算法也不断改进中，其实论文模型的推断速率受限于Hourglass Network的特征提取，有志青年也可以沿着这个思路取得更好的性能。

# 相关

- [CornerNet：目标检测算法新思路](https://zhuanlan.zhihu.com/p/41825737?utm_source=ZHShareTargetIDMore&utm_medium=social&utm_oi=56829493116928)
