---
title: 2.16 RefineNet
toc: true
date: 2019-09-01
---

**7.RefineNet**

使用 CNN 最后一层的特性可以生成 soft 对象段的边界。在 DeepLab 算法中避免了这个问题深黑色的卷曲。RefineNet采用了另一种方法通过细化中间激活映射并分层地将其连接到结合多尺度激活，同时防止锐度损失。网络由独立的 RefineNet 模块组成，每个模块对应于 ResNet。每个 RefineNet 模块由三个主要模块组成，即:剩余卷积单元(RCU)，多分辨率融合(MRF)和链剩余池(CRP)。RCU块由一个自适应块组成卷积集，微调预训练的 ResNet 权重对于分割问题。MRF层融合不同的激活物使用卷积和上采样层来创建更高的分辨率地图。最后，在 CRP 层池中使用多种大小的内核用于从较大的图像区域捕获背景上下文。RefineNet在 Person-Part数据集上进行了测试 68.6，与 DeepLab-v2的 64.9相比，两者都使用了 ResNet-101作为特征提取器。

![img](https://pic3.zhimg.com/80/v2-b03c776a72697ea67cde09f23b99fe56_hd.jpg)







## 9.6 RefineNet


网络结构：

RefineNet block 的作用就是把不同 resolution level的 feature map进行融合。网络结构如下：<span style="color:red;">什么是 resolution level？怎么进行融合的？</span>

<center>

![](http://images.iterate.site/blog/image/20190722/TUon18avobcH.png?imageslim){ width=65% }

</center>


最左边一栏就是 FCN 的 encoder 部分(文中是用的 ResNet)，先把 pretrained ResNet 按 feature map 的分辨率分成四个 ResNet blocks，然后向右把四个 blocks 分别作为 4 个 path 通过 RefineNet block 进行融合 refine，最后得到一个 refined feature map(接 softmax 再双线性插值输出)。<span style="color:red;">怎么进行 refine 的？</span>

注意除了 RefineNet-4，所有的 RefineNet block 都是二输入的，用于融合不同 level 做 refine，而单输入的 RefineNet-4 可以看作是先对 ResNet 的一个 task adaptation。<span style="color:red;">什么 task adaptation ？</span>


**RefineNet Block**

接下来仔细看一下 RefineNet block，可以看到主要组成部分是

- Residual convolution unit
- Multi-resolution fusion
- Chained residual pooling
- Output convolutions。

<span style="color:red;">这些分别是什么？是怎么实现的？起到什么作用？</span>

切记这个 block 作用是融合多个 level 的 feature map 输出单个 level 的 feature map，但具体的实现应该是和输入个数、shape无关的。

<center>

![](http://images.iterate.site/blog/image/20190722/8dWvUzuf0orc.png?imageslim){ width=85% }

</center>

简单介绍如下：

- Residual convolution unit 就是普通的去除了 BN 的 residual unit；<span style="color:red;">为什么去除 BN？</span>
- Multi-resolution fusion 是先对多输入的 feature map 都用一个卷积层进行 adaptation(都化到最小的 feature map的 shape)，再上采样再做 element-wise 的相加。注意如果是像 RefineNet-4那样的单输入 block 这一部分就直接 pass 了；<span style="color:red;">嗯。</span>
- Chained residual pooling 中的 ReLU 对接下来池化的有效性很重要，还可以使模型对学习率的变化没这么敏感。这个链式结构能从很大范围区域上获取背景 context。另外，这个结构中大量使用了 identity mapping 这样的连接，无论长距离或者短距离的，这样的结构允许梯度从一个 block 直接向其他任一 block 传播。<span style="color:red;">没明白这个。</span>
- Output convolutions 就是输出前再加一个 RCU。<span style="color:red;">什么是 RCU？</span>


<span style="color:red;">没有很理解，而且，之前介绍的 dilated conv 好像没有使用。</span>





# 相关

- [2019年最新基于深度学习的语义分割技术讲解](https://zhuanlan.zhihu.com/p/76418243)
