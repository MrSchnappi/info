---
title: 3.12 图像级别标记
toc: true
date: 2019-09-04
---

### 9.10.2 图像级别标记


论文地址：[Constrained Convolutional Neural Networks for Weakly Supervised Segmentation （ICCV 2015）](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Pathak_Constrained_Convolutional_Neural_ICCV_2015_paper.pdf)

UC Berkeley的 Deepak Pathak使用了一个具有图像级别标记的训练数据来做弱监督学习。训练数据中只给出图像中包含某种物体，但是没有其位置信息和所包含的像素信息。该文章的方法将 image tags转化为对 CNN 输出的 label 分布的限制条件，因此称为 Constrained convolutional neural network (CCNN).

<center>

![](http://images.iterate.site/blog/image/20190722/JtkbrkVP9SH3.png?imageslim){ width=55% }

</center>



该方法把训练过程看作是有线性限制条件的最优化过程：

$$
\underset{\theta ,P}{minimize}\qquad D(P(X)||Q(X|\theta ))\\
subject\to\qquad A\overrightarrow{P} \geqslant \overrightarrow{b},\sum_{X}^{ }P(X)=1
$$


其中的线性限制条件来自于训练数据上的标记，例如一幅图像中前景类别像素个数期望值的上界或者下界（物体大小）、某个类别的像素个数在某图像中为 0，或者至少为 1 等。该目标函数可以转化为为一个 loss function，然后通过 SGD 进行训练。

<center>

![](http://images.iterate.site/blog/image/20190722/WuPIWS0t3RPj.png?imageslim){ width=55% }

</center>


实验中发现单纯使用 Image tags 作为限制条件得到的分割结果还比较差，在 PASCAL VOC 2012 test数据集上得到的 mIoU 为 35.6%，加上物体大小的限制条件后能达到 45.1%，如果再使用 bounding box做限制，可以达到 54%。FCN-8s可以达到 62.2%，可见弱监督学习要取得好的结果还是比较难。
