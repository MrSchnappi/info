---
title: 7.01 面向自动驾驶场景的 3D 视觉
toc: true
date: 2019-09-04
---
# 面向自动驾驶场景的 3D 视觉

代表性论文：PointRCNN: 基于原始点云的 3D 物体检测方法

![mark](http://images.iterate.site/blog/image/20190903/lFjmoYSNL07b.png?imageslim)


本文首次提出了基于原始点云数据的二阶段 3D 物体检测框架，PointRCNN。3D物体检测是自动驾驶和机器人领域的重要研究方向，已有的 3D 物体检测方法往往将点云数据投影到鸟瞰图上再使用 2D 检测方法去回归 3D 检测框，或者从 2D 图像上产生 2D 检测框后再去切割对应的局部点云去回归 3D 检测框。而这些方法中，前者在将点云投影到俯视图上时丢失了部分原始点云的信息，后者很难处理 2D 图像中被严重遮挡的物体。

我们观察到自动驾驶场景中物体在 3D 空间中是自然分离的，从而我们可以直接从 3D 框的标注信息中得到点云的语义分割标注。因此本文提出了以自底向上的方式直接从原始点云数据中同步进行前景点分割和 3D 初始框生成的网络结构，即从每个前景点去生成一个对应的 3D 初始框（阶段一），从而避免了在 3D 空间中放置大量候选框。

在阶段二中，前面生成的 3D 初始框将通过平移和旋转从而规则化到统一坐标系下，并通过点云池化等操作后得到每个初始框的全局语义特征和局部几何特征，我们将这两种特征融合后进行了 3D 框的修正和置信度的打分，从而获得最终的 3D 检测框。

在提交到 KITTI 的 3D 检测任务上进行官方测试时，我们提出的方法在只使用点云数据的情况下召回率和最终的检测准确率均超越了已有的方法并达到了先进水平。目前我们已将该方法的代码开源到了 GitHub 上。
