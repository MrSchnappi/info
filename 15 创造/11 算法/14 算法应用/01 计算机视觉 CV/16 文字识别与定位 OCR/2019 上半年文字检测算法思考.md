---
title: 2019 上半年文字检测算法思考
toc: true
date: 2019-09-15
---
作者： 我不是那样的烟火

https://zhuanlan.zhihu.com/p/78844538

本文已由作者授权，未经允许，不得二次转载

上半年的文字检测算法还是集中于 one-stage和 two-stage。one-stage的算法主要利用 FPN 的结构预测分割图以及其他辅助的标签，如回归的值等得到文本的区域；two-stage的算法主要利用 mask-rcnn辅助一些改进提升文字检测算法的性能。这篇文章我们就主要说一说这半年的文字检测算法到底在改进什么。

### one-stage算法

这类算法多为基于 unet 分割的优势，将文本检测任务转换为文本区域分割的问题，同时利用分割时像素的位置信息，预测一些相关定位的信息，最后将信息整合，得到最终的文本区域。

上半年里 one-stage的文字检测算法代表，CRAFT和 PSENet。两者网络结构如下：

![img](https://ask.qcloudimg.com/http-save/yehe-1638669/de6xqxmzap.jpeg?imageView2/2/w/1620)

CRAFT

![img](https://ask.qcloudimg.com/http-save/yehe-1638669/qhxedmis8i.jpeg?imageView2/2/w/1620)

PSENet

两种算法可以认为是两条路线：

1. 在分割的基础上，像素不仅仅预测类别，同时预测与位置相关的信息。
2. 利用像素的分割信息寻找文本实例。

这里分别对这两种类型进行分析。首先是第一种类型的检测算法。这类型类似 anchor free的算法，在模型的最后一层输出像素的分类信息以及回归信息。EAST、AdvancedEAST以及一些类 EAST 的算法，都是如此的做法。但是 EAST 等直接预测一个文本实例的方法容易受特征的局限，进而导致最终长距离无法稳定预测。于是后来目光逐渐转向 slices+grouping的思路。pixellink，textfield， textmoutain等。这类型算法因为只需要关注局部相关的信息就可以很好的得到文本实例，缺点是如果局部信息获取不好，检测会出现 badcases。但是这类算法在榜上都刷到了不错的性能，但是一旦把回归方式改为预测整个文本实例的位置信息，性能就会下降。为什么？

原因在于仅仅凭借 unet 的最后一层输出，去预测文本的各种尺度大小，是没有这样的特征的。如 stride=4的 feature，经过 conv3x3 或许可以 cover 住 12x12 的范围，但是这时候用这些特征如预测 512x128 的文本实例，是会出现问题的。因此，大家换做局部 slices+grouping的做法，尽可能的让单层特征预测尺度变化不大的目标，然后利用 grouping 得到最终的文本实例。

结合分割与像素回归的方法，边界会相对稳定，因为其边界多为很多像素投票或者加权的结果。也因为如此，直接回归文本实例的方法，无法很好的精准定位长文本的边界。

对于第二种算法，则需要借助网络超强的分割能力，尽可能精准的将文本区域分割出来，接着利用像素之间的一些关系，得到文本实例。这类型算法依赖很强的特征提取能力，需要提取到可以很好的判别文本像素归属的特征，因此依赖 unet 的结构，如结合多尺度信息融合的手段增强特征，分割文本。但是由于文本区域中是包含背景噪声的，因此当文本包含背景噪声较多时，如镂空、较大的字体、较大的间隔等，容易导致检测的失败。

以上是对 one-stage方法的简单分析，one-stage算法需要面对的是类别不均衡、特征 misalignment 等问题，当然与文本标签中存在部分噪声有关系。

### Two-stage算法

two-stage算法的典型代表便是基于 maskrcnn 的改进，这里拿如下两种算法进行分析：

![img](https://ask.qcloudimg.com/http-save/yehe-1638669/uj6eqpia8y.jpeg?imageView2/2/w/1620)

Box_Discretization_Network

![img](https://ask.qcloudimg.com/http-save/yehe-1638669/9y3jawegmn.jpeg?imageView2/2/w/1620)

PMTD

我们知道 MaskRCNN 的回归方式为，roi_feature进行编码，预测类别，bbox以及分割图。但是由于文本的宽高比变化剧烈，长文本会无法 cover。因此以上两种算法对 maskrcnn 的结果进行微调。即去预测辅助定位的信息。BDN将 ROIAlign 得到的特征分别预测三种信息，分别为水平方向的响应值，竖直方向的响应值，以及 xy 的匹配方式。这里具体的方式可以阅读论文参看细节。为什么这么做管用？这里的分类的目标值为 bbox 定点与中心点的平均，如(xmin + xmean) / 2, 将四个顶点与中心点关联，同时这个预测值往往会落在 roi 范围内，避免了直接回归很远的位置，利用现有范围内的特征预测得到范围外的值。最终在得出检测结果是，进行 qbox 的校准。

对于 PMTD，则是将 mask 分支的分割标签改进，改为类似于高斯图的结构，这样做的目的是为了在检测得到文本区域之后，可以利用分割得到的值进行边界的推断，最终得到完整的文本区域。

### 一些想法

实际上 Maskrcnn 做文字检测可以达到一个很高的 baseline，如 PMTD 中说的 maskrcnn 在 icdar2017mlt 上可以到 76%以上，而回过头来看 one-stage算法在 mlt 上的性能，psenet性能为 72%左右，相当于 one-stage的极限。是什么原因导致了这样的结果？如果把 backbone 对齐的话，我们可以看到 maskrcnn 相比较 psenet 等算法多做了 RPN，ROIAlign，Instance-Segmentation，这些部件的作用可以如下类比，RPN相当于 one-stage中的直接回归，ROIAlign特征对齐，Instance-Segmentation是类别均衡的分割。对比之下，可以看出以下几点：

- 特征对齐对于直接回归的重要性，假设 EAST 中每个像素与整个文本实例相关，那么可以很好的定位边界。
- 特定感受野的特征回归特定的范围，如果类 EAST 算法更改回归方式，可以很好的避免回归目标与特征不匹配的问题。

以上只是对比 one-stage与 two-stage，而对于 maskrcnn 来说，依旧存在对于宽高比剧烈的文本无法检测完整，原因在于此类文本经过 ROIAlign 得到的特征，往往只是局部信息，因此无法很好的回归整个文本实例。那么 maskrcnn 应该如何改进呢？我觉得还是特征对齐～



# 相关

- [2019 上半年文字检测算法思考](https://cloud.tencent.com/developer/article/1492081)
