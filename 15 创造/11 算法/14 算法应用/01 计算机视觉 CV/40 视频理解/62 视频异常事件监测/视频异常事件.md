---
title: 视频异常事件
toc: true
date: 2019-11-17
---
# 如何检测视频异常事件？阿里工程师提出全新检测模型


论文收录：ACM MM 2017


论文中我们为城市大脑提供监控交通异常的方法。受动作识别等领域的最新研究成果启发，设计了一种时空自编码进行视频异常检测，同时提出一种权重递减的预测误差计算方法。经真实的交通场景评测，该算法在重要指标上已经超过了此前的最好方法。

## **摘要**

真实世界视频场景中的异常事件检测是一个高难度的问题，因为“异常”本身很复杂而且场景中还存在杂乱的背景、物体和运动。大多数已有的方法都是在局部空间区域中使用人工设计的特征来识别异常。

在本论文中，我们提出了一种称为时空自编码器（Spatio-Temporal AutoEncoder，简称 ST AutoEncoder 或 STAE）的全新模型，使用深度神经网络来自动学习视频表征以及通过执行三维卷积来从空间维度和时间维度提取特征。

在经典的自编码器中所使用的重建损失之外，我们为未来帧的生成引入了一种权重递减型预测损失，这能够增强视频中的运动特征学习。因为大多数异常检测数据集都局限于外观异常或不自然的运动异常，所以我们收集了一个新的高难度数据集，该数据集是由真实世界的交通监控视频构成的。我们在公开数据集和我们的交通数据集上进行了多项实验，结果表明我们提出的方法的表现显著优于之前最佳的方法。

## **1 引言**

自动检测视频流中的异常事件是智能视频监控系统面临的一大基本难题，并且已经在过去几年中受到了学术界和工业界的高度关注。

不同于动作识别和事件检测等监督式视频分析问题，视频异常检测主要面临着两大难题：一是正例样本和负例样本之间的数据不平衡（即作为正例样本的异常事件的数量远远少于常规事件）；二是正例样本内部存在很大的差异性（异常事件可能包含很多不同的情况，但一般而言可用的训练数据却很有限）。

由于正例样本的稀疏性，经典的监督式事件检测和识别算法无法应用于这个任务。这个问题的通常解决方式是使用无监督方法训练一个表征正常视频序列中的模型，然后将异常值（模型的外点）看作是异常事件。

鉴于训练数据通常只包含普通视频，所以学习常规活动的特征表征是一个无监督学习问题。之前的一部分异常检测研究侧重于建模局部 2D 图像图块或 3D 视频立方体的时空事件模式，这个过程中会用到从低层面外观和运动中提取的人工设计的特征，比如方向梯度直方图（HOG）、光流直方图（HOF）、3D 时空梯度等。但是，由于人工设计的特征的表征能力有限，这一类之前的方法并不适合用来分析复杂的视频监控场景。

深度学习方法已经展现出了在特征学习方面的优势，而且研究已经证明其可以非常有效地解决鉴别式视觉任务。基于自编码器网络的无监督深度学习方法也已被提出用作解决视频异常检测问题的又一类方法。但是，这些方法只依赖于全连接的自编码器或 2D 卷积自编码器，而没有利用来自时间维度的特征，因此无法获取异常事件的时间线索，而这对于识别视频事件异常而言是至关重要的。

受 3D 卷积网络在视频分析中的优越表现的启发，我们提出了用于视频异常检测的时空（ST）自编码器：通过在编码器中应用 3D 卷积和在解码器中应用 3D 反卷积，能够增强模型从时间维度中提取运动模式的能力。

除了经典的自编码器所使用的重建损失，我们还引入了一种权重递减型预测损失来预测未来帧，这可以引导模型获取运动目标的轨迹以及增强编码器以更好地提取时间特征。经过在正常视频数据上的训练之后，该自编码器应该能够以较低误差重建出常规视频片段，而在重建非常规视频片段时则会出现高误差。然后模型再根据这个误差计算视频序列中每一帧的规律性分数（regularity score），然后再将其用于确定异常事件，如图 1 所示。

![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWiclveB6N2C7I8JJGcMaWKbyT0Ne7blLC6QPic6jXJoYOl6ic8o7kRcGEKA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 1：来自 CUHK Avenue 数据集的一段视频序列的规律性分数。红色区域表示基本真值异常帧。规律性分数会在异常事件发生时下降。



大多数真实世界情形中的异常事件都非常复杂，而大多数当前的异常检测数据集都只包含外观异常或人为制造的运动异常。为了评估我们提出的方法的实用性，我们收集了一个新的高难度数据集，其由真实世界交通监控视频构成。实验表明我们的模型可以应用于这一复杂应用。



本论文的主要贡献总结如下：



- 我们提出了一种全新的时空自编码器深度网络，可以通过执行 3D 卷积同时根据空间维度和时间维度来建模常规视频数据。据我们所知，这是首个基于 3D 卷积的视频异常检测模型。
- 我们在模型训练中引入了一个权重递减型预测损失，这能提升检测异常事件的表现。
- 我们收集了一个新的由真实世界交通监控视频构成的异常检测数据集，并且表明我们的方法的表现在公共基准和我们的 Traffic 数据集上都优于之前最佳的方法。

##

## **2 我们的方法**



为了具体描述，我们首先简要介绍一下 3D 卷积，然后再详细讨论我们提出的模型。

###

### 2.1  3D 卷积



典型的 2D 卷积网络是在 2D 特征图上应用卷积来提取空间维度的特征。2D 卷积网络在图像识别方面表现优越，但它们却无法获取用于视频分析问题的连续帧中所编码的时间信息。Ji 等人[1] 提出执行 3D 卷积来同时计算来自时间维度和空间维度的特征，具体做法是将一个 3D 核卷积到通过连接时间维度中的多个连续帧而形成的立方体上。

###

### 2.2  3D 卷积自编码器



**输入数据。**在大多数用于图像识别的典型 CNN 中，输入数据都是具有 3 个通道（比如 R、G、B 颜色通道）的单张图像。而在异常检测网络中，输入数据是一段包含多帧的视频片段。Hasan等人 [2] 通过使用滑动窗口（滑动窗口的长度为 T）的时间立方体来构建输入。但其中的时间特征很少得到保留。为了解决这个问题，我们以超立方体的形式构建输入——通过在第 4 维（通常被称为时间维）上堆叠 T 帧，然后再在其上执行 3D 卷积。



**数据增强。**通过在从视频序列中采样的片段上应用多种变换（随机裁剪、亮度变化和高斯模糊），我们可以生成更多输入超立方体。在我们的方法中，我们使用恒定步幅来采样帧，这样目标的运动速度保持不变。



**网络架构。**图 3 给出了我们提出的时空自编码器网络示意图。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWicibibDcJhBuKKfRQibLxH9V0SROchFYkaY09L08Sib6adCzCRLiaT3BANruw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 3：网络的架构。在编码器之后有两个分支的解码器，分别用于重建过去的帧和预测未来的帧。



### 2.3 权重递减型预测损失



之前已有研究证明预测网络有助于学习视频表征，受这些研究的启发，我们在解码器部分设计了一个预测分支来预测输入视频片段之后的未来 T 帧。具体来说，重建分支和预测分支具有相同的隐藏特征层，但执行的是不同的任务，分别是：重建过去的序列和预测未来的序列。其中预测任务可以引导模型获取运动目标的轨迹以及让编码器更好地提取时间特征。



在大多数视频异常检测场景中，视点是固定的，各种目标进进出出。新目标的出现难以预测，从而会影响预测网络在训练阶段的收敛性。我们应用了预测损失来增强模型的能力，以提取已有目标的运动特征和预测它们在未来近期的运动，而不会预测相对遥远的未来的新目标的出现。新目标出现的概率会随时间推移逐渐增大，因此我们在预测得到的视频片段的每一帧上施加了一个递减的权重。



### 2.4 规律性分数



由常规事件组成的视频序列有更高的规律性分数，因为它们接近于特征空间中的正常训练数据。相反，异常序列的规律性分数更低，因此可以被用于定位异常事件。

##

## **3 实验**

###

### 3.1 数据集



我们在三个数据集上评估了我们提出的时空自编码器，其中包含 UCSD Pedestrian 和 CUHK Avenue 这两个已有的数据集，另外还有新收集的 Traffic 数据集。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWicibGoib2IUmIgDvHSUXZdGibDQ5wRIznBHXgSVw8ryDL5lQOiaFOlHqwfHQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

表 1：异常检测数据集比较。Nor 表示正常帧，Abn 表示异常帧。



### 3.2 异常的可视化



当我们训练完模型之后，规律性分数可以根据重建误差计算得出。由正常事件组成的视频序列有更低的误差，而异常序列有更高的误差。重建误差是根据每一帧中的每个像素计算得出的，这让我们可以将误差分解到每一帧以及定位图片中的异常区域。



图 4 给出了 5 组来自不同数据集的示例。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWic5q2B2gEHgA82rEWjlA65xvXjP58m9ic2hnvGDAAib8giaxVTicKcSxd8iaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 4：异常的可视化。左列：来自不规则视频片段的帧。中列：我们的模型的重建输出。右列：重建误差图。橙色矩形突出强调了误差图中的异常区域。在前三个场景中都只有单个目标存在异常，后两个场景则与多个目标有关。

###

### 3.3 异常事件检测



基于重建误差可以计算得到规律性分数，而规律性分数又可被进一步用于检测异常事件。如图 5 所示，视频片段的规律性分数会在异常发生时下降。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWicFiaHQmMzePGXU5DWx6G3ejW3XdEY8Ijaa4thqHpCWGpg6x11PR6TaSQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 5：来自三个数据集的四段测试视频片段的规律性分数曲线。红色区域表示基本真值异常帧。结果表明规律性分数会在异常发生时下降。每个场景都给出了几帧采样，用以展示常规/非常规事件。



表 2 给出了我们的方法与几种当前最佳方法在 UCSD Pedestrian 和 CUHK Avenue 数据集上的表现比较。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWicQk1picKv4MiawF0ebg6LQwbmiah7ZETn979HuhTuylNENUyLVm7ZF14iaA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

表 2：在 UCSD Pedestrian 和 CUHK Avenue 数据集上的比较



结果还表明我们的时空自编码器模型可用于不同类型的输入数据。



我们还在新收集的 Traffic 数据集上进行了同样的评估。我们将 ConvAE[2] 设为当前最佳方法，因为它有一定的揭示时间特征的能力。表 3 给出了 5 种场景的结果，另外也报告了平均结果。所有被测模型的输入都是灰度帧。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWic6ukeiaiaCAPwgc9NZRibDhRia3ooUz2dd2dLHkdZoNQoqk172QzggoOYGg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

表 3：在 Traffic 数据集上的比较

###

### 3.4 预测未来帧



如前所述，我们在时空自编码器网络中设计了一个预测分支，以通过跟踪视频序列中运动目标的轨迹来增强视频表征学习的能力。



图 6 给出了两个示例。我们的 STAE 模型可以重建输入的规则视频片段，也能预测未来帧。运动中的车辆（用绿框标出）的轨迹在未来帧中被很好地预测了出来。我们还给出了有新车辆（用红框标出）进入该场景的示例，这表明我们的模型无法预测新出现的目标。



![img](https://mmbiz.qpic.cn/mmbiz_png/LwZPmXjm4WyVsd5w0045bDuBTROBRpWicx7T7e6AtvFtXoPicNzJuQZZd8gPLo1Zo4RtIBTokkqFiaO4L4psQ9zlQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 6：在 Traffic 数据集上的两组帧预测示例。每一组的上一行都是基本真值视频序列，下一行则是我们的网络重建和预测的输出。左侧部分是从 T 个输入帧中采样的，右侧部分是从未来片段中采样的。运动汽车用绿框标出，新进入场景的汽车用红框标出。



## **4 结论**



未来的研究方向包括研究其它网络架构，融合多模态输入数据（比如 RGB 帧和光流），在实例层面而非像素层面评估规律性分数，以及将我们的框架应用于更复杂的场景。



参考内容：

[1]Shuiwang Ji, Wei Xu, Ming Yang, and Kai Yu. 2013. 3D convolutional neural networks for human action recognition. IEEE transactions on pattern analysis and machine intelligence 35, 1 (2013), 221–231.

[2]Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K Roy-Chowdhury,and Larry S Davis. 2016. Learning temporal regularity in video sequences. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.733–742.


# 相关

- [如何检测视频异常事件？阿里工程师提出全新检测模型](https://mp.weixin.qq.com/s?__biz=MzU5ODUxNzEyNA==&mid=2247483869&idx=1&sn=f774e0cabaaba58be1186094362cee4c&chksm=fe43b536c9343c206ba625374969d4b738af419a095ae19448d8d0fbfe4303fe918cf0477bc5&mpshare=1&scene=1&srcid=0801LPXU6dlBqVHLfE8U7JAe#rd)
