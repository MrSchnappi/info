---
title: 01 距离和度量学习
toc: true
date: 2018-08-29
---
##### 第 12 章度量学习


第 12 章介绍了度量学习的基本概念，并从图片开始，一步步实现了基于 Caffe 的 Siamese 网络，还实现了基于 t-SNE的结果可视化。



本章介绍度量学习(Metric Learning)的基本概念，并通过 MNIST 训练 Siamese 网络 的例子来加深理解。

12.1距离和度量学习

在机器学习中，有一类算法如 K 近邻/K-means、SVM、相似比对/搜索相关的算法等， 非常依赖距离这个度量来对数据执行分类/聚类/搜索等任务。所以有一个方向专门研究如 何让一个算法更好地学习到一种度量，比如欧式距离，提升特定任务的算法性能，这就是 度量学习。

12.1.1欧氏距离和马氏距离

本节首先来考虑图 12-1所示的例子。

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-303.jpg)

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-304.jpg)

图 12-1中左下角是在二维空间中由一个分布产生的方块样本，这个分布的一条等高线 如虚线的椭圆框所示。图 12-1中还有一个不属于该分布的圆圈样本，在做聚类一类的任务 时，通常会用欧式距离判断是否属于同一类，如果对于本例用欧式(Euclidean)距离则会 出现问题。如图 12-1左上角图所示，从方块分布中抽出中央和右上角边缘的两个样本，和 圆圈样本单独画出来，可以看到圆圈样本更加靠近方块样本的中心，而那个离得远的方块 样本到中心样本的欧氏距离反而更远，这是因为产生样本的分布本身形状导致的。这种情 况下，马氏(Mahalanobis)距离则是更加合适的一种度量。马氏距离是由印度统计学家 Mahalanobis提出的一种用于表示数据的协方差距离的度量，定义如下：

###### dM    (公式 12-1)

其中 X, 分别是两个空间中的坐标，z是产生方块的分布的协方差矩阵。在这种距离 的度量下，方块分布的等高线到分布中心的距离都是相等的，如图 12-1右上角图所示。在 第 2 章讨论 PCA 的时候已经讲过，协方差矩阵包含着方差在不同轴上投影的信息，所以如 果把马氏距离看作是如下的形式的话：

dM {x,y) = yj(x- y)AAJ (x - y) = \A7x - A7y\    (公式 12-2)

其中 dT=£Tt/T，对角矩阵的对角线分别为协方差矩阵本征值的倒数开方，t/T的行 向量就是协方差矩阵的本征向量。通过对原来的样本进行变换，就得到图 12-1右下角 图，对于方块的分布而言，计算马氏距离就等效于在变换后的空间里计算欧式距离。

通过前面的讨论知道了马氏距离就是对一个可以用协方差矩阵描述的分布，计算等效 距离的一种方式，不过对于很多机器学习任务，得到描述某一类样本的分布的协方差矩阵 往往意义不大，或是有时候样本数量相对于维度都不足以得到一个有效的协方差矩阵。所 以在机器学习中，马氏距离的意义可以拓展一下，如果用：

d(x,y) = yj(x-y)M(x-y)    (公式 12-3)

来表示想要最终使用的度量，其中 M 可以是任意满足条件的半正定矩阵，那么如何找到一 个合适的 Af 就是最早的度量学习关心的问题。

12.1.2欧式距离和余弦距离

除了马氏距离，第 2 章中讲过用来计算相似性的余弦距离也是一种常用的度量方式， 如图 12-2所示的样本。



a)    b)    c)

如图 12-2a所示，两种样本在距离上展现出的区分度并不特别明显。但在以原点为中 心和坐标轴成的角度来看，区分反而显得更清晰，这种情况就可以考虑用余弦距离。第 2 章讲过计算余弦距离的公式，通过公式可以知道，余弦距离其实本质上还是在计算角度之 间的差，因为直接计算余弦距离的运算量并不小，所以更常用的一种计算方式是用归一化 之后的坐标(或者特征)相减，降低计算量，公式如下：

=    (公式 12-4)

形象的理解如图 12-2b和 12-2c所示，假设图 12-2b中的虚线圆弧是单位圆所在，那么 归一化就相当于把每个样本沿着半径投影到单位圆上，投影后的样本就是空心的方框和小 圆圈，如图 12-2c所示。投影之后再计算欧式距离，这个距离就等于距离和半径比值。因 为单位圆半径是 1，当两个样本距离较近时，这个值可以很好地近似样本的夹角，当两个 样本距离远时，虽不能很好近似，但也能大致反映出夹角大小。

12.1.3非线性度量学习和 Siamese 网络

12.1.1中计算马氏距离相当于是线性变换，不少很有代表性度量学习的方法都是基于 线性变换去做的，比如 Large Margin Nearest Neighbor, Information Theoretic Metric Learning 等。线性变换的优点是学习出来的 metric 不容易过拟合，求解很快，泛化性也相对好一些。 但是缺点也很明显，拟合能力往往不够，对输入样本特征的可分性要求也高。

在 12.1.2节中计算余弦距离就已经不是线性变换了。所以广义来看，度量学习要解决 的就是找到一种好的度量方式，不管是非线性还是线性的。对于非线性的情况，概括为公 式如下：

^(^J)= |/(^)-/(J)|    (公式 12-5)

其中/是非线性变换。既然可以有非线性变换，那么神经网络当然也是一个选项。考 虑一个卷积神经网络用戶 G(x)表示对输入进行的非线性变换。对于来自于同一类的样本， 让同类别的样本之间的距离经过 G 变换后距离更近，而不同类别之间的样本经过 G 变换后 距离更远。训练阶段可以考虑训练的时候每次都输入两个样本，用两个参数完全一样的网 络对这两个样本进行变换，最后设计一个 loss 函数来实现让相同样本对之间的距离更近， 不同样本对之间的距离更远，如图 12-3所示。



'    x2

第 12 章度量学习

这种网络结构被称为 Siamese Architecture，是 1993 年 LeCun 在贝尔实验室时和同事 合作发表的文章《Signature Verification using a ’’Siamese’’ Time Delay Neural Network》中提 出的结构。Siamese的名字源于著名的连体双胞胎恩（Eng）和昌（Chang）。19世纪的时 候，这对连体双胞胎兄弟因为跟随马戏团在全世界巡演而名噪一时，因为二人的出生地是 泰国的暹罗（Siam），所以被称为 Siamese Twins，后来 Siamese Twins就成了连体人的代 名词。2005年的时候 LeCun 用这种结构的卷积神经网络来训练人脸比对（Face Verification） 模型，获得了不错的结果，论文《Learning a Similarity Metric Discriminatively, with Application to Face Verification》发表在 CVPR 上，一举成为了用卷积神经网络做 Metric Learning的基础方法。

12.1.4 Contrastive Loss：对比损失函数

基于 LeCun 的工作，Caffe对 Siamese 训练提供了很好的支持，Caffe中内置了用于训 练 Siamese 网络的 Contrastive Loss层，这种 loss 的计算公式如下：

1 N    7

L（d,y） =-+（1 -y/）max（zwargz>2-t//,0）    （公式 12-6）

27V ,=i

其中#是每个 batch 的大小，y是标签，1代表相同样本，0代表不同样本，margin是 人为设定的一个值，是每对样本的欧式距离。

=\at-b\    （公式 12-7）

其中〃和分别是要比较距离的两个样本最后计算出来的特征（一个向量）。利用 Contrastive Loss层的时候，需要 3 个输入：两个输入分别是一对样本对应的特征 tz 和 6， 欧式距离在层内自动计算，另一个输入为是否相似的标签 JV。

根据 Contrastive Loss的定义，当两个样本一样的时候，y=\，优化的目标是让'尽量 小，是让相同样本尽量靠近；当两个样本不同时，y=0，是让 max（zzwrrgz>?-6/,0）2尽量小，也 就是 6/尽量大以接近让不同的样本尽量远离。

12.2 用 MNIST 训练 Siamese 网络

本节还是通过最简单的 MNIST 的例子，通过训练 Siamese 网络让相同数字变换后的距 离尽量靠近，不同数字变换后尽量远离。

12.2.1数据准备

Caffe中也有用 MNIST 训练 Siamese 的例子，不过和 MNIST 分类的例子一样，细节 全都隐藏在 c++和 shell 代码里了，所以本节从头开始，方便读者举一反三。

第一步当然是准备 MNIST 的数据，可以参考第 8 章，下载 MNIST 压缩包并生成图片， 然后在当前文件夹下建立一个指向 mnist 文件夹的链接：

» In -s /path/to/mnist mnist

第 2 篇实例精讲

Caffe官方的例子使用的 leveldb，本节中不打算介绍这种方式，而是用另一种思路， 利用之前用过的 lmdb 来实现 Siamese 训练。具体办法是：生成两个 lmdb，其中数据的顺 序一一对应，如果是相同数字，则标签为 1，否则标签为 0。对训练时用到的 pmtotxt 也做 相应修改，用两个 data layer分别读取两个数据，按照图 12-3所示的思路经过 CNN 之后 最后再计算转换后特征的距离。

在 Caffe 和其他一些流行框架如 Keras 中，产生样本方式就是随机配对，这种情况下, 假设每类数字的样本数量相等，均为〃，则相同样本的占比是：

10xC(«，2)    10x«(«-l)    10    1

C(10n,2) ~ 10n(10w-l) ~T00_l0

对于 n＞〉l的情况，近似就是 0.1，这个比例对于 MNIST 这样简单的数据效果还不错，

本节也用这个简单的策略进行训练。不过需要提一句的是，在做一些其他的训练的时候，

相同样本和不同样本的比例往往是经验值，需要一定的尝试。用来生成 MNIST 文件列表

的脚本如下：

import os import random import re

\#指定训练图片和验证图片的路径 train_dir = 'mnist/train1 val_dir = *mnist/val*

\#岳定样本对数目

n_train =    100000

n_val =    10000

从文件名中获取数字的正则表达式

pattern = re.compile(1\d+_(\d)\.jpg')

\#生成训练集和 b 证集列表的文件_

for img_dir, n_pairs in zip([train_dir, val_dir], [n_train, n_val]): #-列出所 w 的文件名 imglist = os.listdir(img_dir)

\#获得所有的样本数量

n_samples = len(imglist)

\#_数据集名称

dataset = img_dir[img_dir.rfind(os.sep)+1:]

\#同时打开两个文 r 牛分别写入应的文件列表

with open(1{}•txt'.format(dataset),    *w *) as f, \

open(1{}_p.txt'.format(dataset),    1 w*) as f_p:

\#按照指定的数目 i 机写入文件路径对 for i in range(n_pairs):

\#随机选取第 I 个文件

filename = imglist[random.randint(0, n_samples-l)] digit = pattern.findall(filename)[0] filepath = os.sep.join([img_dirz filename])

\#随机选取第二个文件

filename_p = imglist[random.randint(0, n_samples-l)] digit_p = pattern.findall(filename_p)[0] filepath_p = os.sep.join([img_dir, filename_p])

\#如果两不文件是同一个数字则标签为 f 否则标签为 0 label =    1 if digit == digit_p else 0

\#分别写入两个文件

f.write(1{}    {}\n *.format(filepath, label))

f_p.write(1{}    {}\n'.format(filepath_p, label))

执行脚本，得到 train.txt、train_p.txt、val.txt、val_p.txt这 4 个文件。然后像在第 8 章 中一样生成 4 个 lmdb：

»    /path/to/caffe/build/tools/convert_imageset . / train.txt train—

lmdb ——gray

\>> /path/to/caffe/build/tools/convert_imageset ./ train_p.txt train— p_lmdb ——gray

»    /path/to/caffe/build/tools/convert_imageset    . / val.txt val_lmdb

——gray

\>>    /path/to/caffe/buiId/tools/convert_imageset    . / va_l_p.txt val_p_

lmdb ——gray

因为文件对本身就是随机挑选的，再加上每行的文件和标签要一一对应，所以不能再 使用-shuffle这个选项。另外需要注意的是，因为两个 lmdb—一对应，所以在使用其他数 据的情况下，比如自己采集的人脸比对的数据，如果其中有任何文件图片是损坏的，贝 IJ 对 应的两个路径都不应该写到列表文件里，否则在生成 lmdb 的时候可能出现错位。

12.2.2参数共享训练

训练的 solver 就是/path/to/caffe/examples/siamese 下的 mnist_siamese_solver.prototxt, 只不过把网络结构文件指向我们自己定义的文件路径。网络结构定义和 Caffe 自带例子主 要的不同在 data layer，基础网络结构就是 LeNet-5，具体如下：

name:    *' mn i s t _ s i ame s e_ t r a i n_ t e s t"

\# 一共 4 个 data layer，分别是训练的一对样本和验证的一对样本 layer {

name: "mnist" type:    "Data"

top:    "data"

top: "label" include {

phase: TRAIN

}

transform_param { mean_value:    128

scale:    0.00390625

}

data_param {

source:    ntrain_lmdbn

batch_size:    64

backend: LMDB

}

}

layer {

name: nmnist_p" type: ’’Data” top: "data_p"

\# top: "label"可以省略，因为已经在 mnist 的 data layer中读取过了 include {

phase: TRAIN

}

transform_param { mean_value:    128

scale:    0.00390625

}

data_param {

source: "train_p_lmdb" batch_size:    64

backend: LMDB

}

}

layer {

name: "mnist" type: "Data" top: "data" top: "label" include {

phase: TEST

}

transform_param { mean一 value: 128 scale:    0.00390625

}

data_param {

source: "val_lmdb" batch_size:    100

backend: LMDB

}

}

layer {

name: "mnist_p" type: "Data" top: "data_p"

layer中读取过了

\# top: "label"可以省略，因为已经在 mnist 的 data include { f

phase: TEST

}

transform一 param { mean_value:    128

scale:    0.00390625

}

data_param {

source: "val_p_lmdb" batch_size:    100

backend: LMDB

}

}

layer {

name: ’’convl’* type: "Convolution" bottom:    "data"

top: "convl"

\#参数共享的方式是指定参数的名字，用 name 指定 #在其他层中如果出现了同样的 name，则共享参数 #本例中共享参数的是 convl_p

param {

name: "convl_w" lr_mult:    1

}

param {

weight_filler {

type: "xavier"

}

bias_filler {

type: "constant"

}

}

}

layer {

name: ’’pooll"

..。中间部分省略...

}

layer {

name: "feat"

type: "InnerProduct"

weight—filler {

type: "xavier"

}

bias_filler {

type: ’’constant"

}

}

}

\#处理 MNIST 数据的网络到此结束 layer {

name: '*convl_pn type: "Convolution" bottom: ndata_p" top: "convl_p"

\#参数共享

param {

name:    "convl_w"

lr_mult:    1

}

param {

name: "convl_b" lr_mult:    2

}

weight_filler {

type:    "xavier"

}

bias_filler {

type: "constant"

}

}

}

layer {

name: "pooll_p"

..。中间部分省略 }

layer {

name: "feat_p" type: "InnerProduct" bottom:    "ip2_p"

top: "feat_p" param {

weight_filler {

type: "xavier"

}

bias_filler {

type: ’’constant’’

}

}

}

layer {

name: "loss"

type: "ContrastiveLoss"

bottom: "feat"

bottom: "feat_p"

bottom: "label"

top: "loss"

contrastive_loss_param { margin:    1

}

}

需要注意的有两点：第一点，对应的 data layer参数要完全一致，每对中只要一个 datalayer读取标签就可以了，另一个可以忽略读取标签；第二点，参数共享通过制定参数 名称实现，一定要保证名称相同。网络结构的可视化如图 12-4所示。



图 12-4用多个 lmdb 训练 Siamese 的网络结构可视化

完整的 solver 和网络结构定义可以在本书的 github 代码仓中查看。接下来训练的过程 与第 8 章类似。

» /path/to/caffe/build/tools/caffe train -solver mnist_siamese_ solver.prototxt -log_dir . /

得到的训练曲线如图 12-5所示。



图 12-5用 MNIST 训练 Siamese 模型的收敛曲线

由图 12-5可知后期显然过拟合了，最小的验证集 loss 是在迭代 22000 次附近。

12.2.3结果和可视化

本节选取 20000 次时保存的模型来试一试，部署的文件就是 Caffe 自带的

mnist_siamese.prototxt：这个文件和一般的 LeNet-5区别不大，只是最后一层换成了一个二

维输出。Caffe自带的例子选择二维输出，一方面可能是因为 MNIST 确实比较简单，另一

方面也容易可视化，所以这里直接用下面脚本把所有 test 集中的样本最后的输出画在二维

###### 平面上。

import os import sys

sys.path.append(*/opt/caffe/python') import re

import numpy as np

import matplotlib.pyplot as pit

import cv2

import caffe

WEIGHTS_FILE = *mnist_siamese_iter_20000.caffemodel'

DEPLOY—FILE =    1mnist_siamese.prototxt'

IMG_DIR = 'mnist/test'

MEAN =    128

SCALE =    0.00390625

caffe.set_mode_gpu() caffe.set_device(0)

net = caffe.Net(DEPLOY_FILEZ WEIGHTS_FILE, caffe.TEST)

\#匹配获取文件对应数字的正则表达式

pattern = re.compile('\d+_(\d)\.jpg*)

\#获取 mnist/test文件夹下所有图片 image_list = os.listdir(IMG_DIR) n_imgs = len(image_list)

\# 一次性读取用 GPU 并行处理

net.blobs['data'].reshape(n_imgsz 1,    28,    28)

\#按照顺序保存 label 的列表 labels =    []

for i, filename in enumerate(image_list):

digit = int(pattern.findall(filename)[0]) labels.append(digit)

\#获取文件路径

filepath = os.sep•join([IMG_DIR, filename])

\#读取单通道文件并减均值和乘系数_

image = cv2•imread(filepath, cv2•IMREAD_GRAYSCALE).astype(np.float)

-MEAN

image *= SCALE

net.blobs[1 data *] .data[i,    . . . ]    = image

labels = np.array(labels) output = net.forward() feat = output['feat *]

\#定义每个数字的颜色，颜色定义从 Caffe 自带例子直接复制而来

colors = [，#ff0000\ ，#ffff0(r, *#00ff00\ ，糊 ffff，， *#0000ff1,

^ffOOff'z '#990000*,    '#999900',    '#009900',    '#009999']

legend = [ '0\ 'I', '2’， *3', '4，， '5', %•' ' 7 ', ; 1 8 \ 1 9']

\#用二维散点图可视化 pit.figure('feat *) for i in range (10):

pit.plot(feat[labels==i,0].flatten(),

feat[labels==iz1].flatten(),

’ .*, c=colors[i])

pit.legend(legend) pit.show()

因为样本量较大，本段代码推荐在 GPU 上运行，运行后得到的结果可以清楚看到相同 的数字会“聚”在一起，如图 12-6所示。

2.0

1.5

1.0

0.5

0.0

-0.5

-1.0

—1.5

-2.0



-2-10 1 2

图 12-6对图片提取二维特征的可视化

12.2.4用 t-SNE可视化高维特征

MNIST的例子非常简单，所以二维的特征就足够了。然而在实际的应用中，比如人脸 比对或场景搜索，特征的维数可能是上千维。这时候如果还要可视化，就需要借助降维手 段。第 2 章讲降维的时候提到过 t-SNE，基本上算是高维度特征在低维度下可视化的最常 用方法了。这种算法的基本思想是，高维空间中样本距离的相对远近，在降维后的空间中 也要体现出来。不过本书不打算探讨该方法的细节，只是讲一下如何通过 python 的 skleam 工具包调用该算法进行可视化。因为我们的例子中没有专门训练一个高维度的特征，所以 用训练好的模型的倒数第二层全连接层 ip2 代替进行测试。接上段代码，可视化 ip2 输出 特征的代码如下：

from sklearn.manifold import TSNE

\#起一个新的 figure pit.figure(* ip21)

\#通过 blobs 取得隐层的数据 ip2_feat = net.blobs[* ip2'].data # n_components指定降维之后的维数，默认就是 2 model = TSNE(n_components=2)

ip2_vis_feat = model.fit_transform(ip2_feat) for i in range(10):

pit.plot(ip2_vis_feat[labels==iz 0] .flatten(),

ip2_vis_feat[labels==i,1].flatten(),

\* . 1, c=colors[i])

pit.legend(legend) pit.show()

如果是配置比较低的计算机，可以考虑只用一部分样本进行可视化。执行上面代码得 到的图像如图 12-7所示。

10

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-310.jpg)

-2

-4

-6

一 8

-10    一 5    0    5    10

图 12-7 t-SNE在二维空间中可视化倒数第二层的 10 维特征

图 12-7虽然效果不如最后的二维特征，但也能看出已经有了比较明显的区分性。可视 化的完整代码和预训练好的模型在本书的 github 代码仓中也可以找到。





# 相关

- 《深度学习与计算机视觉》
