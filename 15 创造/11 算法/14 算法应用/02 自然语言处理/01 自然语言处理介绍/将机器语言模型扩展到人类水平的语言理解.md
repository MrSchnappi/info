# 将机器语言模型扩展到人类水平的语言理解

> **【新智元导读】**DeepMind、斯坦福大学、谷歌等的研究团队近日发表论文《将机器语言模型扩展到人类水平的语言理解》，回顾了最近AI在自然语言处理方面的突破，认为机器要达到人类水平的语言理解能力，需要互补的记忆系统和丰富的情境表征。他们描述了向人类水平的语言理解扩展ML模型的路线图。戳右边链接上 [新智元小程序](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3MTA0MTk1MA%3D%3D%26mid%3D2652060304%26idx%3D4%26sn%3D3e0eb673f99a35ed0f62285de8025446%26chksm%3Df1204e61c657c777ca83bab4a46033196937933f045e996470bee2f7af0ecb4430f336e2aeee%26token%3D2092177547%26lang%3Dzh_CN) 了解更多！



语言是人类智能的核心。但理解语言意味着什么呢？

DeepMind、斯坦福大学、博世人工智能中心、Google Research以及 LMU Munich的研究团队最近发表论文《将机器语言模型扩展到人类水平的语言理解》(Extending Machine Language Models toward Human-Level Language Understanding)，回顾了最近在自然语言处理方面的突破，并提出了有待实现的目标。

研究人员认为，**机器要达到人类水平的语言理解能力，需要互补的记忆系统和丰富的情境表征**。他们描述了向人类水平语言理解扩展ML模型的路线图。

![img](https://pic3.zhimg.com/80/v2-71032fba945ae9d3742cf2be88fafc12_hd.jpg)

最近的方法依赖于人工神经网络捕获的关于学习和表示的领域通用原理。然而，当前的大多数模型都过于关注语言本身。对于人类来说，语言是一个用于获取、表示和交流物理世界和社会世界中的对象和情况的更大的系统的一部分，**未来的机器语言模型应该模仿这样一个系统**。

人类语言处理利用了**互补的学习系统**，包括像机器系统一样逐渐学习的深度神经网络式学习系统，以及支持快速学习新信息的**快速学习系统**。**将这样一个系统添加到机器语言模型中，将是迈向真正的类人语言理解的重要一步**。

## **人类综合理解系统(IUS)**

**情境和对象**

尽管神经语言建模取得了成功，但存在一大限制，即这些模型完全基于语言。

我们需要这样一个模型，在这个模型中，**语言是一个综合理解系统(integrated understanding system，IUS)的一部分，用于理解和交流我们遇到的情境(situations)以及参与其中的对象(objects)**。

情境表征构成了我们的世界模型，并指导着我们的行为和对语言的解释。事实上，解决一个句子中代词的指称问题可以从构建该句子所描述的情境的表示开始。简而言之，我们认为，语言的进化是为了交流情况，我们的系统应该解决这个问题。

情境可以是具体的和静态的，例如猫在垫子上；也可以是事件，例如男孩在打球。它们可以是概念上的、社会上的或法律上的，例如法院宣布某项法律无效，甚至可以是虚构的。

对象可以是真实的或虚构的物理对象或位置；动物、人、团体或组织；信仰或其他精神状态；或实体，如理论，法律或宪法。本文中我们重点考虑具体的情境，我们的研究建立在语言学、人类认知、人工智能和早期PDP模型的经典著作之上，与认知神经科学的新兴观点相吻合。

人类构建情境表征的证据来自Bransford和他的同事的经典著作(33,38)。这项工作表明：

(1)当我们能将文本中的陈述与熟悉的情境联系起来时，我们就能更好地理解和记忆文本;

(2)传达情境的信息可以通过文字附带的图片提供;

(3)我们记住的对象的特征取决于它们在文本中所处的情境;

(4)我们记忆中的对象没有在文本中明确提及;

(5)在听到描述对象之间的空间关系或概念关系的句子后，我们记住的是这些关系，而不是语言输入。

此外，眼动的证据表明，人们在语境中处理语言时，会同时且立即使用语言输入和非语言输入。例如，在听到“The man will drink …”这句话后，参与者看到的是满的葡萄酒杯，而不是空的啤酒杯。而听到“The man drank…”，他们的看到的是空的啤酒杯。

因此，语言理解包括使用视觉输入和语言输入，实时地构建语言输入所描述的情境的表示，包括所涉及的对象及其相互之间的空间关系。

## **大脑中的理解系统**

图4描述了我们提出的综合理解系统。我们所提出的既是关于大脑理解基础的理论，也是未来语言理解研究的架构。

首先，我们关注系统的一部分，被称为新皮层系统(neocortical system)，它的作用是将语言和非语言输入结合起来，例如，在听到一个包含“bat”这个词的句子时，它能理解所指的对象和情境，同时观察世界上相应的情境。

![img](https://pic1.zhimg.com/80/v2-5b0265c7ecbed8233ce99c091090a204_hd.jpg)图4：综合理解系统(IUS)

这个系统由图中的蓝色椭圆(对应于大脑中的神经元池)和蓝色箭头(这些池之间的连接)组成。蓝色框包含了新皮层系统，每个椭圆形成一个特定信息的嵌入(表示)。蓝色箭头表示已学习的连接，允许嵌入相互约束。红色框包含内侧颞叶系统，被认为提供了一个存储新皮层系统状态完整嵌入的网络。红色箭头表示快速学习连接，这些连接将嵌入的元素绑定在一起，以便以后重新激活和使用。连接红色和蓝色椭圆的绿色箭头支持两个系统之间的双向影响。(A)和(B)是正文中讨论的两个例子。

## **互补的学习系统**

学习在理解中起着至关重要的作用。我们所描述的神经网络中连接权值的知识是通过基于每次经验的非常小的调整积累而获得的。连接权重逐渐变得对微妙的高阶统计关系敏感，随着学习的继续，越来越多地考虑上下文，并表现出对一般信息和重复的特定信息(如亲密朋友和名人的名字)的敏感性。

在我们提出的架构中，这个渐进的过程发生在图4中蓝色箭头所代表的所有路径中，就像它发生在上述人工神经语言模型中一样。然而，这种学习机制不适合快速获取新信息，而试图通过有针对性地重复快速学习特定的新信息，会导致对已知信息的灾难性干扰。

但是，人类通常可以依靠过去任意时间仅呈现一次的信息来告知我们当前的理解。例如，考虑这段话：

> John put some beer in a cooler and went out with his friends to play volleyball. Soon after he left, someone took the beer out of the cooler. John and his friends were thirsty after the game, and went back to his place for some beers. When John opened the cooler, he discovered that the beer was ___.

要推测出John再次打开冷藏箱时找不到啤酒，我们必须依靠第一次听说啤酒被偷走了时所获得的信息。

这种情况非常普遍，学习系统必须能够利用这些信息，但是BERT等语言模型在这种方式下是有限的。虽然有些模型将长单词序列保持在活动状态，但当一个文本被替换为另一个文本时，只保留上面描述的较小的连接调整，使这些系统无法访问先前信息的细节。

**人类的大脑包含一个能解决这种限制的系统**。考虑这样一种情况：某人看到了一个以前不熟悉的物体，并听到了关于它的口头陈述，如图4B所示。视觉输入提供了一个关于该对象(先前不熟悉的动物)的信息源，而语言输入提供了它的名称。在仅仅经历了两次这样的短暂配对之后，人类就表现出了很强的学习能力。这种学习方式依赖于**海马体和大脑内侧颞叶(MTL)**的邻近区域。虽然MTL在学习和记忆中的作用学界仍在讨论，但形成的一个共识是，MTL对于新记忆的初步形成至关重要，包括对特定事件及其构成对象和情境的记忆， 而一般知识、理解语言的能力以及先前获得的技能不受MTL损害的影响。

关于MTL损伤的研究证据表明，**在MTL中存在一个快速学习系统(fast learning system)**。根据互补学习系统理论(CLST)，该系统(图4中的红色部分)提供了对理解系统状态的完整表示，并在MTL(红色箭头)中使用可快速修改的连接，以支持基于单一经验的新学习。绿色箭头表示新皮层系统(蓝色)和MTL系统(红色)之间携带信息的连接，因此系统可以相互影响。

总结而言，人类的大脑包含了互补的学习系统，当我们试图理解一个经历过的情况时，这些系统支持同时使用许多信息来源。其中一个系统是通过交错学习的方式逐渐形成一个完整的知识体系，包括我们对单词含义、经常遇到的物体的属性、熟悉情况的特征的认识。另一个是对该系统的补充，以允许将来自特定经验的信息用于对当前情况的解释。

## **迈向人工综合理解系统**

我们回顾了当前的深度学习研究，这些研究采取的步骤与我们所提议的IUS相一致，并指出了实现一个真正完整且功能齐全的语言理解系统所需要的未来方向。

我们从建立在具体的视觉和物理环境中的语言环境开始，然后考虑记忆的作用，最后将注意力转向对更抽象的对象、情境和关系的理解上。

**将视觉和语言映射到对象的表示**

一个模型如何学习世界上可能发生的情况？

长期以来，人们一直在讨论构建一个建立在外部世界基础上的人工语言理解系统的必要性。早期的一个例子是Winograd的SHRDLU系统，它产生并响应了关于模拟物理世界的语言。

深度学习使感知输入和语言的端到端的联合训练成为可能。这些模型的最新进展极大地改善了性能，导致应用程序改变了用户体验。例如，当展示给系统一张照片，系统就可以回答一些问题，比如这个人手上拿着什么？女士的衬衫是什么颜色的？这些模型展示了将视觉和语言信息相结合以理解一类情况的能力。

**体现语言理解的模型**

如图4所示，除了视觉和语言的综合之外，我们还可以看到许多附加信息源的更充分的综合。每个源都为不同的学习目标提供了基础，并使一个源中突出的信息能够引导另一个源中的学习和推断。其他重要的信息来源包括非语言的声音、触觉和力觉，以及关于个人行为的信息。

尽管有这些令人鼓舞的迹象，但要实现完全的人类水平的泛化仍然是一个重要的挑战。我们建议，结合一个类似MTL的快速学习系统将有助于解决这一问题，即允许新单词链接到相应的对象上，而在其他情况下，仅从单个事件支持使用该单词来指代被指称者。

**一个人工的快速学习系统**

在综合理解系统的实现中，快速学习系统应该是什么样的呢？可微神经计算机(DNC)中的存储系统是一种可能性。这些系统将过去事件的嵌入存储在插槽(slots)中，这些插槽可以存储综合的系统状态表示，就像我们人类的MTL一样。或者，它们可以存储整个状态的集合，包括视觉、语言、对象和场景表示。

虽然我们不相信大脑对每段记忆都有一个单独的槽位，但模拟它是很有用的(56)，在这方面，具有无限容量的人工系统可能会超过人类的能力。

在这样一个系统中，相关信息的检索是如何工作的呢？DNC采用一个类似BERT的查询系统，检索可以基于上下文和项目信息的组合，类似于人类记忆(70)。

研究出这样一个系统的细节是未来一个令人兴奋的研究方向。

## **结论**

语言并不是孤立存在的。大脑中的综合理解系统将语言与物体和情境的表征联系起来，并通过充分利用我们对世界的多感官体验、我们对运动动作的表征以及我们对先前情景的记忆来增强语言理解。

我们认为下一代的语言理解系统应该模仿大脑中的这个系统，并且我们已经勾勒出了这个系统可能采取的一些形式。

当强调对具体情况的理解时，我们认为对更抽象的语言的理解是建立在这一具体基础之上的，并指出未来我们有可能建立一个人工系统来理解远远超出具体、此时此刻这一范围的抽象情况。

总而言之，我们提出，对大脑中的综合理解系统进行建模，将使人工智能更接近于达到人类水平的语言理解和智能。

论文地址：

[https://arxiv.org/pdf/1912.05877.pdfarxiv.org](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1912.05877.pdf)


# 相关

- [AI要达到真正人类水平的语言理解能力，应该模仿人脑 | DeepMind、斯坦福等重磅研究](https://zhuanlan.zhihu.com/p/97878583)
