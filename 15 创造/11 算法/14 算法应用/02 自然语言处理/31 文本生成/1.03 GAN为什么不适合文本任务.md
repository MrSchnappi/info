---
title: 1.03 GAN为什么不适合文本任务
toc: true
date: 2019-09-03
---

# GAN为什么不适合文本任务？

GAN 在 2014 年被提出之后，在图像生成领域取得了广泛的研究应用。然后在文本领域却一直没有很惊艳的效果。主要在于文本数据是离散数据，而 GAN 在应用于离散数据时存在以下几个问题：

- GAN 的生成器梯度来源于判别器对于正负样本的判别。然而，对于文本生成问题，RNN 输出的是一个概率序列，然后取 argmax。这会导致生成器 Loss 不可导。还可以站在另一个角度理解，由于是 argmax，所以参数更新一点点并不会改变 argmax 的结果，这也使得 GAN 不适合离散数据。<span style="color:red;">没明白。</span>
- GAN 只能评估整个序列的 loss，但是无法评估半句话，或者是当前生成单词对后续结果好坏的影响。<span style="color:red;">嗯，这个是的。</span>
- 如果不加 argmax，那么由于生成器生成的都是浮点数值，而 ground truth 都是 one-hot encoding，那么判别器只要判别生成的结果是不是 0/1 序列组成的就可以了。这容易导致训练崩溃。<span style="color:red;">什么是 ground truth？为什么容易导致训练崩溃？</span>









# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
