---
title: 01.02 问答系统比赛
toc: true
date: 2019-10-13
---
# 问答系统比赛

从 SQuAD 说开去

其实，一部问答系统发展史就是一部人工智能史。伴随着人工智能的兴衰，问答系统也经历了半个多世纪的浮沉。此外，随着符号主义（代表算法为：关联规则、决策树等）、贝叶斯主义（代表算法为：概率图模型）、进化主义（代表算法为：遗传算法）、Analogizer（代表算法为：支持向量机）、联结主义（代表算法为：深度神经网络）轮流登上历史舞台的最高峰，用于支撑问答系统的核心算法也经历了数次更迭，从而使得人们构建问答系统的思路不一。为了构建一个良好的问答系统产学研生态圈，业界和学术界一直致力于提出质量更好的数据集、举办更有影响力的比赛来促进该领域的蓬勃发展。其中，斯坦福大学在 2016 年推出的数据集 SQuAD 成为了今年来最受到学术界和工业界瞩目的重量级阅读理解数据集，可以说 SQuAD 之于问答系统就好比 ImageNet 之于计算机视觉的意义。这个阅读理解数据集会给研究者提供一篇篇文章，准备相应的问题，而研究者需要自己设计问答系统模型用于给出问题的答案。SQuAD 之所以备受推崇，得益于其巨大的规模，它包含 536 篇文章以及相关的 107,785 个问题。（详情请见雷锋网(公众号：雷锋网)文章：<https://www.leiphone.com/news/201608/ftBdq445PzC1kxbF.html>  ）此外，数据集采用 F1 值和 EM（exact match，完全匹配）两种分类标准来评价模型性能，保证了模型评价的相对客观。

![问答系统冠军之路：用 CNN 做问答任务的 QANet](https://static.leiphone.com/uploads/new/article/740_740/201805/5aefe06004a5a.png?imageMogr2/format/jpg/quality/90)

图 2: SQuAD排行榜

如上图所示，SQuAD 赛事吸引了微软、谷歌、阿里巴巴、科大讯飞等业界巨头和 CMU，哈工大等高校参与其中，排行榜上的名次经常处于变化之中。尤记得去年 7 月科大讯飞首次登顶该榜榜首，取得了 77.845 的 EM 以及 85.297 的 F1 值，一时间风头无两，但是不久后这个成绩就被其他机构超越。今年年初，微软的 r-net 在 EM 指标上获得了 82.625 的高分，声称首次在该指标上超越了人类（根据斯坦福收集的数据，人类的 EM 值为 82.304）。

直到最近，谷歌大脑团队和 CMU 联合推出的 QANet 再一次拔得头筹，**大幅度地将 EM 值提高至 83.877（第二名为科大讯飞和哈工大的 AOA reader 模型获得的 82.482）， F1 值也获得了有史以来的最高分——89.737。另一方面，相比别的团队提交的模型在 DAWNBench 中动辄 7 到 10 个小时的训练时间，QANet 只需要短短 45 分钟。**


# 相关

- [问答系统冠军之路：用 CNN 做问答任务的 QANet](https://www.leiphone.com/news/201805/A1mkxTOKWrZOY64l.html)
