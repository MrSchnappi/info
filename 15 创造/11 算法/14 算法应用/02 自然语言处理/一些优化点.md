---
title: 一些优化点
toc: true
date: 2019-10-18
---
# 一些优化点


比赛结束后一些队伍分享了他们的解法，从中我学到了一些我没有做或是做的不够好的地方：

- 产品标题的组织方式是有 Pattern 的，比如一个产品是否带有某附件一定会用 `With/Without XXX` 的格式放在标题最后。
- 使用**外部数据**，比如 WordNet，Reddit 评论数据集等来训练同义词和上位词（在一定程度上替代 Word2Vec）词典。
- 基于**字母**而不是单词的 NLP Feature。这一点我让我十分费解，但请教以后发现非常有道理。举例说，排名第三的队伍在计算匹配度时，将搜索词和内容中相匹配的单词的长度也考虑进去了。这是因为他们发现**越长的单词约具体，所以越容易被用户认为相关度高**。此外他们还使用了逐字符的序列比较（`difflib.SequenceMatcher`），因为**这个相似度能够衡量视觉上的相似度**。像这样的 Feature 的确不是每个人都能想到的。
- 标注单词的词性，找出**中心词**，计算基于中心词的各种匹配度和距离。这一点我想到了，但没有时间尝试。
- 将产品标题 / 介绍中 TF-IDF 最高的一些 Trigram 拿出来，计算搜索词中出现在这些 Trigram 中的比例；反过来以搜索词为基底也做一遍。这相当于是从另一个角度抽取了一些 Latent 标识。
- 一些新颖的距离尺度，比如 Word Movers Distance
- 除了 SVD 以外还可以用上 NMF。
- **最重要的 Feature 之间的 Pairwise Polynomial Interaction**。
- **针对数据不 i.i.d. 的问题，在 CV 时手动构造测试集与验证集之间产品 ID 不重叠和重叠的两种不同分割，并以与实际训练集 / 测试集的分割相同的比例来做 CV 以逼近 LB 的得分分布**。
