---
title: 3.12 对数损失函数
toc: true
date: 2019-09-03
---
# 对数损失函数

$$
L(Y, P(Y|X)) = -\log{P(Y|X)}
$$

常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数是平方损失，其实不然。逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看，就是对数损失函数。<span style="color:red;">没有很明白。</span>


## 对数损失函数是如何度量损失的

<span style="color:red;">这个地方没有很清楚。</span>

例如，在高斯分布中，我们需要确定均值和标准差。

如何确定这两个参数？最大似然估计是比较常用的方法。最大似然的目标是找到一些参数值，这些参数值对应的分布可以最大化观测到数据的概率。

因为需要计算观测到所有数据的全概率，即所有观测到的数据点的联合概率。现考虑如下简化情况：

（1）假设观测到每个数据点的概率和其他数据点的概率是独立的。

（2）取自然对数。

假设观测到单个数据点 $x_i(i=1,2,...n)$ 的概率为：

$$
P(x_i;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp
\left( - \frac{(x_i-\mu)^2}{2\sigma^2} \right)
$$

（3）其联合概率为：

$$
P(x_1,x_2,...,x_n;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp
\left( - \frac{(x_1-\mu)^2}{2\sigma^2} \right) \\ \times
 \frac{1}{\sigma \sqrt{2\pi}}\exp
\left( - \frac{(x_2-\mu)^2}{2\sigma^2} \right) \times ... \times
\frac{1}{\sigma \sqrt{2\pi}}\exp
\left( - \frac{(x_n-\mu)^2}{2\sigma^2} \right)
$$

​对上式取自然对数，可得：

$$
\ln(P(x_1,x_2,...x_n;\mu,\sigma))=
\ln \left(\frac{1}{\sigma \sqrt{2\pi}} \right)- \frac{(x_1-\mu)^2}{2\sigma^2}  \\ +
\ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right)- \frac{(x_2-\mu)^2}{2\sigma^2} +...+
\ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right)- \frac{(x_n-\mu)^2}{2\sigma^2}
$$

根据对数定律，上式可以化简为：

$$
\ln(P(x_1,x_2,...x_n;\mu,\sigma))=-n\ln(\sigma)-\frac{n}{2} \ln(2\pi)\\
-\frac{1}{2\sigma^2}[(x_1-\mu)^2+(x_2-\mu)^2+...+(x_n-\mu)^2]
$$

然后求导为：

$$
\frac{\partial\ln(P(x_1,x_2,...,x_n;\mu,\sigma))}{\partial\mu}=
\frac{n}{\sigma^2}[\mu - (x_1+x_2+...+x_n)]
$$
​
上式左半部分为对数损失函数。损失函数越小越好，因此我们令等式左半的对数损失函数为 0，可得：

$$
\mu=\frac{x_1+x_2+...+x_n}{n}
$$

同理，可计算 $\sigma ​$。











# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
