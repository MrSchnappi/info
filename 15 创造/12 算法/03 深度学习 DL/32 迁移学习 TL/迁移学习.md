---
title: 迁移学习
toc: true
date: 2019-11-17
---
# 迁移学习


**迁移学习：深度和对抗成为范式**



**机器之心：去年，您在机器之心的 GMIS 大会上提到了迁移学习的六个进展，分别是结构与内容分离、多层次的特征学习、多步迁移学习、学习「如何迁移」、迁移学习作为元学习以及数据生成式的迁移学习。在过去的一年多时间里，有哪些方向出现了令人瞩目的进展？**



**首先是层次感**。这方面进展非常迅速。业界发现深度学习天然适合做迁移的学习，正是因为深度学习不同的层次负责编码不同的知识。



因此多层次的特征学习有很多种可行结构：一是多视角，让不同的输入分别进入不同的初始层，处理后共享一些中间层；另一种是利用对抗的结构，例如 GAN 和 DANN，筛出不同领域间可共享的特征。共享特征的意思是无法用这个特征区分两个领域。用对抗找出共享特征的意思是，让一个网络负责筛选出让对方区分不了的特征，让另一个网络负责根据特征区分两个领域，两个网络通过博弈达到平衡时，就自动找到了两个领域之间的重叠部分。



总的来说，对抗网络现在已经变成了迁移学习的一种已定式和系统了。



在**学习如何迁移**方面，我们最近有一篇 ICML 2018 文章，Transfer learning by learning to transfer 讲的就是这个问题。这个文章的第一作者是魏颖博士。文章的主旨是，在我们积累了在很多领域进行学习的经验后，把领域间的迁移过程作为例子。例如在翻译问题上，从日语到中文是一个迁移，从日语到英文是另一次迁移。如果有 N 个领域，就会有 近 N*N 个例子。把迁移的例子做成训练集，就可以训练出一个自动的迁移规划器，它会告诉你如何迁移或是说迁移的方法论。来了一个新问题，迁移器可以告诉你应该挑那些迁移学习算法来用在这个问题上。



这个问题的输入是算法的参数和描述不同领域的参数，优化函数是所有样本的期望损失最低，学出来的迁移器既挑选模型，也学习参数。这个工作的主题是「学习如何学习」，和时下流行的 AutoML 有紧密的联系。今年，「第四范式公司」会在 NIPS 2018 上将举办首届 AutoML 大赛，也是给大家一次展示迁移学习能力的机会。



「学习如何学习」也不仅仅是计算机科学中的问题。在心理学领域，上世纪美国心理学家 Thorndike 就拿猴子做了一个实验，证明猴子是有迁移能力的。他让猴子解决一些不同的任务，解决好了就能拿到食物，解决不好就让他继续解决，一段时间后，猴子就学会了在新的领域里寻找特征，利用原有的经验解决新问题。因此 Thorndike 总结道：「智能就是迁移能力。」他将这个观点应用到教育学上，认为教育程度高，并不是考试分数高，而是学下一门课学得更快。



最后，**结构与内容分离**，换言之，就是要用尽可能少的例子来学尽可能多的事儿，这方面的内容仍然不是很多。但这其实并不是局限于迁移学习的一个讨论，而是人工智能整体试图解决的一个问题。



最近 Yann Lecun 的在 IJCAI2018 上的一个讲座让我觉得很有启发。Yann 也在思考为什么人只需要几个例子，而深度学习需要那么多例子。他的观点是，一个例子中的内容特别多，而用一个例子做一个任务，就等于把其他的内容浪费了，因此我们需要**从一个样本中找出多个任务**。比如说遮挡图片的一个特定部分，用没遮挡部分来猜遮挡的部分是一个任务。那么通过遮挡不同的部分，就可以用一个样本完成不同任务。Yann 描述的这个方法被业界称作「自监督学习」。



我觉得自监督学习可以和迁移学习结合来做的。因为一个样本毕竟还是有局限性，它的变化很小，统计性很差，但是如果和以前的经验能结合起来，例如从其他任务里迁移一个偏置项，可能就是解决小样本的一个方向。



**机器之心：您如何对当前的迁移学习算法进行分类？原因是什么？**



之前，我们通常将迁移学习分为三类。第一类是**样本迁移**，将可能对新领域有用的样本的权重加大。这一类方法非常经典，但是现在用得比较少。



第二种叫做**特征迁移**，特征空间的维度很高，如果我发现第一个领域里发现的重要特征能够覆盖新领域，那么我就把它迁移到新领域中去。迁移的部分可能是人工选出来的特征，这种方法在自然语言处理迁移中比较常见，也可以是一个特征提取器，这种方法在计算机视觉迁移中比较常见。



最后一种是**参数迁移**，迁移的范围与两个领域之间的距离有关。例如和图像相关的模型，越是靠下的层越通用，迁移能力越强，越是靠上的层越是特殊，迁移能力越弱。因此可以根据领域间距离定量地确定迁移的程度：如果两个领域相距很远，那么可以只迁移最下方的几层，如果两个领域很相似，则可以多迁移几层。此外还可以量化迁移后调节参数的时机：两个领域相距越远，参数调节就应该越早进行，两个领域相距越近，参数调节就可以越晚进行。



近年一个有意思的特征迁移案例是斯坦福大学为联合国做的「如何在卫星图片中标记贫穷的地区」。联合国在决定给每个地区分配的资助前，需要确定当地的贫穷程度。在过去，做法是派人去进行经济调查，而斯坦福大学试图用 跨越式迁移的方法来解决这个问题。研究人员首先对白天的卫星图片进行语义级别的分割，标出桥梁、建筑物等。然后以灯光明亮度代表富裕程度，通过白天和夜晚的图像比对，找出最富有的地区在白天有哪些可见的特征，比如游泳池。然后将游泳池视为富裕地区的显著特征后，再通过搜索游泳池周围经常出现特征，进行另一轮的代表性特征选择。逐步扩展下去，最后在识别贫富程度上达到和现场调查人员相近的准确率。



**这类非常具有社会意义的选题也是值得国内研究者思考和借鉴的**，我们不应该只擅长刷 ImageNet 榜单。



除此之外，根据采用的模型结构还可以分成采用/不采用深度学习的。近年随着对抗生成网络在迁移学习中的应用越来越广泛，还有一种分法是根据是否利用对抗的方法进行分类。迁移学习中天然存在可以对抗的部分：希望算法在本领域准确性尽可能高，希望算法在两个领域间的差距尽可能小。把这两个限制条件同时作为目标，就形成了一个恰恰合适对抗生成网络做的事情。


# 相关

- [机器之心专访杨强教授：联邦迁移学习与金融领域的AI落地](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650746037&idx=1&sn=646008f2d88f2377b4564282add32aed&chksm=871ae8cbb06d61dd498817437fe76d2760a906ab808f3025fc396d22d560177448c8e5eb27cb&mpshare=1&scene=1&srcid=0801X9tUQ4I6DlMCmKCvy77B#rd)
