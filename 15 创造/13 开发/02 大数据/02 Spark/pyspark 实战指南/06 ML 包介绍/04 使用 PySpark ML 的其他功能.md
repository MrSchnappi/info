---
title: 04 使用 PySpark ML 的其他功能
toc: true
date: 2019-07-02
---
6.4 使用 PySpark ML的其他功能
在本章开头，描述了 PySpark ML库的大部分功能。在本节中，将提供一些如何使用转换器和评估器的示例。
6.4.1 特征提取
我们已经使用了 PySpark 这个子模块中不少的模型。本节中，我们将展示如何使用最有用的（我们所认为的）模型。NLP相关特征提取
如前所述，NGram模型采用标记文本的列表，并生成单词对（或 n-gram）。
本例中，我们从 PySpark 的文档中摘录一段，并介绍如何在将文本传递给 NGram 模型之前进行清理。数据集如下（为了简洁只写了简短一部分）：如下代码完整版请从我们的 Github 库下载代码：https://github.com/drabastomek/learningPySpark。我们从管道中 DataFrame 用法描述里面复制了这四个段落：http://spark.apache.org/docs/latest/ml-pipeline.html#dataframe。
在单列的 DataFrame 中，每一行只是一堆文本。首先，需要对文本进行标记。为了做到这一点，将使用 RegexTokenizer 而不仅是 Tokenizer，以便可以指定拆分文本的模式：
该模式会将文本在所有的空格处分隔，而且还会删除逗号、句号、反斜杠和引号。tokenizer的一行输出类似如下：
如你所见，RegexTokenizer不仅将句子分割成单词，而且还使文本变得规范化，每个单词都是小写的。
然而，我们的文本中仍然有很多垃圾内容：如 be、a或通常分析文本时对我们无用的词。因此，我们会使用 StopWordsRemover（……）来删除这些所谓的 stopword：
该方法的输出类似如下内容：
现在我们只剩下有用的单词。所以，我们来构建 NGram 模型和管道：
现在我们有了管道，可以遵从与之前类似的方式来使用：


以上代码产生如下输出：
处理完毕。我们得到了 n-grams，现在可以在进一步的 NLP 处理中使用它们了。离散连续变量
我们常常需要处理高度非线性的连续特征，很难只用一个系数来供给模型。
这种情况下，可能难以用一个系数来解释这样的特征与目标之间的关系。有时候，将值划分成分级类别是很有用的。
首先，使用以下代码帮助创建一些假数据：
现在，使用以下代码创建一个 DataFrame：


接下来，将使用 QuantileDiscretizer 模型将连续变量分为五个分级类别（numBuckets参数）：
来看看我们得到了什么：
我们的函数现在看起来如下：
现在可以将此变量视为分类，并使用 OneHotEncoder 对其进行编码以备将来使用。标准化连续变量
标准化连续变量不仅有助于更好地理解特征之间的关系（因为解释系数变得更容易），而且还有助于计算效率，并防止运行到某些数字陷阱。这里演示了如何使用 PySpark ML来完成这个工作。
首先，需要创建一个向量代表连续变量（因为它只是一个 float）：
接下来构建 normalizer 和管道。通过将 withMean 和 withStd 设置为 True，该方法将删除均值并让方差缩放为单位长度：
转换后的数据如下所示：



如你所见，数据现在以单位方差（绿线）振荡在 0 左右。
6.4.2 分类
到目前为止，我们只使用了来自 PySpark ML的 LogisticRegression 模型。在本节中，将再次使用 RandomForestClassfier 来模拟婴儿的生存机会。
不过在这之前，我们需要将 label 特征转化为 DoubleType：
现在已经将 label 转换成了 double，可以开始构建模型。处理方式与之前类似，区别在于我们将重用本章前面的 encoder 和 featureCreator。numTrees参数指定我们的随机林中应该有多少个决策树，maxDepth参数限制树的深度：
现在来看看与 LogisticRegression 相比，RandomForestClassifier模型表现如何：
得到结果如下：
那么，如你所见，结果比逻辑回归模型要好大约 3 个百分点。我们来测试用一个树的模型表现如何：


以上代码产生如下结果：
一点也不差！实际上，它的表现比随机森林模型在查全率（precision-recall）关系方面表现得更好，仅在 ROC 下的区域稍差。那么谁的表现胜出已经显而易见了！
6.4.3 聚类
聚类是机器学习的另一个重要组成部分：通常在现实世界中，我们没有那么幸运具有目标特征，所以需要回到一个无监督的学习范例，来试图从中发掘数据内的模式。在出生数据集中查找簇
本例中，我们将使用 k-means模型在出生数据中查找相似性：
估计模型后，我们来看看是否能找到簇间的一些差异：
如上代码产生如下输出：
簇 2 中的 MOTHER_HEIGHT_IN非常不同。检查结果（在这里我们就不这么做了）很可能发现更多的不同，并且能让我们更好地了解数据。主题挖掘
聚类模型不仅限于数字型数据。在自然语言处理（NLP）领域，诸如主题提取等问题也依赖于聚类来检测具有相似主题的文档。我们将展示一个这样的例子。
首先创建数据集。数据来自互联网上随机选择的段落：其中三个是处理自然和国家公园的主题，其余三个覆盖技术主题。显而易见，这里又省略了某些代码片段。完整的代码请参考 GitHub 上的源文件。



首先，再次使用 RegexTokenizer 和 StopWordsRemover 模型：
接下来，管道中的是 CountVectorizer：该模型计算文档中的单词并返回一个计数向量。向量长度等于所有文档中不同单词的总数，可以在以下代码段中看到：
以上代码产生如下输出：
如你所见，文本中有 262 个不同的单词，而每个文档由每个单词出现次数的计数表示。
现在可以开始预测主题了。为此，我们将使用 LDA 模型——潜在狄利克雷分布（Latent Dirichlet Allocation）模型：


k参数指定我们期待看到的主题数量，optimizer参数可以是“online”或“em”（后者代表最大期望算法）。
把这些拼在一起就会产生到目前为止我们所做过的最长的管道了：
我们有没有正确揭示了话题呢？那我们来看看吧：
我们得到的是：
看起来我们的方法正确地发现了所有的主题！但是千万不要对这种好结果习以为常：悲惨的是，现实世界的数据很少会这样友好。
6.4.4 回归
还没构建一个回归模型，我们不能就这么结束关于机器学习库的这一章节。
在本节中，我们将尝试用给定的一些特征来预测 MOTHER_WEIGHT_GAIN，在这里列出它们包含的特征：
首先，由于所有的特征都是数字型的，所以将它们整理在一起，并使用 ChiSqSelector 来仅选择前六个最重要的特征：
为了预测增加的体重，我们将使用梯度提升决策树 regressor：



最后，我们把它们一起放在一个管道：
创建了 weightGain 模型后，我们来看看它在测试数据上是否表现良好：
我们得到如下输出：
遗憾的是，这个模型没有什么特别之处。看起来如果没有与 MOTHER_WEIGHT_GAIN标签相关的其他更好的独立特征，我们将无法充分解释其变化。6.
