# 优化介绍

大部分机器学习模型的参数估计问题都可以写成优化问题。

机器学习模型不同，损失函数不同，对应的优化问题也各不相同。



## 凸函数

凸函数定义：

- 函数 $L(\cdot)$ 是凸函数当且仅当对定义域中的任意两点 $x, y$ 和任意实数 $\lambda \in[0,1]$ 总有


$$
L(\lambda x+(1-\lambda) y) \leqslant \lambda L(x)+(1-\lambda) L(y)
$$

图示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190407/nAjNgctqwNsH.png?imageslim">
</p>

即：

- 凸函数曲面上任意两点连接而成的线段，其上的任意一点都不会处于该函数曲面的下方。


# 优化问题划分


凸优化问题：

- 支持向量机
- 线性回归等线性模型

非凸优化问题：

- 低秩模型（如矩阵分解）<span style="color:red;">没懂</span>
- 深度神经网络模型


对比：

- 对于凸优化问题，所有的局部极小值都是全局极小值，因此这类问题一般认为是比较容易求解的问题。
