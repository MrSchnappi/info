---
title: 2.12 朴素贝叶斯分类器
toc: true
date: 2019-09-03
---

### 2.19.4 朴素贝叶斯分类器

<span style="color:red;">想知道，是不是用 PCA 或 LDA  去除线性相关属性之后就可以使用朴素贝叶斯来进行分类了？还说非线性相关的属性也要去掉？在真实工作中要怎么去掉这种相关的属性？怎么知道属性是独立的？</span>

假设样本 $\boldsymbol{x}$ 包含 $d$ 个属性，即 $\boldsymbol{x}=\{ x_1,x_2,...,x_d\}$。于是有：

$$
P(\boldsymbol{x}|c_i)=P(x_1,x_2,\cdots,x_d|c_i)
$$

这个联合概率难以从有限的训练样本中直接估计得到。于是，朴素贝叶斯（Naive Bayesian，简称 NB）采用了“属性条件独立性假设”：对已知类别，假设所有属性相互独立。于是有：

$$
P(x_1,x_2,\cdots,x_d|c_i)=\prod_{j=1}^d P(x_j|c_i)
$$

这样的话，我们就可以很容易地推出相应的判定准则了：

$$
h_{nb}(\boldsymbol{x})=\mathop{\arg \max}_{c_i\in Y} P(c_i)\prod_{j=1}^dP(x_j|c_i)
$$

<span style="color:red;">这个 nb 是什么？</span>

**条件概率 $P(x_j|c_i)​$ 的求解：**

如果 $x_j$ 是标签属性，那么我们可以通过计数的方法估计 $P(x_j|c_i)$

$$
P(x_j|c_i)=\frac{P(x_j,c_i)}{P(c_i)}\approx\frac{\#(x_j,c_i)}{\#(c_i)}
$$

其中，$\#(x_j,c_i)$ 表示在训练样本中 $x_j$ 与 $c_{i}$ 共同出现的次数。

如果 $x_j​$ 是数值属性，通常我们假设类别中 $c_{i}​$ 的所有样本第 $j​$ 个属性的值服从正态分布。我们首先估计这个分布的均值 $μ​$ 和方差 $σ​$，然后计算 $x_j​$ 在这个分布中的概率密度 $P(x_j|c_i)​$。<span style="color:red;">没明白，这个要怎么算？</span>





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions) 原文
