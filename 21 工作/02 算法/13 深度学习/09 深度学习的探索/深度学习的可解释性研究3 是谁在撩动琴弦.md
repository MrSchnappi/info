---
title: 深度学习的可解释性研究3 是谁在撩动琴弦
toc: true
date: 2019-11-17
---
# 深度学习的可解释性研究3 是谁在撩动琴弦


在上一节中我们介绍了建模后深度学习可解释性方法之一：隐层分析法，但我们也会发现隐层分析法的一个问题在于，通过端到端训练的隐层很多时候并没有什么特定的含义，多数依赖我们的主观判断。但是深度学习模型中往往只有输入层对我们来说才是有意义的，所以了解深度学习模型的一个更直观的方法是通过研究输入层的变化对结果的影响来判断输入变量或输入样本的重要性，这也是通常所说的敏感性分析方法。



敏感性分析（Sensitivity Analysis）是一类非常重要的，用于定量描述模型输入变量对输出变量的重要性程度的方法，在经济、生态、化学、控制等领域都已经有了非常成熟的应用。假设模型表示为 ![[公式]](https://www.zhihu.com/equation?tex=y%3Df%28x_1%2Cx_2%2C...%2Cx_n%29) ，**敏感性分析就是令每个属性在可能的范围变动，研究和预测这些属性的变化对模型输出值的影响程度**。我们将影响程度的大小称为该属性的敏感性系数，敏感性系数越大，就说明属性对模型输出的影响越大。一般来讲对于神经网络的敏感性分析方法可以分为**变量敏感性分析、样本敏感性分析**两种，变量敏感性分析用来检验输入属性变量对模型的影响程度，样本敏感性分析用来研究具体样本对模型的重要程度，也是敏感性分析研究的一个新方向。

## **变量敏感性分析**

神经网络中的变量敏感性分析方法大概有以下几种：基于连接权的敏感性方法，基于偏导的敏感性分析方法、通过改变输入变量观察其影响的方法和与统计方法结合的敏感性分析方法。



**基于连接权的敏感性分析方法**

基于连接权的方法中比较有代表性的工作是Garson等人1991年在**《Interpreting neural network connection weights》**提出的方法，这种来自于“远古时期”的智慧相对来说就要简单粗暴一点。输入变量 ![[公式]](https://www.zhihu.com/equation?tex=x_i+) 对输出变量 ![[公式]](https://www.zhihu.com/equation?tex=y_k) 的影响程度为：

![[公式]](https://www.zhihu.com/equation?tex=Q_%7Bik%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5EL%28w_%7Bij%7Dv_%7Bjk%7Dg%2F%5Csum_%7Br%3D1%7D%5ENw_%7Bij%7D%29%7D%7B%5Csum_%7Bi%3D1%7D%5EN%5Csum_%7Bj%3D1%7D%5EL%28w_%7Bij%7Dv_%7Bjk%7Dg%2F%5Csum_%7Br%3D1%7D%5ENw_%7Brj%7D%29%7D)

但是由于这种方法中 ![[公式]](https://www.zhihu.com/equation?tex=w_%7Bij%7D) 的正负性导致我们可能没办法得到真实的敏感性系数，所以后来就对这个公式进行了改造，改为用绝对值来评估影响力。

![[公式]](https://www.zhihu.com/equation?tex=Q_%7Bik%7D%27+%3D+%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5EL%28%7Cw_%7Bij%7Dv_%7Bjk%7D%7Cg%2F%5Csum_%7Br%3D1%7D%5EN%7Cw_%7Bij%7D%7C%29%7D%7B%5Csum_%7Bi%3D1%7D%5EN%5Csum_%7Bj%3D1%7D%5EL%28%7Cw_%7Bij%7Dv_%7Bjk%7D%7Cg%2F%5Csum_%7Br%3D1%7D%5EN%7Cw_%7Brj%7D%7C%29%7D)



下图就通过一个例子描述了Garson方法对变量重要性的评估过程。

![img](https://pic3.zhimg.com/80/v2-1f9fb3da3acd7ce7f8fcd50904940f6a_hd.jpg)



![img](https://pic4.zhimg.com/80/v2-cfa0dd0bddeb15670e3ed6e2909a475f_hd.jpg)

![img](https://pic2.zhimg.com/80/v2-c05fab555a67a8f8069c44535a638c9d_hd.jpg)

当然这种方法存在的问题就不用我多说了，放到一个两个隐层的网络可能还适用，放到深度网络中由于忽略了非线性激活函数误差会一步一步积累，所以慢慢也就被大家抛弃了。



**基于统计方法的敏感性分析方法**

基于统计方法的敏感性分析方法中一个比较有代表性的工作是Olden等人2002年在Elsevier上发表的**《Illuminating the “black box”: a randomization approach for understanding variable contributions in artificial neural networks》**，虽然也是来自于“远古时期”的智慧，却是我个人非常欣赏的一个工作，现在看来依然觉得非常牛逼。这个工作的步骤如下：

\1. 使用随机初始的权重构建一组神经网络

\2. 从中选出预测性能最好的神经网络，记录下该网络的初始权重，计算并记录：

(1) 输入神经元对输出神经值经过某个隐层神经元的连接权重：也就是上面Garson算法图中的 ![[公式]](https://www.zhihu.com/equation?tex=c_%7BA1%7D+)

(2) 全局的连接权重，也就是每个变量输入层到输出层连接权的总和，也就是上面Garson算法图中的 ![[公式]](https://www.zhihu.com/equation?tex=c_1+%3D+c_%7BA1%7D%2Bc_%7BB1%7D)

(3) 根据前面所提到Garson算法计算每个变量的相对重要性

\3. 随机打乱输出值( ![[公式]](https://www.zhihu.com/equation?tex=y_%7Brandom%7D) )

\4. 使用 ![[公式]](https://www.zhihu.com/equation?tex=y_%7Brandom%7D) 和初始的随机权重构建一个神经网络

\5. 大量重复步骤3和4，每次都记录步骤2中的值

这个方法牛逼的地方在于通过大量的重复采样（bootstrap）使得**对神经网络的统计检验**成为了可能，随机打乱了输出值使我们能够得到**基于给定初始值随机训练网络的权重和重要性分布**，这样就可以通过统计检验的方法来（如果pvalue非常小，那么我们可以认为这个值不是随机选的，是显著的），就像下图所示，表示了表面积对生物多样性的影响（三个图分别表示在步骤2中所记录的经过隐层神经元B的连接权、总连接权、相对重要性），在概率分布图中基本P值都比较小，因此可以认为这些影响都是显著的。

![img](https://pic3.zhimg.com/80/v2-afd57bafd19ebe1d61d140f46f0b80c6_hd.jpg)

![img](https://pic3.zhimg.com/80/v2-3449130e6a2c0cfe892ed5e23523e4ce_hd.jpg)

![img](https://pic1.zhimg.com/80/v2-ab793f482a8324f729bb3cc25c593504_hd.jpg)



**基于偏导的敏感性分析方法**

基于偏导的敏感性分析方法主要是利用偏导数来评估输入变量对输出的影响，比如Dimoponlos等人在**《Use of some sensitivity criteria for choosing networks with good generalization ability》**中提出的敏感性方法，除了考虑偏导以外，作者也考虑了曲率（也就是二阶导数）的影响，因为神经网络在激活函数处的非线性导致了虽然导数绝对值较小，但有可能因为曲率较大导致敏感性高的情况，某个变量j的敏感性可以由所有样本在变量j处的导数和曲率乘积的平方和度量：



![img](https://pic4.zhimg.com/80/v2-e805102325f96cb086b587f5b08e0bc7_hd.jpg)

**基于输入变量扰动的敏感性分析方法**

基于输入变量扰动的敏感性分析方法是在前向网络中最为常用的一种敏感性分析方法，可以用于评估变量的重要性从而达到变量筛选的目的，比如Dombi等人提出的**平均影响值（MIV，Mean Impact Value）方法**就是一种被广泛应用的评估方法，MIV方法的计算过程如下：

1. 在网络训练终止后，将训练样本P中每一自变量特征在原值的基础上分别加/减10%后成两个训练样本P1和P2
2. 将P1和P2分别作为仿真样本利用已建成的网络进行仿真，得到两个仿真结果A1和A2
3. 求出A1和A2的差值，即为变动该自变量后对输出产生的影响变化值
4. 最后将IV按观测样本数平均得到该自变量对应变量——网络输出的MIV。

按照MIV的绝对值排序即可得到各个自变量对网络输出影响的重要性排序，从而完成变量筛选的目的。

## **样本敏感性分析**

样本敏感性分析中比较有代表性的工作是 Pang Wei Koh 2017年在ICML上发表的

**《Understanding Black-box Predictions via Influence Functions》**，这篇文章也是去年ICML的best paper，通过影响力函数来理解深度学习黑盒模型的预测效果。什么是影响力函数呢？这个其实就涉及到统计学的相关概念了，大家都知道一般来说我们训练神经网络模型也好还是别的SVM之类的什么模型都是通过SGD等方法训练的，找到一个目标损失函数然后让它不断收敛得到最终的参数。在理想状况下最后收敛的点应该都是导数为0的点，那么我们如何评估某个样本的敏感度呢？有个办法就是将样本做微小的改变 ![[公式]](https://www.zhihu.com/equation?tex=%5Cepsilon) ，这样最后收敛的参数也会发生改变，然后得到参数的改变对 ![[公式]](https://www.zhihu.com/equation?tex=%5Cepsilon) 的导数就是这个样本的影响力函数。

这里如果假设 ![[公式]](https://www.zhihu.com/equation?tex=L%28z_i%2C%5Ctheta%29) 是每个样本的损失函数，那么总的损失函数可以写成：

![img](https://pic2.zhimg.com/80/v2-3c88d31c719b101b6e48f4c1be3ed07d_hd.jpg)

![[公式]](https://www.zhihu.com/equation?tex=R%28%5Ctheta%29) 的二阶偏导矩阵 ![[公式]](https://www.zhihu.com/equation?tex=H_%7B%5Chat+%5Ctheta%7D) 可以写成下面的形式，这里我们假设 ![[公式]](https://www.zhihu.com/equation?tex=H_%7B%5Chat+%5Ctheta%7D) 是正定的，这样可以保证在后续推导中 ![[公式]](https://www.zhihu.com/equation?tex=H_%7B%5Chat+%5Ctheta%7D) 的逆存在

![img](https://pic2.zhimg.com/80/v2-441d3bfce5fcf927227c06258a7f10b9_hd.jpg)

在这里我们给z样本添加一个微小的扰动 ![[公式]](https://www.zhihu.com/equation?tex=%5Cepsilon) ，这个时候可以得到一个新的收敛参数 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat+%5Ctheta_%7B%5Cepsilon%2Cz%7D)

![img](https://pic3.zhimg.com/80/v2-72317d0c98b97b349aeec2bdc8512df2_hd.jpg)

定义参数的改变量为 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctriangle_%5Cepsilon+%3D+%5Chat+%5Ctheta_%7B%5Cepsilon%2Cz%7D-%5Chat+%5Ctheta) ，则我们要计算的可以表示为：

![img](https://pic1.zhimg.com/80/v2-afb2a19c5399b4afcdc823a9ef41bd7c_hd.jpg)

由于导数为0的条件可以得到：

![img](https://pic4.zhimg.com/80/v2-f29b4614d391814b0aeac5582f7536af_hd.jpg)

由于当 ![[公式]](https://www.zhihu.com/equation?tex=%5Cepsilon)趋近于0，![[公式]](https://www.zhihu.com/equation?tex=%5Chat+%5Ctheta_%7B%5Cepsilon%2Cz%7D+%5Crightarrow+%5Chat+%5Ctheta) ，可以应用泰勒展开得到下面的式子

![img](https://pic2.zhimg.com/80/v2-3e6c6e79eb01aef80094d77671ebe12d_hd.jpg)

![img](https://pic1.zhimg.com/80/v2-57c457c3e82fa9c061d05baf6f433c3c_hd.jpg)



由于 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctriangle+R%28%5Chat+%5Ctheta%29%3D0) ，只保留 ![[公式]](https://www.zhihu.com/equation?tex=O%28%5Cepsilon%29) 项

可以得到：

![img](https://pic1.zhimg.com/80/v2-a802bd048804e0dc061e72355861dac4_hd.jpg)

最后我们可以得到下面的表达式：

![img](https://pic1.zhimg.com/80/v2-5a7276fde58b9e84b7a7b73c1a2eaf24_hd.jpg)

这个也就是**影响力函数的表达式，**根据这个定义，作者推导出了提升某个训练样本的权重或者对训练样本施加轻微扰动之后对特定测试样本损失函数的影响：

![img](https://pic4.zhimg.com/80/v2-dd79b435854e0298187b41ed6c96b63f_hd.jpg)

![img](https://pic2.zhimg.com/80/v2-9fb923239b02420e1cc2e06a12f9f2f5_hd.jpg)

当然由于在影响力的计算中涉及到Hessian矩阵的求逆问题，作者也提出了一种简便计算的方法来迅速计算影响力函数的近似值，具体在这里就不介绍了，想了解的可以阅读原文以备参考。

通过影响力函数的计算可以发现，对下图的测试样本7来说，右边的训练样本的存在对该样本的判定是有害的。

![img](https://pic3.zhimg.com/80/v2-aa551b746e31a0a8e5afd037734ff822_hd.jpg)

而由于计算出了对训练样本施加轻微扰动之后对特定测试样本损失函数的影响，所以这个方法也可以应用到对抗样本的生成中，只需要在一部分影响力函数较大的样本中添加一些肉眼不可见的扰动，就足以干扰其他样本的判定结果。

![img](https://pic4.zhimg.com/80/v2-4e78876987984bf057db843b0853386f_hd.jpg)



## **小结**

在本节中我们介绍了建模后深度学习可解释性方法之一——敏感性分析方法，敏感性方法的主要用途是衡量变量/样本的重要性，优点是把解释性归于输入特征或样本使得更容易被理解。不过敏感性方法不如隐层分析法的一点在于基本上完全忽视了对隐层结构的研究，在接下来我们将介绍第三类方法：代理/替代模型方法，欢迎继续关注。


# 相关

- [深度学习的可解释性研究（三）——是谁在撩动琴弦](https://zhuanlan.zhihu.com/p/38568075)
- Garson G D. Interpreting neural-network connection weights[M]. Miller Freeman, Inc. 1991.
- Olden J D, Jackson D A. Illuminating the “black box”: a randomization approach for understanding variable contributions in artificial neural networks[J]. Ecological Modelling, 2002, 154(1–2):135-150.
- Dimopoulos Y, Bourret P, Lek S. Use of some sensitivity criteria for choosing networks with good generalization ability[J]. Neural Processing Letters, 1995, 2(6):1-4.
- Koh P W, Liang P. Understanding Black-box Predictions via Influence Functions[J]. 2017.
