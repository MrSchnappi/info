---
title: 03 DCGAN 当 GANs 遇上卷积
toc: true
date: 2019-04-24
---
# 可以补充进来的

- 感觉挺厉害的。不过有些没有怎么明白。

# DCGAN：当 GANs 遇上卷积


虽然 GANs 一开始用于图像生成，但是没有马上应用卷积神经网络。<span style="color:red;">哎？为什么呢？</span>

通常提到图像，人们会想到卷积神经网络，为什么 GANs 最初时没有用它呢？原来不是随便一个卷积神经网络就能玩转 GANs，研究者最初的尝试不怎么成功。<span style="color:red;">哦，为什么呢？</span>

图像相关的几大学习任务包括：图像分类、图像分割、物体检测与识别等。


**我们先看看图像分类**

图像分类任务是大多数卷积神经网络的主战场，从手写数字识别到 ImageNet 大规模图像识别比赛，从 AlexNet、VGG、GoogLeNet 到 ResNet，遍布着各类卷积神经网络结构。

输入一张图片，输出一个类别，一端是密密麻麻的像素点阵，一端是表示类别的一个词，从输入端到输出端会丢失大量信息。而信息的丢失使得卷积神经网络仅用来识别图片类别，难以输出一张高分辨率的图片。<span style="color:red;">嗯，信息的丢失造成的。</span>

比如识别狗的图片，模型关心的是狗，不是狗的大小、颜色和品种，如图 13.9所示，图像分类：

<center>

![](http://images.iterate.site/blog/image/20190424/wJLhbyqENIn6.png?imageslim){ width=55% }

</center>


**再看看图像分割**

图像分割任务中，输入一张图片，输出与原图同尺寸的分割图，图片被切成不同区域，同区域的点用同一颜色表示。输入端还是一张图，输出端信息量相比分类任务是有所增加了。

注意，传统卷积神经网络中每层的高宽越来越小，丢失大量与像素位置相关的信息。

因此，为了进行图像分割任务，研究者们提出了一些新的卷积神经网络结构，比如分数步进卷积层（Fractional-Strided Convolutions），也称反卷积层（Deconvolutions），它让每层的高宽不减反增，从而使得分割任务中最终的输出和原始输入图片尺寸相同。<span style="color:red;">没想到。之前对于图像分割没有怎么了解过，没想到是用反卷积层做的。嗯，想更多的了解下</span>


如图所示，图像分割。

<center>

![](http://images.iterate.site/blog/image/20190424/TcUMdgypkhsX.png?imageslim){ width=55% }

</center>


**OK，我们再来看看图像生成**

图像生成不是图像分割（见图 13.11）：

<center>

![](http://images.iterate.site/blog/image/20190424/qMphAjmYfAJO.png?imageslim){ width=55% }

</center>

图像分割的输出端虽然与原图同尺寸，但是像素级别的细节信息依然大量丢掉，难以生成高分辨率的图片。<span style="color:red;">是的。</span>

图像生成这点事，绝不是信手拈来一个卷积神经网络就能搞定。我们该怎么改进卷积神经网络呢？<span style="color:red;">嗯。</span>

知识点

卷积神经网络，分数步进卷积层（反卷积层），批量归一化，ReLU/LReLU

## 在生成器和判别器中应该怎样设计深层卷积结构？

为了生成高分辨率的优质图片，我们准备在 GANs 框架内嵌入多层卷积网络。

但是，一般的卷积结构达不到我们的期待。

分析与解答


为了充分发挥 GANs 中卷积网络的威力，我们需要搞清楚两件事情：生成器到底做了什么？以及判别器到底做了什么？<span style="color:red;">是的。</span>

### 生成器

生成器生成图片，可以看成图片分类的一个逆过程。图片分类器的输入是一张图片，输出是一个类别；图片生成器的输出是一张图片，但它的输入是什么呢？

输入通常有一个随机向量，如高斯分布产生的 100 维随机向量。这个随机向量有什么含义？在深度神经网络的黑盒子里，我们无从知道。但是我们可以确定：100 维随机向量对比一张 128×128 小图片（扁平化后是 16384 维）是一个极低维的向量。<span style="color:red;">是的。</span>

从低维向量得到高维图片，想高分辨率，这怎么可能？

例如，从一个类别到一张图片，信息由少到多，不仅不能压缩或丢失信息，还要补充信息，任务难度必然增大。

好比，我一说“狗”，你脑子里闪出狗的画面，可能是金巴，可能是藏獒，你以前一定见过这样的狗，脑子里已经有了它的影像信息，我的一个词就能引起你的想象。

即便这样，让你画出狗来，假定你绘画功底很强，你最先画出的是狗的轮廓，而不是一张真实图片，因为有太多的细节需要一点点添加，比如：狗毛发的颜色，狗是跑着的还是卧着的，狗在屋子里还是在草地上……

我们可以把 100 维随机向量，理解成要事先确定一些信息，除了类别还要有细节，它们各项独立并可以相互组合，比如一只装在茶杯里的呆萌茶杯犬：<span style="color:red;">什么叫除了类别还有细节？感觉这句话有点不通顺。。</span>

<center>

![](http://images.iterate.site/blog/image/20190424/CT2yFtfQmnhp.png?imageslim){ width=55% }

</center>

用随机向量的每维刻画不同的细节，然后生成一张图片。

随机向量不含像素级别的位置信息，但是对于图片，每个像素都有它的位置，点构成了线，线组成了面，进而描绘出物体的形状。如果这些位置信息不是从随机向量中产生，那么就应出自生成器的特殊网络结构。<span style="color:red;">嗯。</span>


那么，卷积神经网络能体现位置信息吗？

最初设计卷积神经网络时，引入了感受野的概念，捕捉图片邻近区域的特征，只有位置靠近的像素点才能被感受野一次捕捉到。传统多层卷积结构中，越靠近输入端，包含的位置信息越明显，随着层层深入，感受野涵盖的区域扩大，过于细节的位置信息丢失，留下高级语义信息，更好地反映图片的类别。<span style="color:red;">嗯，是的。感受野。使得只有位置靠近的像素点才能被感受野一次捕捉到。</span>

经典的卷积神经网络只是捕捉或识别位置信息，不负责产生位置信息，位置信息来源于输入的图片，当它们不能有效反映图片的高级语义（如类别）时，就会在逐层计算中被丢掉[36]。<span style="color:red;">嗯。是的。</span>

因此，从随机向量造出图片，要在造的过程中产生位置信息。<span style="color:red;">是的。</span>

这个生成过程需要符合以下两点原则：


1. 保证信息在逐层计算中逐渐增多。
2. 不损失位置信息，并不断产生更细节的位置信息。

<span style="color:red;">是呀，要怎么做呢？</span>

参考文献[37]给出了一套具体的做法：


#### 1. 去掉一切会丢掉位置信息的结构，如池化层。

池化层是在邻近区域取最大或取平均，会丢失这一区域内的位置信息：无论怎么布局，最大值和平均值是不变的。位置不变性是应对图片分类的一个优良性质，但是对图片生成来说是一个糟糕的性质，因为这是一个降采样的过程，通过丢失细节信息来保留高级语义（即分类相关信息）。<span style="color:red;">是的，位置不变性是一个降采样的过程。</span>
#### 2. 使用分数步进卷积层。<span style="color:red;">这个是什么？之前好像没有听说过。</span>


模型要做的不是抽象而是具象，计算是升采样的过程，逐步提供更多细节。将 100 维随机向量经过一层，变换成一个 4×4×1024 的张量，宽度和高度都为 4，虽然大小有限，但是暗示了位置的存在，接着经过层层变换，高度和宽度不断扩大，深度不断减小，直至输出一个有宽度、高度及 RGB 三通道的 64×64×3 图片。<span style="color:red;">嗯，以前一直想知道，为什么要层层变换呢？这些层层变换起到的作用是什么？多少层合适？为什么不能一层到位？</span>

传统卷积层只能缩小或保持前一层的高度和宽度，对于扩大高宽无能为力，我们需要采用特殊的卷积层来实现增加高宽的升采样计算[38]，即分数步进卷积层，如图 13.13所示：<span style="color:red;">什么是分数步进卷积层？是怎么做到的？</span>


![](http://images.iterate.site/blog/image/20190426/AvetosfWhaIC.png?imageslim){ width=55% }


步长大于 1 的传统卷积层会把输入图缩成一张高宽更小的图，5×5 的图经过核 3×3步长 2×2 的卷积层得到一个 2×2 的图，如图 13.14（a）所示：

<center>

![](http://images.iterate.site/blog/image/20190426/42jPklgT2Yqd.png?imageslim){ width=55% }

</center>


如果这个过程可逆，则由输入 2×2 图可得 5×5图。严格意义上的逆过程是数学上的求逆操作，这太复杂。分数步进卷积层只是象征性地保证输入 2×2 图输出 5×5 图，同时仍满足卷积操作的定义。

怎么做到的？

填零，不仅边缘处填零，像素点间也填零。我们将 2×2 图扩为 5×5 图，再经过核 3×3 步长 1×1 的卷积层，就能得到一个 5×5 图，如图 13.14（b）所示。这个“逆”卷积过程只是图分辨率的逆，而非数学意义上的求逆。<span style="color:red;">？没有怎么看明白。怎么扩充的？嗯，看到说不仅边缘处填 0，像素间也填 0 ，好像明白了。不过还是要明确下的。</span>


#### 3. 去掉最后的全连接层

通常 CNN 最后接全连接层，是为了综合各维度做非线性变换，应对图片分类的目标。这里的任务是生成图片，用全连接层不仅没必要，还会打乱多层卷积建立的空间结构。<span style="color:red;">是的。</span>

越靠近图片输出端，越要精心呵护宽高二维平面上的位置信息，反而在输入端可以增加一个全连接层，将 100 维随机向量经过矩阵乘法转换成 4×4×1024 的张量。<span style="color:red;">嗯。加了这个效果会变好吗？</span>


#### 4. 批量归一化和 ReLU 激活函数

批量归一化是 2015 年 Loffe & Szegedy 提出的用于改进神经网络结构的一层，称为 Batchnorm 层，现已被广泛使用[39]。

单个神经元在 batch 层面上做正规化处理，得到均值 0 方差 1 的新 batch，保证通畅的梯度流，免除糟糕初始化的影响，改善模型的训练效果。

生成模型越深，越需要 Batchnorm 层，否则训练不充分，极易出现模型坍塌问题，总生成相同的图片样本。<span style="color:red;">哦，这个之前只知道 Batchnorm 可以使训练模型更快，不知道在生成模型中也很重要。</span>

另外，为了避免梯度饱和，让学习更稳定，内部使用 ReLU 激活函数，只在图片输出层用 Tanh 激活函数。<span style="color:red;">为什么？为什么不用相同的函数？</span>

### 判别器

判别器鉴别生成图片和实际图片。这是一个典型的图片分类任务，但是又不同于一般的图片分类。

真品和赝品的区别，往往是细节上的差异，而不是宏观层面的语义差异。<span style="color:red;">哇塞！没想到！</span>

判别器的多层卷积网络，依然抛弃池化层，将它替换为步长大于 1 的卷积层，虽然也是一个降采样的过程，但是没有池化层那样粗放。<span style="color:red;">嗯，是的，因为要关注细节。</span>

判别器的最后一层不接全连接层，扁平化处理后直接送给 Sigmoid 输出层，最大限度地留住位置细节。<span style="color:red;">嗯。</span>

另外，判别器的内部激活函数使用 LReLU，也是要最大限度地留住前层信息。<span style="color:red;">这个为什么？为什么 LReLU 可以最大限度的保留前层信息？</span>

判别器也用到 Batchnorm 层。<span style="color:red;">嗯。</span>



# 相关

- 《百面机器学习》
