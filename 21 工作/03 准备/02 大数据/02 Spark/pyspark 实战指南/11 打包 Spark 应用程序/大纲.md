---
title: 大纲
toc: true
date: 2019-07-02
---
到目前为止，我们已经使用 Spark 进行了一种非常方便的开发代码方式——Jupyter笔记本。当你想研究一个概念验证并且记录你在这个过程中做了什么时，这种方法就很好。
不过，如果你需要计划一个作业，该作业每小时都在运行，Jupyter笔记本就工作不了了。另外，打包应用程序是相当困难的，因为很难把你的脚本分成具有明确定义的 API 的逻辑块——所有的东西都放在一个笔记本中。
在本章中，我们会学习到如何利用可重用的模块形式编写脚本，并且以编程方式提交作业到 Spark。
然而在你开始之前，你可能想查看额外的章节，我们提供了关于如何订阅和使用 Databricks 社区版本或者 Microsoft 的 HDInsight Spark产品的操作指南。关于如何使用该指南可以在此处找到：https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf。
