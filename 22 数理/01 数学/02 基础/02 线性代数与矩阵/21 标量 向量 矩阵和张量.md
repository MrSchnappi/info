---
title: 21 标量 向量 矩阵和张量
toc: true
date: 2019-05-05
---

# 标量 向量 矩阵和张量

学习线性代数，会涉及以下几个数学概念：

## 标量(scalar)

一个标量就是一个单独的数，它不同于线性代数中研究的其他大部分对象(通常是多个数的数组)。我们用斜体表示标量。标量通常被赋予小写的变量名称。

在介绍标量时，我们会明确它们是哪种类型的数。比如，在定义实数标量时，我们可能会说“令 $s \in \mathbb{R}$ 表示一条线的斜率”；在定义自然数标量时，我们可能会说“令 $n \in \mathbb{N}$ 表示元素的数目”。<span style="color:red;">嗯，是的。</span>


## 向量(vector)

一个向量是一列数。这些数是有序排列的。通过次序中的索引，我们可以确定每个单独的数。<span style="color:red;">向量一定是一列的吗？不会是一行的是吧？</span>

通常我们赋予向量粗体的小写变量名称，比如 $\boldsymbol{x}$。向量中的元素可以通过带脚标的斜体表示。向量 $\boldsymbol{x}$ 的第一个元素是  $x_1$ ，第二个元素是 $x_2$，等等。我们也会注明存储在向量中的元素是什么类型的。如果每个元素都属于 $\mathbb{R}$，并且该向量有 $n$ 个元素，那么该向量属于实数集 $\mathbb{R}$ 的 $n$ 次笛卡儿乘积构成的集合，记为 $\mathbb{R}_n$。<span style="color:red;">什么意思？该向量属于实数集 $\mathbb{R}$ 的 $n$ 次笛卡儿乘积构成的集合？</span>

当需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵列：

$$
\boldsymbol{x}=\left[ \begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{n}}\end{array}\right]\tag{2.1}
$$

我们可以把向量看作空间中的点，每个元素是不同坐标轴上的坐标。

有时我们需要索引向量中的一些元素。在这种情况下，我们定义一个包含这些元素索引的集合，然后将该集合写在脚标处。比如，指定 $x_{1}$、$x_{3}$ 和 $x_{6}$，我们定义集合 $S=\{1,3,6\}$ ，然后写作 $x_S$。我们用符号 - 表示集合的补集中的索引。比如 $\boldsymbol{x}_{-1}$ 表示 $\boldsymbol{x}$ 中除 $x_{1}$ 外的所有元素，$\boldsymbol{x}_{-S}$ 表示 $\boldsymbol{x}$ 中除 $x_{1}$, $x_{3}$, $x_{6}$ 外所有元素构成的向量。<span style="color:red;">嗯，之前没有见到过 $\boldsymbol{x}_{-S}$ 这样的表示，嗯，也挺合理的。</span>


## 矩阵(matrix)

矩阵是一个二维数组，其中的每一个元素由两个索引(而非一个)所确定。

我们通常会赋予矩阵粗体的大写变量名称，比如 $\boldsymbol{A}$。如果一个实数矩阵高度为 $m$，宽度为 $n$，那么我们说 $\boldsymbol{A} \in \mathbb{R}^{m \times n}$ 。我们在表示矩阵中的元素时，通常以不加粗的斜体形式使用其名称，索引用逗号间隔。比如，$A_{1,1}$ 表示 $\boldsymbol{A}$ 左上的元素，$A_{m,n}$ 表示 $\boldsymbol{A}$ 右下的元素。我们通过用“:”表示水平坐标，以表示垂直坐标 i 中的所有元素。比如，$\boldsymbol{A}_{i,:}$ 表示  $\boldsymbol{A}$ 中垂直坐标 $i$ 上的一横排元素。这也被称为  $\boldsymbol{A}$  的第 $i$ 行(row)。同样地，$\boldsymbol{A}_{ :, i}$ 表示  $\boldsymbol{A}$ 的第 $i$ 列(column)。<span style="color:red;">嗯，好的。</span>

当需要明确表示矩阵中的元素时，我们将它们写在用方括号括起来的数组中：

$$
\left[ \begin{array}{ll}{A_{1,1}} & {A_{1,2}} \\ {A_{2,1}} & {A_{2,2}}\end{array}\right]\tag{2.2}
$$


有时我们需要矩阵值表达式的索引，而不是单个元素。在这种情况下，我们在表达式后面接下标，但不必将矩阵的变量名称小写化。比如，$f(\boldsymbol{A})_{i, j}$ 表示函数 $f$ 作用在 $\boldsymbol{A}$ 上输出的矩阵的第 $i$ 行第 $j$ 列元素。<span style="color:red;">嗯，这种表示忘记之前有没有看到过了。后面注意下。</span>


## 张量(tensor)

在某些情况下，我们会讨论坐标超过两维的数组。一般的，一个数组中的元素分布在若干维坐标的规则网格中，我们称之为张量。<span style="color:red;">哇塞，规则网络中，厉害，如果是一个不规则网络呢？</span>


我们使用字体![](http://images.iterate.site/blog/image/20190505/f1uc8uphqyJu.png?imageslim){ width=55% }来表示张量“A”。张量中坐标为 $(i, j, k)$ 的元素记作 $A_{i, j, k}$。



转置(transpose)是矩阵的重要操作之一。矩阵的转置是以对角线为轴的镜像，这条从左上角到右下角的对角线被称为主对角线(main diagonal)。

图 2.1显示了这个操作。我们将矩阵 $A$ 的转置表示为 $A^{\top}$，定义如下

$$
\left(\boldsymbol{A}^{\top}\right)_{i, j}=A_{j, i}\tag{2.3}
$$

向量可以看作只有一列的矩阵。对应地，向量的转置可以看作只有一行的矩阵。<span style="color:red;">嗯，是的。</span>有时，我们通过将向量元素作为行矩阵写在文本行中，然后使用转置操作将其变为标准的列向量，来定义一个向量，比如 $\boldsymbol{x}=\left[x_{1}, x_{2}, x_{3}\right]^{\top}$ 。<span style="color:red;">嗯嗯，是的。</span>

标量可以看作只有一个元素的矩阵。因此，标量的转置等于它本身，$a=a^{\top}$。


只要矩阵的形状一样，我们可以把两个矩阵相加。两个矩阵相加是指对应位置的元素相加，比如 $\boldsymbol{C}=\boldsymbol{A}+\boldsymbol{B}$ ，其中 $C_{i, j}=A_{i, j}+B_{i, j}$ 。

标量和矩阵相乘，或是和矩阵相加时，我们只需将其与矩阵的每个元素相乘或相加，比如 $\boldsymbol{D}=a \cdot \boldsymbol{B}+c$ ，其中 $D_{i, j}=a \cdot B_{i, j}+c$ 。

在深度学习中，我们也使用一些不那么常规的符号。我们允许矩阵和向量相加，产生另一个矩阵：$\boldsymbol{C}=\boldsymbol{A}+\boldsymbol{b}$ ，其中 $C_{i, j}=A_{i, j}+b_{j}$。换言之，向量 $\boldsymbol{b}$ 和矩阵 $\boldsymbol{A}$ 的每一行相加。这个简写方法使我们无须在加法操作前定义一个将向量 $\boldsymbol{b}$ 复制到每一行而生成的矩阵。这种隐式地复制向量 $\boldsymbol{b}$ 到很多位置的方式，称为广播(broadcasting)。<span style="color:red;">哦，这种计算的方式一直都知道，但是没有注意过这个的名字是广播，嗯。</span>




# 相关

- 《深度学习》花书
